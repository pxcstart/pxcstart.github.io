<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>长序列用户建模</title>
    <link href="/2025/06/09/%E9%95%BF%E5%BA%8F%E5%88%97%E7%94%A8%E6%88%B7%E5%BB%BA%E6%A8%A1/"/>
    <url>/2025/06/09/%E9%95%BF%E5%BA%8F%E5%88%97%E7%94%A8%E6%88%B7%E5%BB%BA%E6%A8%A1/</url>
    
    <content type="html"><![CDATA[<ol><li>SIM模型</li></ol><p>模型由GSU+ESU两部分组成：</p><p><strong>通用搜索单元GSU:</strong> 从原始的任意长顺序行为数据中进行通用搜索，结合候选项的查询信息，得到与候选项相关的子用户行为序列</p><p><strong>精确搜索单元ESU:</strong> 模拟候选项目与 SBS 之间的精确关系<br><img src="/../article_img/lifelong/img1.png" alt="SIM framework"></p><p>对于GSU部分，模型提出了两种通用搜索方案：<strong>硬搜索Hard Search</strong> 和 <strong>软搜索Soft Search</strong></p><div align="center">$$r_i =\begin{cases} Sign(C_i=C_a) & hard-search \\(W_b e_i) \odot (W_a e_a)^T & soft-search\end{cases}$$</div><p>硬搜索Hard Search: 根据item_category或item_id对behavior分成若干group，只检索与target item相同的group</p><p>软搜索Soft Search: 其中$W_a$和$W_b$为可训练参数，基于长期行为数据的辅助 CTR 预测任务进行训练。训练完成后，行为表示为$U_r&#x3D;\sum_{i&#x3D;1}^Tr_i e_i$，然后对每个行为表示和目标向量取内积，取分数最高的 Top-K 作为后续模型子集（内积搜索采用ALSH方法， 迅速高效）</p><p>对于ESU部分，通过Target Attention获取检索子集中每个行为和target item之间的注意力，通过多头注意力的方式获得用户长期兴趣表示</p><p><img src="/../article_img/lifelong/img2.png" alt="ESU Part"></p><p><strong>小结：</strong><br>SIM模型作为处理用户长序列用于兴趣建模的经典方案仍存在很多问题，例如:</p><ul><li>GSU的检索条件过于简单导致的信息丢失(Optimization: 多场景，多行为等)</li><li>两阶段范式并非端到端模型，建模模型和预估模型目标很难保证强一致性，即GSU与ESU之间的gap<ul><li>Optimization: 将Target Attention直接应用到长期行为序列，将两阶段建模修改为端到端建模 Challenge：如何高效的对长序列进行聚合</li></ul></li><li>依赖ID特征进新用户行为建模，缺乏对用户和商品的语义信息的理解<ul><li>Optimization: 使用LLM对用户行为进行建模  Challenge:（1）受LLM上下文长度的限制，无法直接有效的对lifelong behavior进行建模 （2）LLM很难关注序列中的时间信息，对动态兴趣变化的感知较弱<br>  （3）效率问题：随着输入行为序列长度的增加，训练和推理所需的时间会迅速增加</li></ul></li></ul><ol start="2"><li>ETA: Efficient Long Sequential User Data Modeling for Click-Through Rate Prediction</li></ol><p>论文链接：<a href="https://arxiv.org/abs/2209.12212">https://arxiv.org/abs/2209.12212</a></p><p>参考链接：<a href="https://mp.weixin.qq.com/s/yuM9ZRR91fMsC5eJBd1yLg">https://mp.weixin.qq.com/s/yuM9ZRR91fMsC5eJBd1yLg</a></p><p>Optimization: 将Target Attention应用到长序列中，缓解GSU和ESU的gap。它通过改善内积计算的方式提高target attention的效率</p><p>ETA 首先通过 SimHash 算法为打分商品和用户历史行为生成 Hash 签名，之后通过 HanmingDistance 为每个从中挑选出最相似的 TopK 个behavior和对应的target item，最后再利用进行标准的 Target Attention。（Novelty: 两个二进制 Hash 签名的 HanmingDistance 的计算是两个两个二进制数的异或运算和异或结果 1 的计数，二进制的运算效率要远远高于两个浮点数向量的内积）</p><p>Locality-sensitive hashing (LSH)是一种高维向量空间快速检索 K 近邻的方法。通常两个向量越相似，则可以以越高的概率获得相同的hash映射。由于概率存在一定的误差，通过 Multi-Round LSH 进行多轮 Hash，即可减少误差，提升精准度。</p><p>Multi-Round LSH：两个向量可以在一个二分类的球面上多次旋转投影，越相似的向量在多次旋转投影中落到同一个分类面的概率就越大。<br><img src="/../article_img/lifelong/img4.png" alt="Multi-Round LSH Attention"></p><p>SimHash算法：对稠密向量的每一维计算m次二进制hash，拼接起来作为该向量的SimHash结果<br><img src="/../article_img/lifelong/img5.png" alt="SimHash"></p><p>下面给出ETA的框架图：</p><p><img src="/../article_img/lifelong/img3.png" alt="ETA"></p><ol start="3"><li>TWIN: TWo-stage Interest Network for Lifelong User Behavior Modeling in CTR Prediction at Kuaishou</li></ol><p>参考链接：<a href="https://mp.weixin.qq.com/s/DjzXpc-9oenmEKSXEJ74Qw">https://mp.weixin.qq.com/s/DjzXpc-9oenmEKSXEJ74Qw</a></p><p>Optimization: 将Target Attention应用到长序列中，缓解GSU和ESU的gap。他通过改善Attention计算中的线性映射来对target attention进行加速</p><p>具体来说，TWIN将用户行为特征分为固有特征和交互特征，其中固有特征仍然按照$KQ^T&#x2F; \sqrt{d}$的方式计算注意力分数，其中$K_h W_h$是缓存起来的，直接查表获得；而Q的计算与序列长度无关，计算量不大；对于交互特征$K_c$, 直接使用维度较低的变换矩阵得到注意力分数</p><p><img src="/../article_img/lifelong/img6.png" alt="Behavior Feature Split"></p><p>TWIN框架图：<br><img src="/../article_img/lifelong/img7.png" alt="TWIN"></p><ol start="4"><li>TWIN V2: Scaling Ultra-Long User Behavior Sequence Modeling for Enhanced CTR Prediction at Kuaishou</li></ol><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/747198544">https://zhuanlan.zhihu.com/p/747198544</a></p><p>Optimization: 在TWIN工作的基础上，根据简单规则对长序列进行分组，再在每个组内进行层次聚类得到簇，用于降低序列长度（可以处理更长的用户序列）</p><p>需要注意的是，v2版本中的Target Attention的实现基本和TWIN类似, 但需要把原来的Item部分换成聚类。</p><p>TWIN-v2框架图：<br><img src="/../article_img/lifelong/img10.png" alt="TWIN v2"></p><ol start="5"><li>LREA: Efficient Long Sequential Low-rank Adaptive Attention for Click-through rate Prediction</li></ol><p> </p><p>论文链接：<a href="https://arxiv.org/pdf/2503.02542">https://arxiv.org/pdf/2503.02542</a> </p><p>参考链接：<a href="https://mp.weixin.qq.com/s/D_T5w7bF5DGn1m8VUfie4w">https://mp.weixin.qq.com/s/D_T5w7bF5DGn1m8VUfie4w</a></p><p>MLA参考链接：<a href="https://www.cnblogs.com/zrq96/p/18732985">https://www.cnblogs.com/zrq96/p/18732985</a></p><p>Optimization: 利用低秩矩阵分解来简化Target Attention计算</p><p>首先回顾下计算Target Attention的时间复杂度，将Target Item视为Q，用户行为序列视为K和V。记L为序列长度，B为target item个数，d为稠密向量维度。用户行为序列表示为$E_s \in R^{L \times d}$，target item表示为$E_t \in R^{1 \times d}$<br>$$ TA(E_s,E_t) &#x3D; E_s^T \odot AttScore(E_s, E_t) $$<br>其中，$E_s^T \in R^{d \times L}$, $AttScore(E_s, E_t) \in R^{L \times B}$.所以Target Attention在线上推理时的时间复杂度为O(L<em>B</em>d)  </p><p>关于模型中低秩矩阵的实现，由于数学过程有些繁杂，这里不再展开，它的功效在于计算target attention时，每个部分能够以低秩矩阵的形式参与计算，时间复杂度变成O(Brd)<br><img src="/../article_img/lifelong/img9.png" alt="低秩计算Attention"></p><p>LREA框架图：<br><img src="/../article_img/lifelong/img8.png" alt="LREA"></p><ol start="6"><li>LONGER: Scaling Up Long Sequence Modeling in Industrial Recommenders</li></ol><p>论文链接：<a href="https://www.arxiv.org/pdf/2505.04421">https://www.arxiv.org/pdf/2505.04421</a> </p><p>参考链接：<a href="https://mp.weixin.qq.com/s/c0dbmF1PdhJOcffRXzzS0Q">https://mp.weixin.qq.com/s/c0dbmF1PdhJOcffRXzzS0Q</a></p><p>Optimization: 不依赖中间阶段(GSU)，直接长序列建模。通过对tokens按时间顺序聚合，使用Cross Attention压缩长序列的方式来降低计算开销</p><p>作者设计了一个全局token放在序列开头，一方面用来稳定长序列的注意力机制，另一方面作为全局信息通过聚合整个上下文信号来影响其他token</p><p><strong>Tokens聚合：</strong> 作者将用户行为长序列按时间顺序每K个Item合并成一组, 这样合并后的序列长度则减少为$\frac{L}{K}$。相关效率分析可见参考链接</p><p><strong>Cross Attention:</strong> 作者从原始的长序列$H$中采样出$H_s$子序列作为部分Query序列，实验发现，直接使用最近的k个交互作为部分Query序列的策略效果最好。然后, 再在前面拼接Global Tokens的表征就得到最终的Query矩阵$O&#x3D;[G;H_s] \in R^{(m+k) \times d}$。 cross attention的具体计算如下：<br><img src="/../article_img/lifelong/img12.png" alt="Cross Attention"></p><p>LONGER框架图：<br><img src="/../article_img/lifelong/img11.png" alt="LONGER"></p><ol start="7"><li>DGIN: Deep Group Interest Network on Full Lifelong User Behaviors for CTR Prediction</li></ol><p>Optimization: 不依赖中间阶段，将完整的终身行为序列分组，通过统计信息和聚类特征分析组内行为，</p><p>DGIN框架图：<br><img src="/../article_img/lifelong/img13.png" alt="DGIN"></p>]]></content>
    
    
    
    <tags>
      
      <tag>Recsys</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>时间序列分解</title>
    <link href="/2025/05/27/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E8%A7%A3/"/>
    <url>/2025/05/27/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<h3 id="1-时间序列分解"><a href="#1-时间序列分解" class="headerlink" title="1. 时间序列分解"></a>1. 时间序列分解</h3><p>时间序列由两个组成要素构成：1、第一个要素是时间要素；2、第二个要素是数值要素。时间序列根据时间和数值性质的不同，可以分为<strong>时期时间序列</strong>和<strong>时点时间序列</strong>。</p><p>一般情况下，时间序列的数值变化规律有以下四种：长期变动趋势、季节变动规律、周期变动规律和不规则变动。</p><p><strong>长期趋势：</strong> 长期趋势指的是统计指标在相当长的一段时间内，受到长期趋势影响因素的影响，表现出持续上升或持续下降的趋势，通常用字母T表示</p><p><strong>季节变动：</strong> 由于季节的转变使得指标数值发生周期性变动，一般以月、季、周为时间单位，不能以年作单位，通常用S表示</p><p><strong>循环变动：</strong> 循环变动通常以若干年为周期，在曲线图上表现为波浪式的周期变动。这种周期变动的特征变现为增加和减少交替出现，通常用C表示</p><p><strong>不规则变动：</strong> 由某些随机因素导致的数值变化，这些因素的作用是不可预知和没有规律性的，因此对数值的变化影响变形为不规则变动， 通常用I表示</p><p>四种变动与指标数值最终变动的关系可能是<code>叠加关系</code>，也可能是<code>乘积关系</code>。</p><p>叠加模型：$Y&#x3D;T+S+C+I$<br>乘积模型：$Y&#x3D;T<em>S</em>C*I$</p><p>反映在具体的时间序列图上，如果随着时间的推移，序列的季节波动变得越来越大，则反映各种变动之间的关系发生变化，建议使用乘积模型；反之，如果时间序列图的波动保持恒定，则可以直接使用叠加模型。</p><h3 id="2-基于移动平均法的长期趋势分析"><a href="#2-基于移动平均法的长期趋势分析" class="headerlink" title="2. 基于移动平均法的长期趋势分析"></a>2. 基于移动平均法的长期趋势分析</h3><p>移动平均法的实质是通过对变量值进行平均的方法，对原来的时间数列进行修匀，以消除季节变动、不规则变动等其他因素对数列产生的影响。移动平均法又可以分为<code>简单移动平均</code>、<code>加权移动平均</code>和<code>指数平滑</code>三种形式。注意：移动平均法一般只适用于具有直线趋势的时间数列。</p><p><strong>（1）简单移动平均：</strong><br>步骤：1. 确定移动的项数k，即每次平均时所包含的变量值的个数 2. 从时间数列的第一个变量值开始，每次向后移动一项，分别计算出k个数值的序时平均数 3. 将计算出来的每个移动平均数的数值与它所对应的时间对应排列，编制成一个新的时间数列</p><p><img src="/../article_img/finance/img1.png" alt="三项平均示例"></p><p>应用移动平均法进行趋势分析有几个注意点：</p><p>1、应合理选择移动项数。移动项数越多，修匀效果越好，但新时间数列项数越少，不利于进行长期趋势分析；反之，移动项数越少新数列项数多，修匀效果不好。所以应根据所研究对象的具体特点，来确定移动的项数。如果原数列指标数值有周期性变化，应以周期的长度作为移动的项数。例如，季度资料作四项移动平均，月资料作十二项移动平均，这样可以消除周期性的季节影响。</p><p>2、利用平均法进行长期趋势分析时要有足够的资料，否则不能如实放映现象固有的变化趋势，这也是进行长期趋势分析的前提条件。</p><p>3、移动平均后的数值要与原数列时间对应。如果是奇数项，平均数落在中间项上，例如，进行3项移动平均，移动平均数落在第2项（(k+1)&#x2F;2）；如果是偶数项，平均数落在两项中间，还应进行项数为2的移动平均</p><p><img src="/../article_img/finance/img2.png" alt="四项平均示例"></p><p><strong>（2）加权移动平均法</strong></p><p>简单移动平均法每个观测值都用相同的权数，即假定过去各期的资料对预测期的影响程度相同。但在加权移动平均中，每个观测值被赋予相应的权重。例如，在大多数情况下，越近的资料应该有最大的权重，而较远的资料的权重较低。</p><p>示例：采用三项加权移动平均，最近时期观测值的权数为最远时期观测值的3倍，中间时期观测值的权数为最远时期的2倍</p><p><img src="/../article_img/finance/img3.png" alt="三项加权平均示例"></p><p><strong>（3）指数平滑法</strong></p><p>指数平滑法是加权移动平均法的一种特殊情形。只选择一个权数，即最近时期观测值的权数，其它时期数据值的权数可以自动推算出来，观测值离预测时期越远，它的权数就越小。模型定义如下：<br>$\hat{Y}_{i+1} &#x3D; \alpha Y_i + (1-\alpha) \hat{Y}_i$  其中$\alpha$为平滑系数，$1-\alpha$为阻尼系数，$Y_i$为实际值，$\hat{Y}_i$为预测值</p><p>现在根据包含三个时期资料的时间数列Y1，Y2和Y3，来说明任何时期指数平滑法的预测值，同样也是时间数列以前所有时期实际值的一个加权平均数。</p><p><img src="/../article_img/finance/img4.png" alt="指数平滑示例"></p><p>经验判断法：</p><p>1、当时间序列呈现较稳定的水平趋势时，应选较小的α值，一般可在0.05~0.20之间取值；</p><p>2、当时间序列有波动，但长期趋势变化不大时，可选稍大的α值，常在0.1~0.4之间取值；</p><p>3、当时间序列波动很大，长期趋势变化幅度较大，呈现明显且迅速的上升或下降趋势时，宜选择较大的α值，如可在0.6~0.8间选值，以使预测模型灵敏度高些，能迅速跟上数据的变化；</p><p>4、当是上升（或下降）的发展趋势类型，α应取较大的值，在0.6~1之间。</p><h3 id="3-季节变动分析"><a href="#3-季节变动分析" class="headerlink" title="3. 季节变动分析"></a>3. 季节变动分析</h3><p><strong>（1）同期平均法</strong><br><img src="/../article_img/finance/img5.png" alt="同期平均法示例"></p><p>缺点：但是这种方法计算的结果误差较大，因为这种方法没有考虑到长期趋势变化的影响</p><p><strong>（2）长期趋势剔除法</strong></p><p>先确定出各期的趋势值，然后再从观测值中扣除趋势值，从而测定季节指数。</p><p>示例：<br><img src="/../article_img/finance/img6.png" alt="示例"></p><p>将上面的数据做散点图：<br><img src="/../article_img/finance/img7.png" alt="散点图"></p><p>从图上看，虽然每年的数据起伏波动较大，但是这种波动具有明显的规律性，即每年第一季度和第三季度的销售量相对较低，而第二季度和第四季度的销售量相对较高，这说明销售量的变化受季节变动的影响。同时随着时间的推移，销售量又逐年增加，这说明销售量的变化也受长期趋势的影响。因而，为了准确的确定季节指数，就需要剔除长期趋势对销售量的影响，即应该采用长期趋势剔除法。分析步骤如下：</p><ol><li><p>对给定的数列先进行四项（以季为单位的资料）或十二项（以月为单位）的移动平均，从而消除不规则变动（I）和季节变动（S）影响，得到趋势分量（T）和循环分量（C）。<br><img src="/../article_img/finance/img8.png" alt="移动平均"><br><img src="/../article_img/finance/img9.png" alt="移动平均"><br><img src="/../article_img/finance/img10.png" alt="移动平均"></p></li><li><p>从原数列中扣除长期趋势和循环分量影响，分离出季节分量和不规则分量(S<em>I)： $S</em>I&#x3D;Y&#x2F;T*C$</p></li></ol><p>例如：2011年1月数据，S<em>I&#x3D;Y&#x2F;T</em>C&#x3D;1&#x2F;7.125&#x3D;14.04%；</p><p><img src="/../article_img/finance/img11.png"></p><p>3、从季节分量和不规则分量（S*I）中应用平均法消除由于偶然因素引起的不规则变动的影响，分离出季节指数（S）。</p><p>调整前季节指数：每年同一个月的均值，例如2011年1月，(67.02%+44.77%+68.93%+83.93%)&#x2F;4&#x3D;66.16%，即将季节分量和不规则分量经过简单平均消除不规则变动的影响后，分离出调整前季节分量。</p><p>调整后季节指数：从理论上说，如果没有季节因素影响，各期季节指数都应该是100%，12个月的季节指数之和应为1200%，实际为1198.13%，所以调整系数为：调整系数&#x3D;1200%&#x2F;1198.13%&#x3D;1.00016；然后用调整系数乘调整前季节指数得到调整后指数。</p><p>计算结果如下：<br><img src="/../article_img/finance/img12.png"></p><h3 id="4-循环变动分析"><a href="#4-循环变动分析" class="headerlink" title="4. 循环变动分析"></a>4. 循环变动分析</h3><p>循环变动是指<strong>一年以上</strong>的周期内，时间数列沿着长期趋势直线上下波动变化。循环变动分析过程如下：</p><p>1、首先将原始数据（按月、季、天等）构成的时间数列，调整为以年为单位的时间数列。因为在影响时间数列的四种因素中，季节变动是一年内的有规律变化，不影响其它年份，所以使用以年为周期的时间数列消除了季节变动影响，只反映长期趋势、循环变动和不规则变动的影响。</p><p>2、利用趋势方程确定长期趋势T。</p><p>3、不规则变动假定为随机变量，在一段时间上的变化总量趋于0.</p><p>4、确定循环变动C。</p><p>循环变动可以用趋势百分数表示，公式如下：</p><p>*<em>趋势百分数(C)&#x3D;实际观测值(Y)&#x2F;长期趋势值(T)<em>100%</em></em></p><p>示例:<br>某公司近9年的销售情况如下表：<br><img src="/../article_img/finance/img13.png" alt="示例"></p><p>用最小二乘法，计算过程可回顾：长期趋势分析，趋势方程为：T&#x3D;12.67+1.5X，其中T为长期趋势值。</p><p>可列出循环变动计算表：<br><img src="/../article_img/finance/img14.png" alt="循环变动分析"><br>可以看出，实际值围绕长期趋势直线波动幅度在74.96%至118.39%之间。用循环变动百分数可以描述过去循环变动的变化情况。但是由于影响循环变动的因素难以预料，所以不能进行未来推断。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Finance</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>初探金融：股票市场分析</title>
    <link href="/2025/05/27/%E8%99%9A%E6%8B%9F%E5%B8%81%E6%B1%87%E7%8E%87%E5%88%86%E6%9E%90/"/>
    <url>/2025/05/27/%E8%99%9A%E6%8B%9F%E5%B8%81%E6%B1%87%E7%8E%87%E5%88%86%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<p>参考链接：<br><a href="https://xueqiu.com/4657085399/276192743">https://xueqiu.com/4657085399/276192743</a>?</p><p><a href="https://zhuanlan.zhihu.com/p/678399088">https://zhuanlan.zhihu.com/p/678399088</a></p><ol><li>超买和超卖<br>✅ 超买（Overbought）<br>定义：资产价格在短时间内上涨过快，超过了其实际价值，存在回调或下跌的风险。</li></ol><p>特点：1. 多头情绪过于强烈。 2. 通常表示市场短期内涨得太多、太快。 3. 可能出现价格见顶或调整的信号。</p><p>例子：RSI（相对强弱指数）高于 70 常被认为是超买。</p><p>✅ 超卖（Oversold）<br>定义：资产价格在短时间内下跌过快，低于其实际价值，存在反弹或上涨的机会。</p><p>特点：1. 空头情绪过于强烈。 2. 通常表示市场短期内跌得太多、太快。 3. 可能出现价格触底或反弹的信号。</p><p>例子：RSI 低于 30 常被认为是超卖。</p><ol start="2"><li>蜡烛线（K线）<br><img src="/../article_img/Coin/K%E7%BA%BF%E5%9B%BE.png" alt="K线图"></li></ol><p>K线图以时间为横轴，价格为纵轴。每个交易日绘制一根蜡烛线，蜡烛线的实体表示开盘价和收盘价之间的范围，蜡烛线的上影线表示最高价，下影线表示最低价。若收盘价高于开盘价，蜡烛线实体为红色，表示价格上涨；若收盘价低于开盘价，蜡烛线实体为绿色，表示价格下跌。 此外，还有一种“十字线”，其开盘价 $\approx$ 收盘价，实体非常小，上下影线可以长也可以短。</p><p>分析:<br>(1) 实体大小表示内在动力和趋势的强弱<br><strong>实体较大：</strong> 表示该时间周期内价格波动较大，多空双方争夺激烈，可能预示着市场的不确定性和波动性</p><p><strong>实体较小：</strong> 表示该时间周期内价格波动较小，多空双方力量相对平衡，市场可能在一个相对稳定的阶段</p><p>(2) 影线长短反映转折意愿<br><strong>影线较长：</strong> 表示该K线周期内存在较大的阻力或支撑，多空双方在这个价位附近争夺激烈。影线越长，说明价格波动的幅度越大，可能预示着市场波动性和不确定性。</p><p><strong>影线较短：</strong> 表示该K线周期内阻力或支撑较弱，多空双方在这个价位附近的争夺相对不激烈。影线较短，说明价格波动的幅度较小，市场可能在一个相对稳定的阶段</p><ol start="3"><li>KDJ线<br>一种衡量超买超卖的技术指标，包含三条线：K线、D线和J线</li></ol><table><thead><tr><th>名称</th><th>含义</th><th>反应速度</th><th>取值范围</th></tr></thead><tbody><tr><td>K线</td><td>快速线，反应当前价格的变动趋势</td><td>快速</td><td>0 ~ 100</td></tr><tr><td>D线</td><td>慢速线，K线的移动平均，更平滑</td><td>较慢</td><td>0 ~ 100</td></tr><tr><td>J线</td><td>超速线，反映K线和D线之间的偏离程度（动量）</td><td>非常敏感（容易剧烈波动）</td><td>可超过 0 ~ 100（可大于100或小于0）</td></tr></tbody></table><p>三条线的计算逻辑：</p><p>$RSV &#x3D; \frac{(C-L_n)}{(H_n-L_n)} \times 100$<br>其中C：当日收盘价 $L_n$: n日内最低价 $H_n$: n日内最高价 </p><p>K值：$K&#x3D;\frac{2}{3} \times K_{前一日} + \frac{1}{3} \times RSV$</p><p>D值：$D&#x3D;\frac{2}{3} \times D_{前一日} + \frac{1}{3} \times K$</p><p>J值：$J&#x3D;3\times K - 2\times D$</p><table><thead><tr><th>情况</th><th>含义</th></tr></thead><tbody><tr><td>K、D、J 都在 80 以上</td><td>超买区域，可能回调或下跌</td></tr><tr><td>K、D、J 都在 20 以下</td><td>超卖区域，可能反弹或上涨</td></tr><tr><td>K线上穿D线（“金叉”）</td><td>可能是买入信号</td></tr><tr><td>K线下穿D线（“死叉”）</td><td>可能是卖出信号</td></tr><tr><td>J值大于100或小于0</td><td>过热或过冷，注意反转风险</td></tr></tbody></table><ol start="4"><li>相对强弱指数RSI<br>用于衡量资产在一定时间内价格上涨与下跌的强度对比，帮助判断市场是否处于超买或超卖状态</li></ol><p>RSI-14: $RSI &#x3D; 100 - (\frac{100}{1+RS})$<br>其中：$RS &#x3D; \frac{\text{平均上涨幅度}}{\text{平均下跌幅度}}$</p><table><thead><tr><th>RSI 数值区间</th><th>含义</th><th>可能操作建议</th></tr></thead><tbody><tr><td>70 ~ 100</td><td>超买区，可能回调</td><td>考虑卖出或观望</td></tr><tr><td>50</td><td>多空平衡</td><td>观望或等待信号</td></tr><tr><td>0 ~ 30</td><td>超卖区，可能反弹</td><td>考虑买入或关注</td></tr></tbody></table><ol start="5"><li>移动平均线MA<br>将一定时间段内的收盘价（或其他价格）进行平均，按时间平滑连接，形成的曲线</li></ol><table><thead><tr><th>类型</th><th>全称</th><th>特点</th></tr></thead><tbody><tr><td><strong>SMA</strong></td><td>简单移动平均（Simple MA）</td><td>各周期价格权重相等</td></tr><tr><td><strong>EMA</strong></td><td>指数移动平均（Exponential MA）</td><td>越靠近当前时间的价格权重越大，更敏感</td></tr><tr><td><strong>WMA</strong></td><td>加权移动平均（Weighted MA）</td><td>给不同价格不同权重，按设定衰减或强化</td></tr></tbody></table><table><thead><tr><th>周期</th><th>常见名称</th><th>用途</th></tr></thead><tbody><tr><td>MA5</td><td>5日均线</td><td>短期趋势，快速反应</td></tr><tr><td>MA10</td><td>10日均线</td><td>短期趋势确认</td></tr><tr><td>MA20</td><td>20日均线</td><td>中期趋势参考</td></tr><tr><td>MA60</td><td>60日均线</td><td>中长期趋势</td></tr><tr><td>MA120 &#x2F; MA250</td><td>年线级别</td><td>趋势稳定区判断（牛熊分界线）</td></tr></tbody></table><ol start="6"><li>移动平均汇聚&#x2F;散发指标（MACD）<br>由<code>DIF(快线)</code>、<code>DEA(慢线)</code>、<code>MACD柱</code>三部分组成，其中DIF表示由短期EMA与长期EMA的差值；DEA表示DIF的平滑移动平均(常为9日)；MACD柱表示DIF与DEA的差值的2倍，显示为红绿柱状图</li></ol><p>计算EMA:</p><p>短期EMA(一般取12日):$EMA_{12}(t)&#x3D;EMA_{12}(t-1) \times \frac{11}{13} + P(t) \times \frac{2}{13}$</p><p>长期EMA(一般取26日):$EMA_{26}(t)&#x3D;EMA_{26}(t-1) \times \frac{25}{27} + P(t) \times \frac{2}{27}$</p><p>计算DIF: $DIF&#x3D;EMA_{12}-EMA_{26}$</p><p>计算DEA: $DEA&#x3D;DIF的9日EMA$</p><p>计算MACD: $MACD&#x3D;2 \times (DIF-DEA)$</p><ol start="7"><li>前复权&#x2F;后复权&#x2F;不复权<br>股票历史价格数据处理中的三种方式，主要用于处理股票除权除息（比如分红、配股、送股）带来的价格跳变问题，使得历史价格具有可比性</li></ol><p><strong>不复权：</strong> 直接使用交易所公布的历史股价数据，没有对除权除息做任何处理</p><p><strong>前复权：</strong> 以当前（最近）的价格为基准，对历史价格进行调整，消除了除权除息带来的价格跳变，使得历史股价更低</p><p><strong>后复权：</strong> 以最初的价格为基准，对后续的价格进行调整，保留历史价格不变，调整当前价格使得走势连贯</p><table><thead><tr><th>类型</th><th>调整基准</th><th>用途偏好</th><th>特点说明</th></tr></thead><tbody><tr><td>不复权</td><td>无调整</td><td>查看真实历史价格</td><td>会出现价格“跳空”</td></tr><tr><td>前复权</td><td>当前价格</td><td>技术分析</td><td>历史价格被调整成更低</td></tr><tr><td>后复权</td><td>历史价格</td><td>回测投资收益</td><td>当前价格被调整成更高</td></tr></tbody></table><ol start="8"><li>换手率<br>换手率是股票市场中的一个重要指标，用来衡量一段时间内股票的流通活跃程度，反映市场上该股票的“受欢迎程度”或“热度”</li></ol><p>公式：换手率 &#x3D;（某段时间内成交的股票数量 ÷ 流通股总数）× 100%</p>]]></content>
    
    
    
    <tags>
      
      <tag>Finance</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Explainable Recommendation Related Work</title>
    <link href="/2025/05/10/Explanation%20Recommendation/"/>
    <url>/2025/05/10/Explanation%20Recommendation/</url>
    
    <content type="html"><![CDATA[<p>写在前面： 最近在肝两篇关于可解释推荐的论文，下面是写intro的过程中对related work发展脉络的一点总结</p><span id="more"></span><ol><li><p>Neural Rating Regression with Abstractive Tips Generation for Recommendation (NRT)<br>（使用GRU架构进行多任务可解释推荐）<br>除了预测给定用户和目标的评级以外，模型还可以简洁的句子自动解释为tips（这里的Tips类似于Explanation，作者将其描述为“比评论更简洁，只需几句话就可以解释用户体验、感受和建议”）<br>对于Tips的生成，作者采用GRU将user和item的潜在特征表示“翻译”为一个简洁的句子；对于评分预测，作者采用多层感知器将user和item的潜在特征表示映射到评分中<br><img src="/../article_img/Explain-Recsys/img3.png" alt="NRT Framework"></p></li><li><p>Learning to Generate Product Reviews from Attributes (Att2Seq)<br>（使用LSTM架构进行多任务可解释推荐）<br>作者提出了一种注意力增强的属性到序列模型，用于为给定的属性信息生成解释。属性编码器学习将输入属性表示为向量，序列解码器通过根据这些向量调节其输出来生成评论。此外，作者还引入了一个注意力层，注意力机制学习生成的单词和属性之间的软对齐，并自适应地计算用于预测下一个标记的编码器端上下文向量。<br><img src="/../article_img/Explain-Recsys/img4.png" alt="Att2Seq Framework"><br>下面是关于注意力机制的工作机理：<br><img src="/../article_img/Explain-Recsys/img5.png" alt="Attention Augmentation"></p></li><li><p>Personalized Transformer for Explainable Recommendation (PETER)<br>（使用Transformer架构进行多任务可解释推荐）<br>解决的问题：使用用户和商品ID进行个性化推荐，但是Transformer建模时无法理解该ID所蕴含的语义。论文提出了一个可解释推荐框架PETER，利用ID来预测目标解释的单词</p></li></ol><p>传统的基于Transformer的ID建模是将ID视为单词，但是ID的出现频率远低于单词，导致模型对ID不敏感，当为用户-商品生成解释的时候，Transformer的Attention-Map更关注<bos> token，而不是user和item id。为了克服这一问题，作者修改了注意力掩码矩阵，设计了一种集解释生成、上下文预测和推荐的多任务学习框架PETER。<br><img src="/../article_img/Explain-Recsys/img1.png" alt="PETER Framework"></p><p>关于ID的OOV问题，作者没有将海量的ID放入词表当中，而是对每个ID执行embedding lookup。此外，作者更改了Transformer的Attention Mask Metrics, 让uid token和iid token可以互相关注,这在上下文预测和推荐任务中会使用到<br><img src="/../article_img/Explain-Recsys/img2.png" alt="Attention Mask for user-item id"></p><p>总结：</p><ol><li><p>Att2Seq 和 NRT 采用注意力机制和递归神经网络（RNN）来生成文本解释。最近的进展进一步探索了Transformer在文本生成中的利用，为推荐结果提供了有价值的见解。然而，这些方法面临着一个共同的挑战，即解释数据的可用性有限，这阻碍了它们生成高质量解释的能力。同样重要的是要强调，基于ID的方法严重依赖ID嵌入，导致泛化能力有限，并且在适应冷启动推荐场景中新增加的用户和项目时存在困难。</p></li><li><p>在主干模型的演化上，随着自然语言生成技术的进步，一些研究采用了递归神经网络、门控递归单元、未预训练的 Transformer 和预训练的语言模型 来生成解释。预训练的大型语言模型最初在 PEPLER 中引入，以提高解释生成的性能。尽管 PEPLER 通过 GPT-2 利用基于提示的迁移学习，但它无法以适合指令调整的方式构建训练数据，从而限制了系统产生高质量解释的能力。</p></li></ol><p>评分-解释一致性推荐的相关工作：</p><ol><li><p>The Problem of Coherence in Natural Language Explanations of Recommendations (CER)<br>Challenge:生成的文本和预测评级之间的连贯性是解释有用的必要条件。目前可解释推荐的方法主要基于深度神经模型，相比于早期基于预定义句子模板的方法可以产生更丰富、更流畅的文本解释。然而，这些方法主要考虑如何提高生成的文本质量，却忽视了文本解释和预测评级之间缺乏连贯性的问题,这将大大削弱系统的可信度。<br>贡献：(1) 开发了一种自动化评估rating-explanation一致性的方法 (2) 在PETER的基础上提出了一个新的可解释推荐系统，以自然语言生成个性化和一致的解释<br><img src="/../article_img/Explain-Recsys/img6.png" alt="CER Framework"><br>评估方法：首先人工采集、注释rating-explanation数据，然后进行二元分类训练作为一致性评估器<br>缺陷：(1) CER使用Transformer作为backbone，这限制了生成性能 (2) CER对生成解释的评分估计依赖于预训练词嵌入的最大池化，这无法捕获丰富的上下文信息</p></li><li><p>Coherency Improved Explainable Recommendation via Large Language Model (CIER)<br>Challenge:目前的可解释推荐工作采用多任务学习的模式，通过共享隐藏表示层但拥有独立的输出层。这种训练方式会产生不一致的解释。<br>创新: (1) 使用LLM作为主干模型来预测评级并生成解释 (2) 采用next-token prediction的方式来生成评级和解释<br>评估方法: 使用GPT4和预训练的情感分析模型来评估连贯性。<br><img src="/../article_img/Explain-Recsys/img7.png" alt="CIER Framework"></p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Paper</tag>
      
      <tag>Recsys</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>&lt;ETH&gt; The DAO、反思、美链</title>
    <link href="/2025/05/01/ETH_4/"/>
    <url>/2025/05/01/ETH_4/</url>
    
    <content type="html"><![CDATA[<p>写在前面：<br>前段时间把b站上北大肖老师的区块链课程速通了一遍，这里引一下csdn上的优质课程笔记，便于个人后续温习。<br>博客链接：<a href="https://blog.csdn.net/qq_40378034/category_11862943.html">https://blog.csdn.net/qq_40378034/category_11862943.html</a><br>课程链接：<a href="https://www.bilibili.com/video/BV1Vt411X7JF/">https://www.bilibili.com/video/BV1Vt411X7JF/</a></p><span id="more"></span><h4 id="10、ETH-The-DAO"><a href="#10、ETH-The-DAO" class="headerlink" title="10、ETH-The DAO"></a>10、ETH-The DAO</h4><h5 id="1）、The-DAO"><a href="#1）、The-DAO" class="headerlink" title="1）、The DAO"></a>1）、The DAO</h5><p>比特币实现了去中心化的货币，以太坊实现了去中心化的合约，有人想既然去中心化这么好，为什么不把所有的东西都改成去中心化呢？有人提出口号：let’s decentralize everything。<strong>DAO</strong>（<strong>Decentralized Autonomous Organization，去中心化的自治组织</strong>）就是在这个背景下产生的。传统社会中，组织都是建立在某种法律文件基础上的，比如说可以有个章程规范组织的行为，有时候还可能到政府登记注册。那DAO就是把组织的规章制度写在代码里，通过区块链的共识协议来维护这种规章制度的正常执行</p><p>在2016年5月，出现了一个<strong>致力于众筹投资的DAO</strong>，它的名字为<strong>The DAO</strong>。DAO是一个通用的概念，凡是去中心化的自治组织都可以称为DAO，The DAO是指具体的这个DAO，它的工作原理有点像众筹的投资基金，本质是运行在以太坊上的一个智能合约。如果你想参与The DAO，那你可以把以太币发给这个智能合约，然后可以换回The DAO的代币。需要决定投资哪个项目的时候，是大家投票决定的，手里的代币越多，投票的权重越大，最后有了收益也是按照智能合约中制定的规章制度进行分配的</p><p>工作原理有点像DAC（Decentralized Autonomous Corporation）去中心化的自治公司，一般来说，DAC是出于盈利目的，DAO的话可以是出于非盈利性目的，比如某种公益事业。DAC虽然有公司这个词，但是在现实社会中，它没有公司应有的法人地位，一般来说也没有像董事长、CEO这样的职务</p><p>The DAO 2016年5月份开始众筹的时候在当时受到了很大的关注度，因为以前从来没有这样民主的投资基金，一个月的时间筹集到了当时价值1.5亿美元的以太币。当时媒体都在预测，未来几年The DAO的影响里会有多么多么的大，有的人甚至说在3到5年以后The DAO的影响力甚至会超过以太坊本身。遗憾的是，The DAO一共只存活了3个月</p><p><strong>如果你是The DAO的投资者，你怎么取回自己的收益，比如你参与The DAO，投了一笔以太币过去，换回一些The DAO的代币，过一段时间你需要用钱了，想把以前投资的以太币换回来，怎么办？</strong></p><p>这个在The DAO的基金里是通过拆分的方式实现的，叫做：split DAO。拆分的做法不止是取回自己的收益，也是一种建立子基金的方式，拆分完之后得到一个child DAO</p><p>设计理念是这样的，The DAO投资项目是靠大家手里的代币去投票，如果有一小部分人他的投资理念和其他人不一样怎么办。这一小部分人可以用拆分的办法从The DAO独立出来，成立一个自己的子基金，叫做child DAO。拆分的时候，他们手中的代币会被收回，换成相应数量的以太币，把相应的以太币打到子基金里，然后他们就可以投自己想投的项目了。拆分的一个极端例子就是单个的投资者成立一个子基金，然后在子基金里就可以把所有的钱投给他自己，这是投资者取回投资和收益的唯一途径。拆分之前有7天的辩论期，拆分完之后有28天的锁定期，就是这28天的锁定期给了后面事故中的补救时间</p><p>拆分的理念并没有错，而且是民主制度的进一步体现，民主制度并不是绝对的少数服从多数，而是说也要尊重少数人选择的权力。拆分的理念没有错，那问题出在哪里呢？<strong>问题就出在split DAO的实现上</strong></p><p><img src="/../article_img/Web3/img7-1.png"></p><p>上图是split DAO的代码，从withdrawRewardFor这个语句开始，首先把钱还给调用这个函数的人，然后把The DAO中的总金额减少相应的数量，再把调用者的账户清0。在上一节讲过，正确的操作是先把账户清0，然后再转账。黑客就是利用这个漏洞进行的重入攻击，转走了5千万美元的以太币，差不多 1 3 \frac{1}{3} 31​</p><p><strong>这件事情在以太坊社区引起了很大的恐慌，引起了币价的大跳水。以太坊社区对此进行了激烈的讨论，该怎么办？</strong></p><p>社区的意见分裂为两派：</p><p>一派认为，要回滚交易，成立的子基金有28天的锁定期，所以黑客暂时还没有办法取走以太币，还有时间可以采取补救措施</p><p>另一派认为，不需要做任何补救措施，因为黑客的行为没有违法，code is law。在疑似黑客的公开信中，黑客声称自己没有做错任何事情，只是利用了代码中的feature，既然代码里写的可以让我重复多次取钱，我就没有违反任何法律。这方认为，不应该回滚交易，区块链最重要的特性是不可篡改性，如果出了问题就回滚，怎么能叫不可篡改呢。而且这次出问题的只是以太坊上的一个应用而已，以太坊本身的代码没有问题，如果每个智能合约出了问题都回滚的话，不就乱套了吗</p><p><strong>以太坊的开发团队是支持采取补救措施的，主要是这个事情的影响太大了，The DAO筹集的以太币数目已经占到了当时以太币总流通量的百分之十几。too big too fail，太大了以至于不能倒。那现在怎么补救呢？</strong></p><p><img src="/../article_img/Web3/img7-2.png"></p><p>比如说从黑客盗取以太币的区块的前一个区块开始分叉，让分叉链更长，这样行不行。如果这样，不光是黑客的交易回滚了，区块上所有的交易都回滚了，会影响大量正常交易的人，所以这样做是不行的</p><p><strong>要回滚的话只能是精确定位，只能是针对黑客盗取以太币的那些交易，其他发生的正常交易不能受到影响</strong>。怎么操作呢？以太坊的团队制度了两步走的方案。第一步，首先要锁定黑客的账户。第二步，把盗取的以太币设法退回去，清退The DAO基金上的这些钱</p><p>第一步，怎么锁定这些账户。以太坊团队发布了一个软件升级，增加了一条规则，凡是和The DAO这个基金上的账户相关的，不能做任何的交易。许多矿工都升级了软件。这个是软分叉，软件升级是增加了一条判断的规则，新矿工挖出来的区块，旧矿工是认可的，旧矿工可以继续在这个区块后来开始挖，旧矿工挖出来的区块，新矿工有可能不认可，如果这个区块里包含了The DAO账户的交易，新账户就不认可，这样对系统只会造成临时性的分叉</p><p>遗憾的是，升级的软件有个问题，那就是判断是否和The DAO相关的交易这个步骤还要不要收取汽油费，如果不收取的话，可能有恶意的攻击者不断的发放非法的交易，拒绝服务（deny of service），浪费矿工的资源，反正对攻击者来说成本很低。<strong>以太坊的这个升级没有收汽油费，受到了deny of service，矿工之后就受不了了，纷纷重新使用升级前的软件。于是软分叉的方案失败了</strong></p><p>这个时候形式严峻了，子基金成立之后有28天的锁定期，然后黑客就可以把钱取走了，软分叉的方案失败了，剩余的时间不多了。以太坊团队想软的既然不行，那就来硬的了，<strong>设计了一个硬分叉的方案，通过软件升级的方法，把The DAO账户上的所有资金强行转到另外一个新的智能合约上去，新的智能合约就只有一个功能，那就是退钱</strong>，当初是用以太币买的The DAO的代币，现在可以把代币退回成以太币</p><p>这个为什么是硬分叉？这种做法的本质是用软件升级的方法强行重新记账，本来的转账是要有合法的签名，比如说我要把你账上的钱转走，需要有你的签名才行，而这个升级的转账是没有合法的签名的，凡是The DAO上面的资金不管本人是否同意都要强行转到新的智能合约上去，挖到第192万个区块的时候，自动执行这条交易。新矿工挖出来的区块，旧矿工是不认可的，所以是个硬分叉</p><p>由此，社区彻底分成了两派，以太坊团队还写了一个智能合约来进行投票，用手中的以太币去投票，结果显示大多数人支持硬分叉，于是绝大数矿工升级了软件。<strong>最后硬分叉没有出现意外，成功了</strong></p><h5 id="2）、ETH和ETC"><a href="#2）、ETH和ETC" class="headerlink" title="2）、ETH和ETC"></a>2）、ETH和ETC</h5><p>但故事没有结束，反对者认为，参与投票的人并不是很多，此外，投票的结果就一定是正确的吗？旧的那条链并没有消亡，还有矿工在上继续挖，算力大幅度下降，不到原来的 1 10 \frac{1}{10} 101​，挖矿难度大幅度下调。<strong>旧链上挖出来的币叫做ETC</strong>（<strong>Ethereum Classic，经典以太坊</strong>），并在交易所上市交易了。一部分人挖是由于投机，一部分人挖则是出于信仰，坚持这种纯而又纯的去中心化理念，认为旧链才是正宗的以太坊，根正苗红，那些搞硬分叉的是在搞修正主义</p><p>刚开始硬分叉的时候带来了一些问题，比如重放攻击，在新链上的合法交易放到旧链上去同样是合法的，反过来旧链上的合法交易放在新链上也是可以执行的。后来给两条链增加了chainID来解决</p><p><strong>为什么针对的都是The DAO中所有的账户，而不只是对应黑客的账户？</strong></p><p>如果只冻结黑客的账户，由于合约的bug修不了，那人人都可以成为黑客去继续盗取，所以必须把与The DAO相关的所有账户都冻结了</p><h4 id="11、ETH-反思"><a href="#11、ETH-反思" class="headerlink" title="11、ETH-反思"></a>11、ETH-反思</h4><h5 id="1）、智能合约的反思：智能合约真的智能吗？-Is-smart-contract-really-smart"><a href="#1）、智能合约的反思：智能合约真的智能吗？-Is-smart-contract-really-smart" class="headerlink" title="1）、智能合约的反思：智能合约真的智能吗？(Is smart contract really smart?)"></a>1）、智能合约的反思：智能合约真的智能吗？(Is smart contract really smart?)</h5><p>首先我们必须了解智能合约里面并没有用到任何人工智能的技术，所以有人认为应该把它叫做自动合约，按照事先写好的代码，自动执行某些操作，现实世界当中，有什么自动合约的例子吗？ATM取款机可以看作物理世界上的一个自动合约，按照事先规定好的逻辑去做某些事情。所以智能合约其实并不智能，而且挺笨的，一旦写好了之后就改不了了，就是作为代码合同（Smart contract is anything but smart）</p><h5 id="2）、不可篡改性是把双刃剑（Irrevocability-is-a-double-edged-sword）"><a href="#2）、不可篡改性是把双刃剑（Irrevocability-is-a-double-edged-sword）" class="headerlink" title="2）、不可篡改性是把双刃剑（Irrevocability is a double edged sword）"></a>2）、不可篡改性是把双刃剑（Irrevocability is a double edged sword）</h5><p>一般来说我们提到区块链的不可篡改性都认为这个是区块链的一个优点，很多区块链的应用都利用了不可篡改的特性，比如防伪、溯源。但是从The DAO事件当中，可以看出不可篡改性其实是一个双刃剑。一方面，不可篡改性增加了合约的公信力，但另一方面，不可篡改性也意味着如果规则中有漏洞，我们想要修补这个漏洞，想软件升级都是很困难的。The DAO的盗币事件有传闻说The DAO的开发团队在发生盗币事件前几天已经收到了有关智能合约中存在安全漏洞的消息，但是没有来得及发布更新后的软件。这个如果是对于一个中心化的系统，大家可能会觉得是很难想象的，如果你发现你的软件中的安全漏洞，你干嘛不及时发布一个安全补丁呢。但是问题在于在区块链的世界里你怎么发布补丁，软件更新需要硬分叉来实现，还需要得到大部分矿工的支持。无论是比特币还是以太坊，硬分叉都不是随便搞的，这次以太坊搞的硬分叉，最后就造成了两条平行的链，而且要搞硬分叉要说明理由，否则别的矿工为什么要升级你的软件，而你一旦说明理由的话，那就会把安全漏洞的信息泄露出去，那么有恶意的攻击者在还没有来得及升级软件之前抢先发动攻击，这些都是区块链上不可篡改性带来的一些问题</p><p>不可篡改性还导致另一个问题，即使我们发现了这个安全漏洞，已经有人进行恶意攻击了，我们想要冻结账户，终止交易都是很困难的。这个和我们日常生活的体验不太一样的地方，比如说你的银行卡的信息被泄露了，第一反应是通知银行，冻结账户，修改密码。很多人在刚接触区块链的时候也是同样的反应，发现比特币账户的私钥泄露出去了，怎么办，赶紧通知谁把账户给冻结了，没有办法冻结，要冻结的话只能软分叉，实质上要发布一个软件更新，有关要冻结的账户的交易都不予执行，这才可以冻结，对于个人来说，你的私钥泄露出去了搞一个软分叉，这是不可能的，对于普通人只能尽快将剩下的资金转到安全账户</p><p>与之相关的一个问题，智能合约发布到区块链上就无法阻止别人对它的调用，比如说这次的盗币事件，黑客偷走了差不多 1 3 \frac{1}{3} 31​的以太币，还有 2 3 \frac{2}{3} 32​的以太币还在The DAO相关的子基金里，同样存在着安全的风险。我们传统直观的认为，智能合约出问题了，那就不能让别人去调用它了。但在区块链上你没办法组织别人对它的调用，你要阻止的话又要软分叉，增加一条新的规则，凡是调用这个智能合约的交易都不予执行。所以还剩的 2 3 \frac{2}{3} 32​的资金也应该及时转走，怎么转走？利用黑客的这个漏洞把钱转走。当时就有人建议这么做的，比如说你是个好人，你创建一个新的智能合约，把这个事情公布给大家，说现在要利用黑客的漏洞把剩下的钱转移到安全的智能合约，手段和重入攻击是一样的，只不过你的目的是好的，这个新的合约的目的是将来把钱退给大家</p><h5 id="3）、没有什么是真的不可篡改的（Nothing-is-irrevocability）"><a href="#3）、没有什么是真的不可篡改的（Nothing-is-irrevocability）" class="headerlink" title="3）、没有什么是真的不可篡改的（Nothing is irrevocability）"></a>3）、没有什么是真的不可篡改的（Nothing is irrevocability）</h5><p>理论上，没有什么是绝对不可篡改的，比如分叉攻击可以回滚交易。The DAO事件中，以太坊开发团队通过软件升级方式强行改变了某些账户的状态，所以不能迷信不可篡改的特性。毕竟代码是死的人是活的，没有什么是绝对改不了的，连宪法都可以修宪，比如美国的宪法修正案，修宪是很难的，但是有必要的时候还是可以改的。区块链上是一样的，想要篡改是比较难的，但是遇到重大事件，要是想改还是改的了的</p><h5 id="4）、合约语言设计的反思（Is-solidity-the-right-programming-language-）"><a href="#4）、合约语言设计的反思（Is-solidity-the-right-programming-language-）" class="headerlink" title="4）、合约语言设计的反思（Is solidity the right programming language?）"></a>4）、合约语言设计的反思（Is solidity the right programming language?）</h5><p>为什么会出现重入攻击这样的事情，从某种意义上来说，Solidity语言上有一些反自然的特性，我们一般的理解是我给你转账，你是一个被动的接收者，你不可能再回来调用我。但Solidity语言的特性是，我给你转账等于调用了你的<code>fallback()</code>函数，虽然表面上我没有调用任何的函数，结果你还可以倒过来调用我。这个和平时的生活体验不一样，所以容易忽视这样的安全漏洞</p><p>有人提议应该改进为函数式编程语言，这样比较安全，不容易出现漏洞，而且从长远来看，要实现理论上证明智能合约的正确性。如果能够用形式化验证（formal verification）的方式，证明一段程序的正确性，那么将能够解决智能合约的漏洞问题，这个有些人曾经认为是智能合约的一个终极目标。但是形式化验证距离实用仍有很大的距离，一般只能证明一些逻辑简单的正确性，而且在证明过程要屏蔽掉很多实现上的细节，这样导致的结果就是即使这个程序从理论上可以证明的正确的，实际跑起来可能仍然有问题。从语言设计上来说，Solidity有很多值得改进的地方，但是不是说我们就该用函数式编程语言，就应该用formal proof的方法证明程序的正确性，这个还有待探讨</p><p>语言设计上的第二个反思是，编写智能合约的语言应该有什么表达能力。我们前面讲过比特币和以太坊的区别，比特币的脚本语言就是很简单的，表达能力很差，而以太坊的编程语言是图灵完备的，凡是计算机能完成的任务，语言都能实现，但是图灵完备的表达能力是不是一个好事情。出现智能合约的漏洞后，有些人认为，应该选取一种表达能力适中的语言，它可以实现智能合约的功能，又不容易出现漏洞。但是难以设计出适当的语言，因为设计语言的时候很难预料将来所有可能出现的所有应用场景，也很难预料将来可能出现的所有安全攻击</p><p>我们说比特币脚本是很简单的，但在实际应用中大部分矿工也只是接收几个常用的脚本，有一个安全脚本的白名单，如果交易的脚本不在白名单里面，很多矿工缺省情况下是不接受的。联想到现实中的合同，也会出现由于不严谨出现一些纠纷，所以通常使用模板写合同来规避这些问题。智能合约可以参考这种在模板基础上书写合约的方法，以后应该也会出现类似写智能合约的专门机构。所以大家不要对智能合约出现了各种各样的问题就对它丧失信心，智能合约的历史相对来说比较短的，最终还是会走向成熟</p><h5 id="5）、开源软件漏洞的反思（Many-eyeball-fallacy）"><a href="#5）、开源软件漏洞的反思（Many-eyeball-fallacy）" class="headerlink" title="5）、开源软件漏洞的反思（Many eyeball fallacy）"></a>5）、开源软件漏洞的反思（Many eyeball fallacy）</h5><p>去中心化的系统一般都是开源的，因为需要所有节点执行同样的操作，才能达成共识。开源的一个好处就是增加合约的公信力，接受群众的监督；有人认为另一个好处是不容易出现安全漏洞，因为全世界有这么多双眼睛在看着这个代码，但实际情况并不如此，我们也看到了智能合约的代码出现了各种各样的漏洞，而且这个问题不是智能合约所特有的，其他开源的软件也有类似的问题。那全世界有这么多双眼睛看着为什么还出现了这么多漏洞？</p><p>理论上代码是开源的，但实际上去研究代码的人是很少的，像The DAO这样涉及到财产安全的项目，你要把你的钱投进去，投钱之前是不是需要检查下这个智能合约靠不靠谱，但是很多人都没有仔细看，看的人可能也没有足够的安全知识去检测里面的安全漏洞。有很多手机上的区块链钱包也是开源的，也是涉及到财产安全的，那么有多少人是去看了钱包的源代码的，有多少是看的懂的，大家都认为别人一定看过了，实际上可能没有谁认真看过，所以不要认为开源软件一定比不开源的软件安全，有很多人用的软件也不一定没有安全漏洞，历史上有很多开源软件的安全漏洞是很多年后发现的。所以这些关键性应用我们还是要小心仔细，需要自己去检查下智能合约是否有安全问题</p><h5 id="6）、去中心化的反思（What-does-decentralization-mean-）"><a href="#6）、去中心化的反思（What-does-decentralization-mean-）" class="headerlink" title="6）、去中心化的反思（What does decentralization mean?）"></a>6）、去中心化的反思（What does decentralization mean?）</h5><p>区块链技术的追随者一般都是去中心理念的拥护者，这些人对于现实生活中中心化的管理方式不满意，所以在区块链的世界中去寻找一种全新的管理方式。这也是为什么以太坊开发团队在推出了硬分叉的解决方案后引发了这么大的争议，有很多人认为又回到了中心化的老路上面，你开发团队凭什么用一个软件升级就把一个人账上的钱转走，这个岂不是比中心化更中心化，在中心化的社会里要没收一个人的财产还需要通过法律各种各样的程序，28天以内还不一定能完成</p><p>但是回想一下这个硬分叉的过程，是不是就是以太坊的开发团队说的算的。首先他们搞了一个投票，最后是大部分人投票支持硬分叉，但是更重要的是以太坊的团队是没有办法强迫大家支持这个投票结果，最后硬分叉能够成功是因为90%以上的矿工升级了软件，用行动支持了硬分叉，即使是这样还有少部分的矿工不支持硬分叉的方案，继续留在旧链上挖矿，那也是他们的自由，以太坊的团队没有什么办法强制他们转过来。所以说去中心化并不是说全自动化，让机器决定一切，不能有人为的干预，去中心化也不是说已经制定的规则就不能修改，而是说对规则的修改需要用去中心化的方式完成。我们平时说是用脚投票，区块链的世界里是用挖矿来投票的。这次硬分叉为什么成功，是因为绝大多数矿工认为以太坊的开发团队所做的决定是符合大部分人的利益的，大家不要低估了广大部分矿工的思想觉悟。如果以太坊开发团队为了一己私利做了什么决定，那广大工人阶级是不会跟着他们这样干的，这是关于去中心化的反思</p><p>关于分叉的事情，我们一般认为分叉是件坏事，但是你仔细想一下分叉恰恰是去中心化的体现。在一个中心化的系统里，你是没有办法分叉的，你可以选择放弃，但是你不能选择分叉。比如以太坊创始人Vitalik的故事，19岁的他非常喜欢打魔兽世界，直到有一天暴雪公司把他最喜欢的技能去掉了，他非常生气，多次找暴雪公司的人反馈，没有得到任何满意的结果，他一气之下就不玩了，后来他就想为什么会出现这种情况， 本质上是因为这个游戏是一个去中心化的游戏，决定权在公司，普通用户没有任何办法，所以他决定要去创建一个去中心的平台，用户不满意就有选择分叉的权利。所以存在分叉的选项恰恰是民主的体现</p><h5 id="7）、去中心化与分布式的反思（decentralized-≠-distributed）"><a href="#7）、去中心化与分布式的反思（decentralized-≠-distributed）" class="headerlink" title="7）、去中心化与分布式的反思（decentralized ≠ distributed）"></a>7）、去中心化与分布式的反思（decentralized ≠ distributed）</h5><p>一个去中心化系统必然是分布式的，但是分布式系统不一定是去中心化的，即使这个系统运行在成千上万的计算机上，如果这些计算机都是由同一个组织所管辖的，那么也不能叫做去中心化的。在分布式的平台上可以运行一个中心化的应用，也可以运行一个去中心化的应用</p><p>比特币和以太坊都是交易驱动的状态机（state machine），它的特点是让系统中几千台计算机做同一个操作，付出很大的代价来维护状态的一致性，而这个并不是分布式系统常用的工作模式，大多数的分布系统是让不同机器做不同的事情。然后再把各台机器的结果汇总起来，得到最后的结果，这样做的目的是为了比单机的速度要快。比如说1台计算机要完成的任务，可能需要一个星期，用10台计算机的分布式集群，可能一天就完成了，最理想的状况是得到线性加速，就是10台计算机的速度比1台计算机的速度要快10倍，但是实际应用当中，线性加速是很难达到的，因为存在任务切分、任务通讯、结果汇总都是有开销（overhead），所以实际应用当中10台计算的速度可能相当于1台计算机的6、7倍，但是任然要比1台计算机要强，这样分布式系统才有意义</p><p>状态机的模式不是这样的，状态机的目的不是比1台计算的处理速度快，而是为了容错。状态机最早的应用场景是什么，是一些mission critical applications（关键任务应用），比如像air traffic control, stock exchange, space shuttle，这些是状态机常见的应用场景，这些场景的特点是什么？这些应用程序必须无间断的向外提供服务，所以需要好几台计算机重复同一种操作，这样即使1台计算机宕机，剩下的计算机还能向外提供服务，这是状态机模式的原理。这样付出的代价是什么，效率很低，几台机器合在一起比一台机器还要慢，因为它要同步状态，而且集群里的机器越多速度越慢，所以传统利用状态机的模型里面机器的数量是比较少的，有很多就是个位数的。像比特币、以太坊这样上千台机器重复同一组操作，在以前是从来没有过的。所以不要以为比特币和以太坊是分布式系统的常态，我们理解了这点就能理解智能合约比较适用的场景是什么，不要把智能合约EVM平台当成大规模计算或者大规模存储等服务，如果你这么做的话，不光是速度很慢，而且也是非常贵的，因为要耗很多汽油费、智能合约是用来编写控制逻辑的，只有那些需要在互不信任的实体之间建立共识的操作，才需要写在智能合约里。如果你需要大规模计算服务的话，可以用亚马逊的云服务平台</p><h4 id="12、ETH-美链"><a href="#12、ETH-美链" class="headerlink" title="12、ETH-美链"></a>12、ETH-美链</h4><h5 id="1）、背景介绍"><a href="#1）、背景介绍" class="headerlink" title="1）、背景介绍"></a>1）、背景介绍</h5><p><img src="/../article_img/Web3/img7-3.png"></p><p>2018年4月发生的事件，美链（Beauty Chain）是发行在以太坊上的代币，这些代币没有自己的区块链，而是以智能合约的形式运行在以太坊的EVM平台上。发行这个代币的智能合约，对应的是以太坊状态树的一个节点，这个节点有它自己的账户余额，就相当于这个智能合约一共有多少个以太币，就是发行这个代币的智能合约它总的资产有多少个以太币，然后在这个合约里每个账户上有多少个代币，这个是作为存储树中的变量，存储在智能合约的账户里。代币的发行、转账、销毁都是通过调用智能合约中的函数来实现的，这个也是跟以太坊上的以太币不太一样的地方，它不像以太坊一样需要挖矿来维护一个底层的基础链，像以太坊上每个账户有多少个以太币，这个是直接保存在状态树中的变量，然后以太坊上面两个账户转账是通过发布一个交易到区块链上，这个交易会打包到发布的区块链上面，而代币发生转账的话实际上就是智能合约上面两个账户之间发生转账，通过调用智能合约上的函数，就可以完成了。每个代币都可以制定自己的发行规则，比如某个代币是1个以太坊兑换100个代币，那么比如说从某个外部账户转1个以太币给这个智能合约，这个智能合约就可以给你在这个智能合约里的代币账户上发送100个代币，每个代币账户上有多少个代币的信息都是维护在存储树里面，发行这个代币的智能合约的存储树里面</p><p>以太坊平台的出现让发行代币提供了方便，包括以前说的EOS，这个在上线之前也是作为以太坊上的代币形式，上线的意思是有自己的基础链了，不用依附在以太坊上了。以太坊发行代币的标准为ERC20（Ethereum Request for Comments）</p><p>美链中有一个叫batchTransfer的函数，就是一次性向很多个接收者发送代币，然后把这些代币从调用这个函数的账户上扣掉。美链的代币叫BEC，比如我有很多BEC，给10个不同的账户发送代币，调用这个batchTransfer函数，每个人发送100个代币，那么这个batchTransfer函数先从我的账户上扣掉1000个代币，然后给10个账户分别增加100个代币</p><h5 id="2）、batchTransfer函数的实现"><a href="#2）、batchTransfer函数的实现" class="headerlink" title="2）、batchTransfer函数的实现"></a>2）、batchTransfer函数的实现</h5><p>&lt;img src&#x3D;“..&#x2F;article_img&#x2F;Web3&#x2F;img7-4.png” width&#x3D;80%”&gt;</p><p>batchTransfer函数有两个参数，第一个参数是数组，接收代币者的地址，函数中规定接收者的数目最多是20个，第二个参数value是转账的金额，先算一下总金额amount，recevier的数目和每人接收的代币计算；然后检查一下发起调用的账户<code>msg.sender</code>确实是有这么多代币的。之后把发起账户的代币数目减去amount，下面一个循环是给每一个接收者接收value这么多的代币</p><p>上图红框中的乘法，当value值很大的时候可能会发生溢出，amount算出来可能是个很小的一个值，所以从调用者的代币中减的时候是很小一部分的代币，但还是给每个receivers增加那么多value的代币，这样做造成了系统中凭空多发行了很多代币</p><h5 id="3）、攻击细节"><a href="#3）、攻击细节" class="headerlink" title="3）、攻击细节"></a>3）、攻击细节</h5><p><img src="/../article_img/Web3/img7-5.png"></p><p>上图中一堆数字是函数调用的参数，该函数有两个参数，分别对应那串数字的前两行，第一个参数是地址，第一行给出的实际上是第一个参数出现的具体位置，这里是16进制的，40也就是64，也就是说第一个参数出现在第64个字节的位置，每一行是32个字节，所以实际上是从第2号开始出现的。第二行是这个value的值，这是个很大的数，前面是8，后面都是0，第三行是这个数组的具体内容，数组的长度，是2，接下来两行是两个接收的地址</p><p>参数的特点：第二行amount是8，再乘以2，算出来的amount恰好溢出为0，<code>add(value)</code>的时候还是加原来特别大的那一串数目</p><p><img src="/../article_img/Web3/img7-6.png"></p><p>上图红框中是接收地址接收的代币，每个地址都接收到了很大一部分代币</p><p><img src="/../article_img/Web3/img7-7.png"></p><p>攻击使代币的价格造成致命性的打击，差不多快要归零了</p><p><img src="/../article_img/Web3/img7-8.png"></p><p>代币上市的交易所在发生攻击后暂停提币的功能，防止黑客携款逃走。两天之后回滚交易，这个事件影响没有The DAO影响的大</p><h5 id="4）、反思"><a href="#4）、反思" class="headerlink" title="4）、反思"></a>4）、反思</h5><p>在进行数学运算的时候一定要考虑溢出的可能性。Solidity有一个safeMath库，里面提供的操作运算都会自动检测有没有出现溢出</p><p><img src="/../article_img/Web3/img7-9.png"></p><p><code>mul()</code>函数中，先用<code>a * b = c</code>，再用<code>c/a</code>看看是否等于b，如果发生溢出的话，<code>assert()</code>会抛出异常</p><p>C语言里，两个数相乘会有一定的精度损失，再除以一个数，不一定会得到和另外一个数一模一样的数。但是在Solidity里面是不存在的，因为两个数都是256位的整数，整数先进行乘法，再进行除法</p><p>batchTransfer的加法和减法都用的safeMath库，只有乘法不小心没有使用，结果酿成了悲剧。曾经有人怀疑是不是故意的，但从事件的结果来看又不像使故意的</p><h4 id="13、总结"><a href="#13、总结" class="headerlink" title="13、总结"></a>13、总结</h4><h5 id="1）、区块链应用的争议"><a href="#1）、区块链应用的争议" class="headerlink" title="1）、区块链应用的争议"></a>1）、区块链应用的争议</h5><p>现在社会上对区块链的争议是非常大的，有很多对区块链的质疑其实也是有道理的，为什么会有那么多人会质疑这个技术，其中一个原因是区块链的概念被滥用了。有些人把什么问题都往区块链上放，无论是效率上的问题，还是监管上的问题，好像区块链是解决一切问题的法宝，无论什么问题放在区块链上都可以解决了，这个是不对的</p><p>举个例子，国外有人提出把保险理赔业务放在区块链上，原因是现有的保险理赔业务非常的慢，可能需要几个星期甚至更长的时间，所以他们觉得放在区块链上之后，因为区块链的转账速度，比如说比特币等6个区块确认，大概一个小时的时间就可以完成，这比保险理赔几个星期的速度要好很多了，这个应用场景有什么问题吗？保险理赔的速度慢并不是支付技术的局限性，就用普通的银行转账就行，是因为理赔的内容需要人工审核才会比较慢，而在这方面上区块链并没有好的优势</p><p>还要人提出用区块链做防伪溯源的，比如有人提出把有机蔬菜生产的全过程放在区块链上，他们认为区块链是不可篡改的，在区块链上可以查到有机蔬菜生产的全过程，所以是很好的应用场景，这个应用场景有什么问题吗？这个应用本身没有问题，但是是不是说只要你用区块链把生成的全过程记录下来了就能保证你买到的蔬菜就是有机的，这个是不一定的。如果这块地是施过化肥的，或者撒上农药的，但是被当作有机蔬菜记录在区块链里，那么区块链技术本身是检测不出来的，同样在运输销售过程中被人掉包了，这个也不是区块链能检测出来的。区块链的不可篡改性只是说这个内容写到区块链上是不可篡改的，但是写入到区块链的时候，本身写的就是假的内容，这个是没有办法检测出来的</p><p>还有一些区块链技术的争议是和信任机制相关的，区块链的一个共识机制的目的是要在互不信任的实体之间建立共识，有些人认为这个本身就是一个伪命题，因为互不信任的实体之间是没有办法进行实体交易的。比如说网上购物，假设有某个电商网站，它是去中心化的，你不信任它，那还怎么会在上面买东西呢。比如说你把比特币付给这个电商网站，对方不给你发货怎么办，或者收到之后发现商品有质量问题怎么办。在一个中心化的世界里，你可以通过各种机构比如说信用卡有一些保护措施，在去中心化的世界这些是没有办法做到的。这个质疑有一定道理，但是中心化和去中心化的界限并不是黑白分明的，在一个成功的商业模式里面，既可以有中心化的成分也可以有去中心化的成分，比特币只不过是一种支付方式，并不是说采用比特币作为支付方式的商业模式本身也必须是去中心化的。比如像亚马逊这样一个中心化的网站，它将来也可以采用比特币作为一种支付方式</p><h5 id="2）、区块链的不可篡改性"><a href="#2）、区块链的不可篡改性" class="headerlink" title="2）、区块链的不可篡改性"></a>2）、区块链的不可篡改性</h5><p>与之相关的一个问题是区块链的不可篡改性，比如说网上购物的例子，交易已经写在区块链上不可撤销了，但商品有问题要退货怎么办。但其实包括信用卡支付，退款也不是撤销原来的付款交易，而是在应用层发起一个新的交易。用比特币支付也是同样的道理的</p><h5 id="3）、区块链的监管"><a href="#3）、区块链的监管" class="headerlink" title="3）、区块链的监管"></a>3）、区块链的监管</h5><p>还要一些是和法律的监管保护相关的，传统的支付方式法律是有保护的，而区块链目前是缺乏监管的，有些认为这是好事情，去中心化可以不受到监管，但监管本身不一定是坏事情，没有法律监管同时也意味着没有司法保护。这里我们要注意的是，这些法律的监管和支付技术本身是没有什么关系的，信用卡被盗刷有些国家提供保护，但也有一些国家不提供保护。更重要的是比特币本来就不应该是和已有的支付方式进行竞争，在已有的支付方式已经解决的很好的领域不应该使用比特币。那哪些领域可以用呢，互联网把信息传播的很好，但对于跨界支付难度就要大很多，现有的体系当中支付渠道和信息传播渠道是分开的。有人说下一代互联网是价值交互网络，现在的互联网可以说是信息传播网络。未来的发展趋势就是支付渠道和信息传播渠道可以融合在一起，使得价值交互可以和信息传播一样的方便（Information can flow freely on the internet, but payment can not）</p><h5 id="3）、支付方式的效率"><a href="#3）、支付方式的效率" class="headerlink" title="3）、支付方式的效率"></a>3）、支付方式的效率</h5><p>还要一些质疑是和支付效率相关的，有些人认为加密货币的支付方式是十分低效的还耗能。第一，加密货币本来就不是用于和已有的支付方式做竞争的。第二，随着技术和共识协议的发展，已经有加密货币的效率大大提高了。第三，我们评价一个支付方式的好坏要和特定的历史条件下去评判，加密货币在某些场景下已经是非常高效的了</p><h5 id="4）、智能合约"><a href="#4）、智能合约" class="headerlink" title="4）、智能合约"></a>4）、智能合约</h5><p>还有一些质疑是和智能合约相关的，有那么多安全漏洞，还不如用法律合同，老百姓还能看的懂。但程序化是个大趋势，Software is eating the world（软件将会改变颠覆世界），任何事件领域在转型的早期都会有一些问题，这是正常的。将来会出现智能合约常用的一些模板。但是不要以为智能合约和去中心化会解决任何问题。比如The DAO如果没有出问题，它的模式也不一定好，虽然它是由投票来决定投资很民主，但是民主就一定是好事情吗，大多数人的决定就一定是正确的吗？</p><p>Democracy is the worst form of Government except for all those other forms that have been tried from time to time.</p><p>丘吉尔说的，民主制度不是一种最完美的制度，就像高考不是一种最好的选拔人才的制度，但相对于其他制度是不错的。但不要以为用民主制度，投票能解决所有的问题，如果真是这样的话，那这个世界太简单了。The DAO的例子也是一样的，去中心化就一定是好事情吗？不一定的，这些风投的投资基金需要去调查许多方面，绝不是像智能合约中简单的投投票就完成了。历史上98 99年的互联网淘金热的时候，有些人就是把所有的概念都往互联网上靠，互联网相关的股票涨的很厉害。当时有人在互联网上卖狗粮，赔的一塌糊涂，因为狗粮很沉，当时的邮费就要不少钱。不要因为某种商业模式用去中心化的概念包装一下就把它捧上天，中心化和去中心化的管理方式其实是各有利弊的，要具体问题具体分析。像The DAO这个项目本就不应该那么热</p><p><strong>对应课程</strong>：</p><p><a href="https://www.bilibili.com/video/BV1Vt411X7JF">北京大学肖臻老师《区块链技术与应用》公开课</a></p><p>本文转自 <a href="https://blog.csdn.net/qq_40378034/article/details/126673999">https://blog.csdn.net/qq_40378034/article/details/126673999</a>，如有侵权，请联系删除。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Web3</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>&lt;ETH&gt; 智能合约</title>
    <link href="/2025/05/01/ETH_3/"/>
    <url>/2025/05/01/ETH_3/</url>
    
    <content type="html"><![CDATA[<p>写在前面：<br>前段时间把b站上北大肖老师的区块链课程速通了一遍，这里引一下csdn上的优质课程笔记，便于个人后续温习。<br>博客链接：<a href="https://blog.csdn.net/qq_40378034/category_11862943.html">https://blog.csdn.net/qq_40378034/category_11862943.html</a><br>课程链接：<a href="https://www.bilibili.com/video/BV1Vt411X7JF/">https://www.bilibili.com/video/BV1Vt411X7JF/</a></p><span id="more"></span><h4 id="9、ETH-智能合约"><a href="#9、ETH-智能合约" class="headerlink" title="9、ETH-智能合约"></a>9、ETH-智能合约</h4><p>智能合约是以太坊的精髓，也是以太坊和比特币一个最大的区别</p><h5 id="1）、什么是智能合约"><a href="#1）、什么是智能合约" class="headerlink" title="1）、什么是智能合约"></a>1）、什么是智能合约</h5><p>智能合约的本质是运行在区块链上的一段代码，代码的逻辑定义了智能合约的内容</p><p>智能合约的账户保存了合约当前的运行状态</p><ul><li>balance：当前余额</li><li>nonce：交易次数</li><li>code：合约代码</li><li>storage：存储，数据结构是一棵MPT</li></ul><p>Solidity是智能合约最常用的语言，语法上与JavaScript很接近</p><h5 id="2）、智能合约的代码结构"><a href="#2）、智能合约的代码结构" class="headerlink" title="2）、智能合约的代码结构"></a>2）、智能合约的代码结构</h5><p><img src="/../article_img/Web3/img6-1.png"></p><p>Solidity是面向对象的编程语言，这里的contract类似于C++当中的类class，这里的contract定义了很多状态变量，Solidity是强类型语言，这里的类型跟普通的编程语言像C++之类的是比较接近的，比如说uint（unsigned int）是无符号的整数，address类型是Solidity语言所特有的</p><p>接下来是两个event事件，作用是用来记录日志的</p><p>第一个事件是HighestBidIncreased，拍卖的最高出价增加了，上图是一个网上拍卖的例子，如果有人出现新的最高价，记录一下参数是address bidder，金额是amount，第二个事件是Pay2Beneficiary，参数是赢得拍卖的人的地址winner以及他最后的出价amount</p><p>Solidity语言跟别的普通编程语言相比有一些特别之处：</p><p>比如mapping，mapping是一个哈希表，保存了从地址到unit的一个映射。Solidity语言中<strong>哈希表不支持遍历</strong>，如果想遍历哈希表里的所有元素，需要自己想办法记录哈希表中有哪些元素，这里是用bidders数组来记录的。<strong>Solidity语言中的数组可以是固定长度的，也可以是动态改变长度的</strong>，这里是一个动态改变长度的数组。如果想在数组里增加一个元素，就用push操作，<code>bidders.push(bidder)</code>，新增加一个出价人在数组的末尾，要想知道这个数组有多少个元素，可以用<code>bidders.length</code>，如果是固定长度的数组的话，就要写明数组的长度，比如说address[1024]，这个就是长度为1024的数组</p><p>再往下是构造函数，构造函数只能有一个，<strong>Solidity语言中定义构造函数有两种方法</strong>：</p><ul><li>一种方法就是像C++构造函数一样，定一个与contract同名的函数，这个函数可以有参数，但是不能有返回值</li><li>新版本Solidity语言更推荐用这个例子的方法，就用一个constructor来定义一个构造函数，这个构造函数只有在合约创建的时候会被调用一次</li></ul><p>接下来是三个成员函数，三个函数都是public，说明其他账户可以调用这些函数</p><h5 id="3）、账户调用"><a href="#3）、账户调用" class="headerlink" title="3）、账户调用"></a>3）、账户调用</h5><p><strong>1）外部账户如何调用智能合约？</strong></p><p><img src="/../article_img/Web3/img6-2.png"></p><p>调用智能合约其实跟转账是类似的，比如说A发起一个交易转账给B：</p><ul><li>如果B是一个普通的账户，那么这就是一个普通的转账交易，就跟比特币当中的转账交易时一样的</li><li>如果B是一个合约账户的话，那么这个转账实际上是发起一次对B这个合约的调用，那么具体是调用合约中的哪个函数呢，是在data域（数据域）说明的</li></ul><p>上图这个例子中，sender address是发起这个调用的账户的地址，to contract address是被调用的合约的地址，调用的函数是txdata，如果函数是有参数的话，那么参数的取值也是在data域里说明的，上面看的网上拍卖的例子中，三个成员函数都没有参数，但是有的成员函数是可以有参数的</p><p>中间那一行是调用的参数，value是说发起调用的时候转过去多少钱，这里是0，这个调用的目的仅仅是为了调用它的函数，并不是真的要转帐，所以value&#x3D;0，gas used是这个交易花了多少汽油费，gas price是单位汽油的价格，gas limit是这个交易我最多原意支付多少汽油费</p><p><strong>2）一个合约如何调用另一个合约中的函数？</strong></p><p><strong>方法一：直接调用</strong></p><p><img src="/../article_img/Web3/img6-3.png" alt="在这里插入图片描述"></p><p>上图这个例子中，有A和B两个合约：</p><p>A这个合约就只是写log，event定义事件LogCallFoo，<code>emit LogCallFoo()</code>是用emit这个操作来调用这个事件，emit语句的作用就是写一个log，对于程序的运行逻辑是没有影响的</p><p>B这个合约，callAFooDirectly这个函数参数是一个地址，就是A这个合约的地址，然后就这个语句把这个地址转换成A这个合约的一个实例，然后调用其中的foo这个函数</p><p><strong>以太坊中规定一个交易只有外部账户才能够发起，合约账户不能自己主动发起一个交易</strong>。所以这个例子中需要有一个外部账户调用了合约B当中的这个callAFooDirectly函数，然后这个函数再调用合约A当中的foo函数</p><p><strong>方法二：使用address类型的call()函数</strong></p><p><img src="/../article_img/Web3/img6-4.png" alt="在这里插入图片描述"></p><p>address类型的call()函数，第一个参数是要调用函数的签名，然后后面跟的是调用的参数</p><p>这种调用的方法跟上一个调用的方法相比，一个区别是对于错误处理的不同，<strong>直接调用时，如果你调用了那个合约在执行过程中出现错误，那么会导致发起调用的这个合约也跟着一起回滚</strong>，在直接调用的例子中如果A在执行过程出现什么异常，会导致B这个合约也跟着一起出错</p><p><strong>而这种<code>address.call()</code>这种形式如果在调用过程中，被调用的合约抛出异常，那么这个call函数会返回false，表明这个调用是失败的，但是发起调用的这个函数并不会抛出异常，而是可以继续执行</strong></p><p><strong>方法三：代理调用delegatecall()</strong></p><p><img src="/../article_img/Web3/img6-5.png" alt="在这里插入图片描述"></p><p>代理调用和call()这种方法基本上是一样的，一个主要的区别是<strong>delegatecall不需要切换到被调用的合约的环境中去执行，而是在当前合约环境中执行就可以了，比如就用当前账户的账户余额存储之类的</strong></p><h5 id="4）、payable"><a href="#4）、payable" class="headerlink" title="4）、payable"></a>4）、payable</h5><p><img src="/../article_img/Web3/img6-6.png" alt="在这里插入图片描述"></p><p>上图中，bid函数有一个payable，另外两个函数都没有。<strong>以太坊中规定如果这个合约账户要能接收外部转账的话，那么必须标注成payable</strong></p><p>这个例子中bid函数是什么意思？</p><p>这是一个网上拍卖的合约，bid函数是用来进行竞拍出价的，比如说你要参与拍卖，你说你出100个以太币，那么就调用合约当中的bid函数。拍卖规则是调用bid函数时要把拍卖的出价100个以太币也发送过去，存储到这个合约里，锁定到拍卖结束，避免有人凭空出价，所以这个bid函数要有能够接收外部转账的能力，才标注一个payable</p><p>第二个withdraw函数没有payable，withdraw是拍卖结束了，出价最高的那个人赢得了拍卖，其他人没有拍到想要的东西，可以调用withdraw把自己当初出的价钱，就是原来bid的时候锁定在智能合约里的以太币再取回来，因为这个的目的不是为了真的转账，不是要把钱转给智能合约，而仅仅是调用withdraw函数把当初锁定在智能合约里的那一部分钱取回来，所以没必要标注payable</p><p><img src="/../article_img/Web3/img6-7.png" alt="在这里插入图片描述"></p><p>上图转账交易的例子，value&#x3D;0，这个交易就属于并没有真的把钱转出去，所以to contract address这个函数就不用定义成payable</p><p><strong>以太坊中凡是要接收外部转账的函数，都必须标识为payable，否则你给这个函数转出钱的话，会引发错误处理，会抛出异常，如果你不需要接收外部转账你就不用标识为payable</strong></p><h5 id="5）、fallback-函数"><a href="#5）、fallback-函数" class="headerlink" title="5）、fallback()函数"></a>5）、fallback()函数</h5><p><img src="/../article_img/Web3/img6-8.png" alt="在这里插入图片描述"></p><p>有一个特殊的函数叫fallback()函数，这个函数既没有参数也没有返回值，而且也没有函数名是个匿名函数，这个fallback关键字也没有出现在这个函数名里</p><p>调用合约的时候，A调用B这个合约，然后要在转账交易的data域说明你调用的是B当中的哪个函数，如果A给合约B转账了一笔钱，没有说明调用的是哪个函数，它的data域是空的，那怎么办呢？那么这个时候缺省的就是调用这个fallback()函数，为什么叫fallback()函数，因为没有别的函数可调了，就调它</p><p>还有一种情况是你要调的函数不存在，在那个data域里，你说要调这个函数，而实际这个合约当中没有这个函数，那怎么办呢？也是调用这个fallback()函数。这就是为什么这个函数没有参数也没有返回值，因为它没法提供参数</p><p>对于fallback()函数来说，也可能需要标注payable关键字，如果fallback()函数需要有接收转账的能力的话，也需要写成是payable，一般情况下，都是写上payable的，如果合约账户没有任何函数标识为payable，包括fallback()函数函数也没有标识成payable，那么这个合约没有任何能力接受外部的转账。如果这个合约没有fallback()函数或者是有fallback()函数但是没有写payable，那么其他人往这个合约里转一笔钱，别的都不说，data域是空的就会引发异常</p><p>fallback()函数不是必须定义的，合约里可以没有fallback()函数，如果没有fallback()函数的话，出现前面说的几种情况，就会抛出异常。另外只有合约账户才有这些东西，外部账户跟这个都没有关系，外部账户都没有代码</p><p>还有一点，转账金额可以是0，但是汽油费是要给的，这是两码事，转账金额是给收款人的，汽油费是给发布这个区块的矿工的，如果汽油费不给的话，矿工不会把你这个交易打包发布到区块链</p><h5 id="6）、智能合约的创建和运行"><a href="#6）、智能合约的创建和运行" class="headerlink" title="6）、智能合约的创建和运行"></a>6）、智能合约的创建和运行</h5><p><img src="/../article_img/Web3/img6-9.png" alt="在这里插入图片描述"></p><p>智能合约是怎么创建的呢？是由一个外部账户发起一个转账交易，转给0x0这个地址，然后把这个要发布合约的代码放到data域里面。你要创建一个合约，要发起一个转账交易，给0这个地址转账，转账的金额都是0，因为你实际上不是真的想转帐，只是想发布一个智能合约，发布的这个智能合约的代码放到数据域就行了</p><p>合约的代码写完之后都是要编译成bytecode，然后运行在EVM上。EVM是类似于JVM的设计思想，通过加一层虚拟机，对智能合约的运行提供一个一致性的平台，所以EVM有时叫做Worldwide Computer（全世界的一个计算机），EVM的寻址空间是非常大，是256位，像前面讲的unsigned int就是256位</p><h5 id="7）、汽油费（gas-fee）"><a href="#7）、汽油费（gas-fee）" class="headerlink" title="7）、汽油费（gas fee）"></a>7）、汽油费（gas fee）</h5><p><img src="/../article_img/Web3/img6-10.png" alt="在这里插入图片描述"></p><p>比特币和以太坊这两种区块链的编程模型，设计理念是有很大差别的</p><p>比特币设计理念是简单，脚本语言的功能很有限，比如说不支持循环</p><p>而以太坊是要提供一个图灵完备的编程模型（Turing-complete Programming Model），很多功能在比特币平台上实现起来很困难，甚至是根本实现不了，而到以太坊平台上呢，实现起来就很容易，当然，这样也带来一个问题，出现死循环怎么办，当一个全节点收到一个对智能合约的调用，怎么知道这个调用执行起来会不会导致死循环？有什么办法吗？</p><p>没有办法，这实际上是一个Halting Problem（停机问题），停机问题是不可解的，从理论上可以证明不存在这样一个算法，能够对任意给定的输入程序判断出这个程序是否会停机。那怎么办呢？办法就是把这个问题推给发起交易的那个账户，<strong>以太坊引入了汽油费机制，发起一个对智能合约的调用要支付相应的汽油费</strong></p><p>上图中间是一个交易的数据结构：</p><ul><li>AccountNonce就是这个交易的序号，用于防止replay attack</li><li>Price和GasLimit就是跟汽油费相关的，GasLimit是这个交易原意支付的最大汽油量，Price是单位汽油的价格，两个乘在一起就是这个交易可能消耗的最大汽油费</li><li>Recipient就是收款人的地址，转账交易转给谁的收款人地址</li><li>Amount是转账金额，把Amount这么多钱转给Recipient，也可以看到交易当中的汽油费跟转账金额是分开的</li><li>Payload就是前面说的data域，用于存放调用的是合约中的哪一个函数，函数的参数取值是什么，都在Payload里面</li></ul><p><strong>当一个全节点收到一个对智能合约的调用的时候，先按照调用过程中给出的GasLimit算出可能花掉的最大汽油费，然后一次性的把这个汽油费从这个发起调用的账户上扣掉，然后再根据实际执行的情况，算出实际花了多少钱，如果汽油费不够的会引起回滚</strong></p><p>不同的指令消耗的汽油费是不一样的。一些简单的指令，比如说加法减法消耗的汽油费是很少的，复杂的指令消耗的汽油费就比较多，比如说取哈希，这个运算一条指令就可以完成，但是汽油费就比较贵，除了计算量之外，需要存储状态的指令消耗的汽油费也是比较大的，那么相比之下，如果仅仅是为了读取公共数据，那么那些指令可以是免费的</p><h5 id="8）、错误处理"><a href="#8）、错误处理" class="headerlink" title="8）、错误处理"></a>8）、错误处理</h5><p><img src="/../article_img/Web3/img6-11.png" alt="在这里插入图片描述"></p><p><strong>以太坊中的交易执行起来具有原子性，一个交易要么全部执行，要么完全不执行，不会只执行一部分</strong>，这个交易既包含普通的转账交易，也包含对智能合约的调用，所以<strong>如果在执行智能合约的过程当中，出现任何错误，会导致整个交易的执行回滚</strong>，退回到开始执行的之前的状态，就好像这个交易完全没有执行过</p><p>那么什么情况下会出现错误呢？</p><p>一种情况就是刚才说的汽油费，如果这个交易执行完之后，没有达到当初的GasLimit，那么多余的汽油费会被退回到这个账户里，一开始的时候是按照最大的GasLimit把汽油费扣掉了，如果最后运行完了，还有剩下来的，实际上是用的多少汽油收多少钱，剩的可以退回去。相反，<strong>如果执行到一半，GasLimit已经都用完了，那么这个时候这个合约的执行要退回到开始执行之前的状态，这就是一种错误处理，而且这个时候已经消耗掉的汽油费是不退的</strong></p><p>为什么要这么设计呢？执行的状态要回滚，但已经耗掉的汽油费是不退的</p><p>因为要么的话就会有恶意的节点可能会发动delays service attack，可能他发布一个计算量很大的合约，然后不停的调这个合约，每次调的时候给的汽油费都不够，反正最后汽油费还会退回来，那么对攻击者来说没有什么损失，但是对矿工来说是白白浪费了很多的资源，这就是为什么说，汽油费不够的话，执行到一半会回滚，花掉的汽油费是不退的</p><p>除了这种汽油费不够的情况，还有一种情况是引起错误处理的，比如说<strong>assert语句和require语句，这两个语句都是用来判断某种条件，如果条件不满足的话，就会导致抛出异常</strong></p><p><strong>assert语句一般用于判断某种内部条件</strong>，有点像C语言中的assert是一样的，<strong>require语句一般用于判断某种外部条件</strong>，比如说判断函数的输入是否符合要求。上图中给出了一个简单的例子，bid这个竞拍的函数判断一下，当前的时间now&lt;&#x3D;拍卖的结束时间auctionEnd，如果符合条件继续执行，如果不符合的话，拍卖都已经结束了，你还在出价，这个时候就会抛出异常</p><p>第三个语句是revert，<strong>revert是无条件的抛出异常，如果执行到revert语句，那么自动的就会导致回滚</strong>，早期的版本里用的是throw语句，新版本Solidity里建议改用revert这个语句</p><p><strong>Solidity当中没有这种try-catch这种结构</strong>，有的编程语言像Java，用户自己可以定义出现问题后怎么办，有这种try-catch，Solidity里没有这种结构</p><h5 id="9）、嵌套调用"><a href="#9）、嵌套调用" class="headerlink" title="9）、嵌套调用"></a>9）、嵌套调用</h5><p><img src="/../article_img/Web3/img6-12.png" alt="在这里插入图片描述"></p><p>智能合约出现错误会导致回滚，那么如果是嵌套调用，一个智能合约调用另外一个智能合约，那么被调用的这个智能合约出现错误，是不是会导致发起调用的智能合约，也跟着一起回滚呢？所谓的叫<strong>连锁式回滚</strong></p><p>不一定，<strong>这个取决于调用这个智能合约的方式。如果是直接调用的话，会出现连锁式的回滚，整个交易都会回滚，如果调用的方式是用比如说call这种方式，就不会引起连锁式回滚，只会使当前的调用失败返回一个false的返回值</strong></p><p>有些情况下，从表面上看你并没有调用任何一个函数，比如说，你就是往一个账户里转账，但是这个账户是合约账户的话，转账这个操作本身就有可能触发对函数的调用，因为有fallback()函数，这就是一种嵌套调用，一个合约往另一个合约里转账，就有可能调用这个合约里的fallback函数</p><h5 id="10）、Block-Header中的GasLimit和GasUsed"><a href="#10）、Block-Header中的GasLimit和GasUsed" class="headerlink" title="10）、Block Header中的GasLimit和GasUsed"></a>10）、Block Header中的GasLimit和GasUsed</h5><p><img src="/../article_img/Web3/img6-13.png" alt="在这里插入图片描述"></p><p>Block Header中的GasLimit和GasUsed也是跟汽油费相关的，<strong>Block Header里面的GasUsed是这个区块里所有交易所消耗的汽油费加在一起</strong></p><p>发布区块需要消耗一定的资源，这个消耗的资源要不要有一个限制，比特币当中对于发布的的区块也是有一个限制的，大小的限制，最多不能超过1M，因为发布的区块如果没有任何限制，有的矿工可能把特别多的交易全部打包到一个区块里面然后发布出去，那么这个超大的区块在区块链上会消耗很多资源，所以它规定每个区块最多不能超过1M，比特币交易是比较简单的，基本上可以用交易的字节数来衡量出这个交易消耗的资源有多少，但以太坊中如果这么规定是不行的，因为以太坊中智能合约的逻辑很复杂，有的交易可能从字节数上看是很小的，但它消耗的资源可能很大，比如它可能调用别的合约之类的，所以<strong>要根据交易的具体操作来收费，这就是汽油费</strong></p><p><strong>Block Header里面的GasLimit是这个区块里所有交易能够消耗的汽油的一个上限</strong>，不是说把区块里每个交易的GasLimit加在一起，如果那样的话，就等于没有限制了，因为每个交易的GasLimit是发布这个交易的账户自己定的，定多少是自己说了算，但是这个区块中的所有交易，实际能够消耗的汽油是有一个上限的，不能无限的消耗，否则你也可能发布一个对资源消耗很大的区块，对整个系统的运行是没有好处的</p><p>GasLimit跟比特币的区别：</p><p>比特币限制资源是按照大小来限制的，而且这个1M的上限是固定了的，是写死在协议里面的，有些人认为1M太小了，而且有的分叉币的产生就是为了提高这个上限</p><p>以太坊中也有一个上限，这个GasLimit，但是每<strong>个矿工在发布区块的时候可以对GasLimit进行微调，可以在上一个GasLimit的基础上上调或者下调 1 1024 \frac{1}{1024} 10241​</strong>。如果出现像比特币那种情况，大家都觉得这个GasLimit设置的太小了，那轮到你发布区块的时候可以增加 1 1024 \frac{1}{1024} 10241​，1&#x2F;1024听起来很小，以太坊的出块速度很快，十几秒就是一个新的区块，所以的话，如果大家都觉得当前的GasLimit太小，那么很快就可以翻一番。当然，也可能下调，有矿工认为GasLimit太大了需要下调，所以这种机制实际上求出的GasLimit，是所有矿工认为比较合理的GasLimit的一个平均值，有的矿工认为要上调，有的矿工认为要下调，那么每个矿工在获得记账权之后就按照自己的意愿进行这种上调或者下调的微调，所以最后整个系统的GasLimit就趋向于所有矿工的一个平均意见</p><h5 id="11）、一些问题"><a href="#11）、一些问题" class="headerlink" title="11）、一些问题"></a>11）、一些问题</h5><p><strong>问题1：某个全节点要打包一些交易到一个区块里面，这些交易里有一些是对智能合约的调用，那么这个全节点应该先把这个智能合约都执行完之后再去挖矿呢，还是说先挖矿获得了记账权然后再执行这些智能合约？</strong></p><p>区块链里有一笔转账交易发布上去的话，本来就是需要所有的全节点都执行的，这不是一种浪费也不是一种出问题了，就是所有的全节点要同步状态，大家都要在本地执行这个转账交易，如果一个全节点不执行那就出问题了，那他的状态跟别人的状态是不一样的，比特币也是一样的，比特币发布一个交易到区块链上，也是要所有的全节点都得执行这个转账交易，要不然怎么更新UTXO啊</p><p>先往回退一步，不回答这个问题，在全节点收到一个对合约的调用的时候，要一次性的先把这个调用可能花掉的最大汽油费从发起这个调用的账户上扣掉，这个具体是怎么操作的？</p><p>状态树、交易树和收据树，这三棵树都是全节点在本地维护的数据结构，状态树记录了每个账户的状态包括账户余额，所以扣汽油费的时候实际怎么扣的？全节点收到调用的时候，从本地维护的数据结构里把账户的余额减掉就行了，如果余额不够的话，这个交易就不能执行，一次性要按GasLimit把他这个余额减掉，执行完之后如果有剩的，再把他的余额再加回去一点</p><p><strong>智能合约执行过程中任何对状态的修改都是在改本地的数据结构，只有在合约执行完了，而且发布到区块链上之后，本地的修改才会变成外部可见的，才会变成区块链上的共识</strong>。有很多全节点，每个全节点都在本地做这个事情，执行的智能合约可能不完全一样，因为根据你收到的交易可能执行不完全一样，如果某个全节点发布一个区块，我收到这个区块之后，我本地执行的就扔掉了，我把收到这个区块里的交易再执行一遍，更新我本地的三棵树。如果我本来已经执行一遍了，我没有挖到矿，那个人发过来我又得执行一遍，我得执行两遍多浪费啊，问题是你不这样还能怎么办，你本地那个候选区块中包含的交易跟他发布的那个交易不一定完全一样，至少有一个肯定不一样，给出块奖励的那个肯定不一样，他不会给你，别的交易也不一定就一样，所以这个没有办法，都是得要重新执行一遍</p><p>以太坊挖矿其实也是尝试各种nonce找到一个符合要求的，计算哈希的时候要用到什么？要用到这个Block Header的内容，Block Header的内容这个Root、TxHash、ReceiptHash，是那三棵树的根哈希值，所以<strong>要先执行完这个区块中的所有交易包括智能合约的交易，这样才能更新这三棵树，这样才能知道这三个根哈希值，这样这个Block Header的内容才能确定，然后才能尝试各个nonce</strong></p><p><strong>问题2：假设我是一个矿工我费了半天劲执行这些智能合约，消耗了我本地的好多资源，最后我挖矿没挖到怎么办，因为挖矿是竞争，很多矿工竞争，记账权被别人抢先了，那我能得到什么补偿，我能得到汽油费吗？</strong></p><p>汽油费是没有的，因为<strong>汽油费是给获得记账权发布区块的那个矿工</strong>，那我能得到啥补偿？以太坊中没有任何补偿，他得不到汽油费也得不到任何补偿，不仅如此，他还要把别人发布的区块里的交易在本地执行一遍，以太坊中规定要验证发布区块的正确性，每个全节点要独立验证，那怎么验证呢？别人发布一个交易区块，你把那个区块里的所有交易在本地执行完一遍，更新三棵树的内容，算出根哈希值，再跟他发布的那个根哈希值比较一下看是不是一致，所有这些都是免费的，没有人给你补偿。所以呢，这种机制下，挖矿慢的矿工就特别吃亏，本来汽油费的设置的目的是对于矿工执行这些智能合约所消耗的这些资源的一种补偿，但是这种补偿只有挖到矿的矿工才能得到，其他的矿工等于是陪太子读书</p><p><strong>问题3：会不会有的矿工你不给我汽油费，那我就不验证？比如说我挖半天没有挖到矿，你发布一个区块，按照协议我要验证一下你这个区块的正确性，我验证他有啥好处，你又不给我汽油费，我验证他干嘛，我就认为你是正确的不就行了吗，我就接着挖，会不会有矿工想不通？</strong></p><p>先说一下，如果这样做会导致什么后果，最直接的后果是危害区块链的安全，<strong>区块链的安全是是怎么保证的，就是要求所有的全节点要独立验证发布的区块的合法性，这样少数有恶意的节点没法篡改区块链上的内容</strong>。如果某个矿工想不通，不给钱我就不验证了，这样的风气蔓延开来就会危及区块链的安全</p><p>会不会有这样的情况？如果他跳过验证这个步骤，他以后就没法再挖矿了，因为你验证的时候是要把区块的交易再执行一遍，更新本地的那三棵树，如果不去验证的话，本地三棵树的内容没有办法更新，以后再发布区块你怎么发布，你本地的这些状态就不对了，你算出的根哈希值发布出去之后别人认为是错的。没有办法跳过验证这个步骤</p><p>为什么要执行才能更新状态？<strong>因为发布的区块里没有这三棵树的内容，只是块头里有三个根哈希值，这三棵树的账户状态具体是什么余额什么内容，发布出来是没有的</strong>，不能把状态树的整个状态发布到区块链上，那太多了，而且很多是重复的，状态都不改了，所以不会跳过验证这个步骤，以太坊的安全还是有保证的</p><p><strong>问题4：发布到区块链上的交易是不是都是成功执行的？如果智能合约执行过程中出现了错误，要不要也发布到区块链上去？</strong></p><p><strong>执行发生错误的交易也要发布到区块链上去，否则汽油费扣不掉</strong>，光是在本地的数据结构上把他的账户扣了汽油费，是没用的，你拿不到钱，你得把区块发布上去之后形成共识，扣掉的汽油费才能成为你账户上的钱，所以发布到区块链上的交易不一定都是成功执行的。要告诉大家为什么扣汽油费，而且别人得验证一遍，也要把这个交易执行完一遍，看你扣的是不是对的</p><p><img src="/../article_img/Web3/img6-14.png" alt="在这里插入图片描述"></p><p>那怎么知道一个交易是不是执行成功了呢，前面说过那三棵树，每个交易执行完后形成一个收据，上图是这个收据的内容，Status这个域就是告诉你交易执行的情况是怎么样的</p><p><strong>问题5：智能合约是不是支持多线程，现在多核处理器很普遍，一个计算器有十几核，几十个核，都是正常的，那么智能合约支不支持多核并行处理？</strong></p><p><strong>Solidity不支持多线程，它根本没有支持多线程的语句，原因是以太坊是一个交易驱动的状态机，这个状态机必须是完全确定性的，就是给定一个智能合约，面对同一组输入，产生的输出或者说转移到的下一个状态必须是完全确定的</strong></p><p>为什么要求这个？因为所有的全节点都得执行同一组操作到达同一个状态，要验证，如果状态不确定的话，那三棵树得根哈希值根本对不上，必须完全确定才行</p><p>多线程的问题在于什么？多个核对内存访问顺序不同的话，执行结果有可能是不确定的，除了多线程之外，其他可能造成执行结果不确定的操作也都不支持，最直接最简单的会导致执行结果不确定的操作：产生随机数，这个操作就是不确定性的，而且这个操作必须得是不确定的，所以以太坊的智能合约没有办法产生真正意义下的随机数，可以用一些伪随机数，不能是真的随机数，否则的话，又会出现前面的问题，每个全节点执行完一遍得到的结果都不一样</p><h5 id="13）、智能合约可以获得的信息"><a href="#13）、智能合约可以获得的信息" class="headerlink" title="13）、智能合约可以获得的信息"></a>13）、智能合约可以获得的信息</h5><p><strong>1）区块信息</strong></p><p><img src="/../article_img/Web3/img6-15.png" alt="在这里插入图片描述"></p><p>智能合约的执行必须是确定性的，这也就导致了智能合约不能像通用的编程语言那样通过系统调用来得到一些环境信息，因为每个全节点的执行环境不是完全一样的，所以它只有通过一些固定的一些变量的值能够得到一些状态信息，上图就是智能合约能够得到的区块链的一些信息</p><p><strong>2）调用信息</strong></p><p><img src="/../article_img/Web3/img6-16.png" alt="在这里插入图片描述"></p><p>上图是智能合约可以获得的调用信息：</p><ul><li><code>msg.sender</code>是发起这个调用的人是谁，这个跟最后一个<code>tx.origin</code>交易的发起者是不一样的。比如说有一个外部账户A调用了一个合约叫 C 1 C_1 C1​， C 1 C_1 C1​当中有一个函数 f 1 f_1 f1​， f 1 f_1 f1​又调用另外一个合约 C 2 C_2 C2​，里面的函数 f 2 f_2 f2​，那么对这个 f 2 f_2 f2​函数来说，<code>msg.sender</code>是 C 1 C_1 C1​这个合约，因为当前这个调用，是 C 1 C_1 C1​这个合约发起的，但是<code>tx.origin</code>是A这个账户，因为整个交易的发起者是A这个账户</li><li><code>msg.gas</code>是当前调用还剩下多少汽油费，这个决定了我还能做哪些操作，包括你还想调用别的合约前提是还有足够的汽油费剩下来</li><li><code>msg.data</code>就是所谓的叫数据域，在里面写了调用哪些函数和这些函数的参数取值</li><li><code>msg.sig</code>是<code>msg.data</code>的前四个字节，就是函数标志符调用的是哪个函数</li><li>now是当前区块的时间戳，跟区块信息中的<code>block.timestamp</code>是一个意思，就是智能合约里没有办法获得很精确的时间，只能获得跟当前区块信息的一些时间</li></ul><h5 id="14）、地址类型"><a href="#14）、地址类型" class="headerlink" title="14）、地址类型"></a>14）、地址类型</h5><p><img src="/../article_img/Web3/img6-17.png" alt="在这里插入图片描述"></p><p>上图中第一个是个成员变量，剩下的都是成员函数。成员变量就是账户的余额balance，unit256是这个成员变量的类型，是以Wei为单位的，是个很小的单位</p><p>下面这些成员函数的话，有一点要注意的，这些成员函数的语义跟我们直观上的理解不是很一样，跟第一个成员变量balance也不太一样</p><p><code>addr.balance</code>是address这个地址上他的账户他的余额，那<code>addr.transfer(12345)</code>是什么意思呢？感觉像是addr这个账户往外转了12345个Wei，是不是这个意思？如果是这个意思的话，问题在于他只有一个参数，他只有转账的金额，没有说转给谁，所以<code>addr.transfer(unit amount)</code>是什么意思呢？并不是说addr这个账户往外转了多少钱，而是当前这个合约往addr这个地址里转入多少钱，这个addr是转入的地址不是转出的地址，转出的地址是哪一个？比如说这是个智能合约C，里面有一个函数f，它包含这条语句<code>addr.transfer(12345)</code>，意思是说C这个合约的账上往这个addr地址里转入12345这么多的钱</p><p><code>addr.call</code>也是一样的语句，并不是说addr这个合约账户发起了一个调用，调哪个别的合约账户，而是说当前这个合约发起一个调用，调得是addr这个合约</p><p>delegatecall区别就是说不需要切换到被调用的函数的环境中，就用当前合约的余额，当前合约的存储这些状态去运行就可以了</p><p><img src="/../article_img/Web3/img6-18.png" alt="在这里插入图片描述"></p><p><strong>问题：我向一个帐户转账说这个账户没有定fallback函数会引起错误，会不会连锁回滚？</strong></p><p>这取决于你怎么转账的，转账有三种方法，上图中这三种形式都可以发送ETH</p><p>区别是这个transfer和send，这两个是专门为了转账的函数，区别在于<strong>transfer会导致连锁性回滚</strong>，类似于你直接调用那个函数直接调用的方法是一样的，失败的时候抛出异常，而<strong>send返回一个false，不会导致连锁式回滚</strong>。call其实也是可以转账的，<code>call.value(unit256 amount)()</code>，最后一个参数如果不用调用函数可以是空的。区别在于transfer和send是专门用来转账的，call的话本意是发动函数调用，但是也可以用来转账，<strong>call也不会引起连锁式回滚，失败时返回false</strong></p><p>另外一个区别是<strong>transfer和send在发起调用的时候，只给了一点儿的汽油，是2300个单位，非常少的</strong>，那么收到这个转账的合约基本上干不了别的事，写一个log就行了，别的事都干不了，而<strong>call是把当前这个调用剩下的所有的汽油都发过去</strong>，比如说call所在的合约本身被调用的时候，可能还剩8000个汽油，然后去调别的合约的时候如果是用call这种方法去转账，就把剩多少汽油都发过去了</p><h5 id="15）、拍卖的例子"><a href="#15）、拍卖的例子" class="headerlink" title="15）、拍卖的例子"></a>15）、拍卖的例子</h5><p><img src="/../article_img/Web3/img6-19.png" alt="在这里插入图片描述"></p><p>回到一开始讲的拍卖的例子，拍卖有一个受益人beneficiary，比如说你有一个古董要拍卖，那么这个受益人就是你；auctionEnd是整个拍卖的结束时间；highestBidder是最高出价人</p><p><strong>拍卖的规则：</strong></p><p>在拍卖结束之前，每个人都可以去出价，去竞拍，竞拍的时候为了保证诚信，要把竞拍的价格相应的以太币发过去，比如你出价100个以太币，那么你竞拍的时候要把100个以太币发到这个智能合约里，它就会锁在这里面直到拍卖结束，拍卖的规则不允许中途退出，我去竞拍发了100个以太币，过一会儿我后悔了想把钱要回来，这个不行。拍卖结束的时侯出价最高的那个人highestBidder，他投出去的钱会给这个受益人beneficiary，当然你也要想办法把这个古董给最高出价人，其他没有拍卖成功的人可以把当初投进去的钱再取回来</p><p>竞拍是可以多次出价的，比如说我出个价钱，100个以太币，然后呢，另外一个人出价110个以太币，我再出价120个以太币，这个时候我只要补差价就行了，就把我这一次的出价跟上一次的出价差额发到智能合约里，我上次投标的时候已经发了100个以太币，这次只要再发20个以太币就行了。出价要有效的话，必须比最高出价还要高，比如说当前的最高出价是100个以太币，我去竞拍，我投80个以太币，这个是无效的，等于是非法的拍卖</p><p>constructor会记录下收益人是谁，结束时间是什么时候，这个构造函数，在合约创建的时候，把这两个就记下来了</p><p><img src="/../article_img/Web3/img6-20.png" alt="在这里插入图片描述"></p><p>上图是拍卖用的两个函数，左边的bid函数是竞拍时候用的，你要竞拍你就发起一个交易调用这个拍卖合约中的bid函数，这个bid函数有一个奇怪的地方，它没有参数，感觉上你竞拍的时候你不需要告诉对方你出的价格是多少吗？它其实是在<code>msg.value</code>这个地方写的，这个是发起调用的时候，转账转过去的以太币数目，以Wei为单位的转账金额，这个的逻辑是：</p><p>首先查一下当前的拍卖还没有结束，如果拍卖结束了，你还出价会抛出异常，然后查一下你上一次的出价加上你当前发过去的以太币大于最高出价，如果你以前没有出价过会怎么样？这个bids是个哈希表，Solidity中哈希表的特点是，如果你要查询的那个键值不存在，那么它返回默认值就是0，所以如果没有出过价，第一部分就是0，然后呢，第一次拍卖的时候把拍卖者的信息放到bidders数组里，原因是Solidity哈希表不支持遍历，要遍历哈希表的话，要保存一下它包含哪些元素，然后记录一下新的最高出价人是谁，写一些日志之类的</p><p>右边是拍卖结束的函数，首先查一下拍卖是不是已经结束了，如果拍卖还没有结束，有人调用这个函数，就是非法的会抛出异常，然后判断一下这个函数是不是已经被调过了，如果已经被调过了，就不用再调一遍了，首先把这个金额给这个beneficiary，<code>beneficiary.transfer</code>是当前这个合约把这个金额给这个beneficiary转过去，最高出价人的钱是给受益人了，然后那些剩下的没有竞拍成功的用一个循环，把这个金额退回给这个bidder，然后标明一下，这个函数已经执行完了写一个log</p><p><strong>智能合约是怎么工作的？</strong></p><p>你写完一个智能合约，你写一个拍卖程序要先把它发布到区块链上，往那个0地址发一笔转账交易，转账的金额是0，然后把智能合约的代码放到data域里面，汽油费是要交的，然后矿工把这个智能合约发布到区块链上之后会返回这个合约的地址，然后这个合约就在区块链上了，所有人都可以调用它</p><p><strong>每次竞拍存在哪？</strong></p><p>智能合约本身有一个合约账户，里面有一个状态信息，它的存储都是在一个MPT存着的</p><p><strong>拍卖的流程：</strong></p><p>比如你的外部账户要拍卖，你要发起一个交易，这个交易要调用这个bid函数，然后这个交易要调用这个bid函数要矿工写到区块链里。任何一个人出价参与这个竞拍，调用这个bid函数的操作都需要发布到区块链里</p><p>你要竞拍就是写一个Solidity程序，然后你发布一个交易把这个合约放到网上，那别人怎么知道你这个合约，你需要线下宣传，用别的方法宣传，区块链不负责给你做这个宣传，就像你的比特币地址别人怎么能知道，你自己去宣传</p><p><strong>上图智能合约这么写的问题是什么？</strong></p><p>写智能合约一定要小心因为智能合约是不可篡改的，说的好听点儿叫不可篡改，说的不好听点儿叫你没法改bug</p><p>auctionEnd这个函数必须要某个人调用才能执行，这个也是Solidity语言跟其他编程语言不同的一个地方，就是没有办法把它设置成拍卖结束了自动执行auctionEnd，可能是拍卖的受益人beneficiary去调用这个auctionEnd，也可能是参与竞拍没有成功的人去调用，总之得有一个人去调用。如果两个人都去调用auctionEnd，矿工在执行的时候把第一个调用执行完了，然后第二个再执行就执行不了了，因为第一个执行完之后，ended就是true了，没有并发执行</p><p><img src="/../article_img/Web3/img6-21.png" alt="在这里插入图片描述"></p><p><strong>假设有一个人通过上图这样的一个合约账户参与竞拍，会有什么结果？</strong></p><p>这个合约实际上就一个函数hack_bid，这个函数的参数是拍卖合约的地址，然后把它转成这个拍卖合约的一个实例，然后调用拍卖合约用的bid函数，把这个钱发送过去。这是一个合约账户，合约账户不能自己发起交易，所以实际上得有一个黑客从他自己的外部账户发起一个交易，调用这个合约账户的hack_bid函数，然后这个函数再去调用拍卖合约的bid函数，把这个黑客外部账户转过来的钱再转给这个拍卖合约中的bid函数，就参与拍卖了</p><p><img src="/../article_img/Web3/img6-22.png" alt="在这里插入图片描述"></p><p><strong>这个合约参与拍卖没有问题，最后拍卖结束退款的时候会有什么问题？这个红框里循环退款，退到合约账户上的钱会有什么情况，退到黑客合约账户上的钱会有什么情况？</strong></p><p>黑客外部账户对拍卖合约来说是不可见的，拍卖合约能看到的只是这个黑客的合约。<strong>转账的时候没有调用任何函数，那么当一个合约账户收到转账没有调用任何函数的时候应该调用fallback函数，而这个合约没有定义fallback函数，所以会调用失败，会抛出异常，这个transfer函数会引起连锁式的回滚，就会导致这个转账操作是失败的，所有人都收不到钱了</strong></p><blockquote><p>再具体点，比如有20个人参与竞拍了，这个黑客是排在第10个，最高出价人排在第16个，那么最后是有哪些收得到钱，哪些收不到钱？</p><p>这个转账实际上是全节点执行到<code>beneficiary.transfer</code>的时候把相应账户的余额进行了调整，所有的Solidity语句就是智能合约执行过程中的任何对状态的修改改的都是本地的状态，都是改的本地的数据结构。所以这个循环当中无论是排在黑客合约前面还是后面，都是在改本地数据结构，只不过排在后面的bidder根本没有机会来得及执行，然后整个都回滚了，就好像这个智能合约从来没有被执行过。所以排在前面的这些转账并没有执行，就是改本地结构，然后如果都顺利执行完了，发布出去之后，别的矿工也把这个auctionEnd重头到尾执行一遍，也改它本地的数据结构，跟你的能对得上就叫形成共识了，而不是说每有一个转账交易的语句是产生一个新的交易写到区块链上。所以都收不到钱，没有任何一个人能收到钱</p></blockquote><p><strong>发起这个攻击的有可能是故意捣乱，写这样一个程序让大家都拿不到钱，也可能是这个人不懂，他就忘了写fallback函数了，那出现这种情况怎么办呢？比如说你发布一个拍卖合约到区块链上，吸引很多人来拍卖，拍卖完之后发现有这样一个问题这个黑客合约，你怎么办？</strong></p><p>现在的问题是你已经把钱投进去了，锁在里面了，你怎么把它取出来。答案是没有办法，出现这种情况没有办法了。Code is law，智能合约的规则是由代码逻辑决定的，而代码一旦发布到区块链上就改不了了，所谓的叫区块链的不可篡改性，这样的好处是没有人能够篡改规则，这样的坏处是规则中有漏洞你也改不了了</p><p>智能合约如果设计的不好的话，有可能把以太币永久的锁起来，谁也取不出来，所以在你发布一个智能合约之前一定要测试测试再测试，你可以在专门的那种测试的网上用假的以太币，做测试确认完全没有问题的情况下再发布</p><p><strong>那我能不能在这个智能合约里留一个后门，用来修复bug，比如给合约的创建者超级用户的权利，在这个构造函数里加一个域叫owner，记录一下这个owner是谁，然后对这个owner的地址允许他做一些系统管理员的操作，比如可以任意转账，把钱转给哪个地址都行</strong></p><p>那样的话，如果出现像这种bug，超级管理员就可以发挥作用，把锁进去的钱给转出来了，因为反正对他没有限制，他转给谁都行。但这样有可能出现卷款跑路的情况，这样做的前提是所有人都要信任这个超级用户，这个跟去中心化的理念是背道而驰的，也是绝大多数区块链的用户不能接受的</p><p><img src="/../article_img/Web3/img6-23.png" alt="在这里插入图片描述"></p><p>第二个版本，把前面那个auctionEnd拆成两个函数，左边是withdraw，右边是Pay2Beneficiary</p><p>withdraw函数这里就不用循环了，每个竞拍失败的人自己调用withdraw函数，把那一部分钱取回来。首先判断一下拍卖是不是结束了，然后看一看调用的那个人是不是最高出价者，如果是的话，不能把钱给他，因为要留着给那个拍卖的beneficiary，然后看一下这个人账户的余额是不是正的，amount是他的账户余额，把账户余额转给<code>msg.sender</code>，就是发起调用的这个人，然后把他账户余额清成0，免得他下次再来取一下钱</p><p>Pay2Beneficiary函数是说把最高出价给这个受益人，也是判断一下拍卖已经结束了，最高出价的金额大于零，下面再把它转过去</p><p><strong>这样可以了吗？</strong></p><p><img src="/../article_img/Web3/img6-24.png" alt="在这里插入图片描述"></p><p>还是有一个问题：重入攻击，如果有黑客写了上图右边这样一个程序会怎么样？</p><p>这个hack_bid跟前面的那个黑客合约hack_bid合约是一样的，通过调用拍卖bid函数参与竞拍，hack_withdraw就在拍卖结束的时候调用withdraw函数，把钱取回来，这两个看上去好像都没有问题</p><p>问题在于fallback函数，他又把钱取了一遍，左边是智能合约中的withdraw函数，hack_withdraw调用withdraw函数的时候，执行到左边第47行会向黑客合约转账，这个<code>msg.sender</code>就是黑客的合约，把它当初出价的金额转给他，而右边这个合约在干嘛？它又调用了拍卖函数的withdraw函数，又去取钱，fallback函数这里的<code>msg.sender</code>就是这个拍卖合约，因为是拍卖合约把这个钱转给黑客合约的，这个左边的拍卖合约执行到if那里，再给他转一次钱</p><p><strong>注意这个清零的操作，把黑客合约账户清零的操作，只有在转账交易完成之后，才会进行，而第47行这个转账的语句已经陷入到了跟黑客合约当中的递归调用当中，根本执行不到下面这个清零操作，所以最后的结果就是这个黑客一开始出价的时候给出了一个价格，拍卖结束之后，就按照这个价格不停地从这个智能合约中去取钱，第一次取得是他自己的出价，后面取得就是别人的钱了</strong></p><p>那这个递归重复取钱，持续到什么时候会结束？有三种情况，一个是这个拍卖合约上的余额不够了，不足以在支持这个转账的语句；第二种情况是汽油费不够了，因为每次调用的时候还是消耗汽油费的，到最后没有足够的汽油剩下来了；第三种情况，调用栈溢出了。所以右边部分黑客合约的fallback函数判断一下这个拍卖合约的余额还足以支持转账，当前调用的剩余汽油<code>msg.gas</code>还有6000个单位以上，调用栈的深度不超过500，那么就再发起一轮攻击</p><p><img src="/../article_img/Web3/img6-25.png" alt="在这里插入图片描述"></p><p>其实最简单的就是<strong>先清零再转账</strong>，就是我们右边的这种写法，右边Pay2Beneficiary写法是正确的，已经把highestBidder的账户余额清成零了，就在bids哈希表里面的余额已经清成0了，然后再转账，转账如果不成功的话，再把余额恢复</p><p>这个实际上是对于可能跟其他合约发生交互的情况的一种经典的编程模式，就<strong>先要判断条件，然后改变条件，最后再跟别的合约发生交互</strong>。在区块链上，任何未知的合约都可能使有恶意的，所以每次你向对方转账或者使调用对方某个函数的时候，都要提醒下自己，这个合约，这个函数有可能反过来调用你当前的这个合约，并且修改状态，小心一点总是好的</p><p><img src="/../article_img/Web3/img6-26.png" alt="在这里插入图片描述"></p><p>还有一种方法，就是不要用<code>call.value</code>的形式转账，对比一下修改前后的两段代码，区别就是绿框的部分。<strong>首先我们把清零的位置提前了，先清零再转账，而且转账的时候用的使sender，用transfer也可以，sender和transfer一个共同的特点就是转账的时候发送过去的汽油费只有2300个单位，这个不足以让接收的那个合约再发起一个新的调用，只够写一个log而已</strong></p><p><strong>对应课程</strong>：</p><p><a href="https://www.bilibili.com/video/BV1Vt411X7JF">北京大学肖臻老师《区块链技术与应用》公开课</a></p><p>本文转自 <a href="https://blog.csdn.net/qq_40378034/article/details/126570851">https://blog.csdn.net/qq_40378034/article/details/126570851</a>，如有侵权，请联系删除。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Web3</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>&lt;ETH&gt; GHOST、难度调整、权益证明</title>
    <link href="/2025/05/01/ETH_2/"/>
    <url>/2025/05/01/ETH_2/</url>
    
    <content type="html"><![CDATA[<p>写在前面：<br>前段时间把b站上北大肖老师的区块链课程速通了一遍，这里引一下csdn上的优质课程笔记，便于个人后续温习。<br>博客链接：<a href="https://blog.csdn.net/qq_40378034/category_11862943.html">https://blog.csdn.net/qq_40378034/category_11862943.html</a><br>课程链接：<a href="https://www.bilibili.com/video/BV1Vt411X7JF/">https://www.bilibili.com/video/BV1Vt411X7JF/</a></p><span id="more"></span><h4 id="5、ETH-GHOST"><a href="#5、ETH-GHOST" class="headerlink" title="5、ETH-GHOST"></a>5、ETH-GHOST</h4><p>以太坊把出块时间降到了十几秒，这对于提高系统的throughput（吞吐量）和降低反应时间来说都是很有帮助的，跟比特币的10分钟的出块时间相比，以太坊的出块速度相当于提高到了40倍</p><p>但是这样大幅度降低出块时间之后也带来一些新的问题，比特币和以太坊都是运行在应用层的共识协议，底层是一个P2P的Overlay Network，这个Overlay Network本身传输的时间是比较长的，因为它的拓扑协议做flooding的时候没有考虑实际的拓扑结构，就带来一个问题，发布一个区块的时候，这个区块在网络上传到其他节点可能需要十几秒的时间</p><p>对于比特币来说，10分钟的出块时间相当于600秒，足够让新发布的区块传播到网上的其他节点，即使这样，因为挖矿是个概率的过程，仍然有可能有两个矿工同时获得记账权，同时发布区块，会带来临时性的分叉；对于以太坊来说，这种临时性的分叉会变成常态，而且分叉的数目也会变得更多，因为十几秒的出块时间很有可能别的节点没有来得及收到发布的区块，还是沿着原来的区块链往下挖，可能等到收到发布的区块的时候，他自己已经挖到了新的区块</p><p>那对于共识协议来说，有什么挑战呢？比特币只有在最长合法链上的那些区块，里面所包含的出块奖励才是真正有用的，其他的一些分叉的链上的出块奖励其实最后是作废的</p><p><img src="/../article_img/Web3/img5-1.png"></p><p>比如说上图这个区块链，分了三个叉，差不多是同一个时间取得了记账权，最后中间这个区块胜出成为最长合法链，那么上面和下面的这个区块叫做orphan block或者stale block，就是挖到这个区块的矿工在里面有一个铸币交易，能够得到一定数量的比特币，但这个实际上是没有用的，因为不在最长合法链上，所以得到的出块奖励最后等于作废了</p><p>对于比特币来说，因为出现这种临时性的分叉不是很多，所以这么规定还是可以接受的。但是对于以太坊也这样处理的话，那么意味着这个矿工挖到的区块有很大概率是白挖了，对于个体矿工特别明显。从过去的经验来看，大型矿池所在的分叉更有可能成为最长合法链，这就促使别的矿工沿着大型矿池所在的分叉继续挖，因为沿着别的链去挖的话，很有可能就白挖了，这样越是大型矿池得到的收益越大，这种情况叫做centralization bias，就是中心化带来的不成比例的优势，如果以太坊按照比特币的共识机制就会有一定的问题</p><h5 id="1）、GHOST协议最初版本"><a href="#1）、GHOST协议最初版本" class="headerlink" title="1）、GHOST协议最初版本"></a>1）、GHOST协议最初版本</h5><p>以太坊中采用一个基于GHOST协议的共识机制，这个并不是以太坊发明的，在以太坊出现以前已经有GHOST协议了，以太坊对这个协议做一些修改</p><p><strong>GHOST协议的核心思想是：矿工挖到一个区块，这个区块最后作废了，为了补偿矿工所作的工作，给一些补偿</strong>。以太坊中这些作废的区块叫做<strong>Uncle Block</strong>（叔父区块），因为相对于最长合法链的当前区块来说，是他的叔父区块。<strong>最长合法链的下一个区块在发布的时候可以把叔父区块包含进来，这样的话，叔父区块可以得到 7 8 \frac{7}{8} 87​的出块奖励</strong></p><p>以太坊的出块奖励，刚开始的时候是5个以太币，17年下半年的时候改成3个以太币，所以出块奖励是 7 8 × 3 \frac{7}{8} \times 3 87​×3个以太币，所以挖到矿最后虽然没有被认可但也可以得到一定的好处，<strong>那个包含叔父区块的区块可以得到额外的 1 32 × 3 \frac{1}{32}\times 3 321​×3个以太币的奖励</strong>，加起来一共可以得到 1 32 × 3 + 3 \frac{1}{32}\times 3 + 3 321​×3+3个以太币的奖励</p><p><img src="/../article_img/Web3/img5-2.png"></p><p>一个区块最多可以包括两个叔父区块，所以上图中当中上下两个叔父区块都可以被包含进去，那么包含了两个叔父区块的区块的得到的奖励还要乘以2，就是 2 × 1 32 × 3 + 3 2 \times \frac{1}{32}\times 3 + 3 2×321​×3+3个以太币</p><p>这个协议的核心思想是对于挖到了矿，但是没有得到认可的那些矿工给予一种安慰，虽然你挖的区块没有成为最长合法链上的区块，但是仍然可以得到大部分的出块奖励，<strong>这样设计有利于鼓励系统中出现分叉之后及时进行合并</strong>，这是GHOST协议最初的版本</p><p><strong>最初的版本也有缺陷：</strong></p><ol><li><img src="/../article_img/Web3/img5-3.png"></li></ol><p>uncle block只能包含两个，如果出现第三个，第三个就不开心了，设计GHOST的目的是如果你给uncle block一点好处的话，他们不愿意合并过来，因为一旦放弃自己所在的分叉就什么好处都没有了，所以要给点好处，把他们招安过来，但是只能招安两个，如果出现第三个uncle block就没办法了。其实，只能包含两个也是有道理的，因为叔父区块得到 7 8 \frac{7}{8} 87​的出块奖励是很高的，要是不限制的话，那么以太坊中的以太币就太不值钱了</p><ol start="2"><li><img src="/../article_img/Web3/img5-4.png"></li></ol><p>区块1把区块2作为叔父区块的前提是，在挖区块1的时候已经知道叔父区块的存在了，如果已经发布了区块1，然后才知道叔父区块，这时候已经来不及了，叔父区块就变成什么好处都没有了</p><ol start="3"><li>如果这个矿工比较自私的话，矿池之间存在竞争关系，出于商业目的，有可能故意不包含叔父区块，就是挖的时候知道这个叔父区块，但是就是不包含，这样的话，对叔父区块来说， 7 8 \frac{7}{8} 87​的出块奖励是得不到的，对于他自己来说， 1 32 \frac{1}{32} 321​的出块奖励是得不到了，好像是损人不利己，但要从商业竞争的角度讲，这么做对这个矿工的损失是比较小的，对挖出叔父区块的矿工的损失是比较大的</li></ol><h5 id="2）、GHOST协议新的版本"><a href="#2）、GHOST协议新的版本" class="headerlink" title="2）、GHOST协议新的版本"></a>2）、GHOST协议新的版本</h5><p><img src="/../article_img/Web3/img5-5.png"></p><p>把协议修改一下，区块1如果没有包含叔父区块（区块2），往下再有一个区块（区块3），按道理来说区块2就不是区块3的叔父区块了，因为区块2跟区块3的爷爷来说是一辈的，但是以太坊规定不能论资排辈，区块2还可以当做区块3的叔父区块。如果再往下挖一个（区块4），那就更不对了，区块2就是区块4的曾祖父的那一辈了，但以太坊不管，区块2还是区块4的叔父区块</p><p>这么规定的好处，如果某个矿池（挖出区块1的矿工）出于竞争关系故意不把这个叔父区块（区块2）包含进去，你不包含没关系，别人可以包含，下一个区块可能不是你挖出来的，不可能最长合法链上都是你挖出来的吧。甚至有可能下一个区块是跟挖出区块2的是一家的，就是挖出区块2的矿工看到最长合法链之后会切换到这里来挖，然后把自己之前挖出的区块2给包含进去</p><p>本质就是为了改进最初版本的GHOST协议存在的一些问题，所以<strong>把叔父的定义扩展了，不一定是当代叔父，可能是隔着几代的叔父</strong>，问题就在于隔多少代呢，以太坊中怎么规定呢？</p><p><img src="/../article_img/Web3/img5-6.png"></p><p>如上图所示，M为区块链上一个区块，F是M严格意义上的叔父，E为其严格意义上的爷爷辈。以太坊中规定，如果M包含F辈区块，则F获得 7 8 \frac{7}{8} 87​出块奖励；如果M包含E辈区块，则F获得 6 8 \frac{6}{8} 86​出块奖励，以此类推向前。直到包含A辈区块，A获得 2 8 \frac{2}{8} 82​出块奖励，再往前的叔父区块，对于M来说就不再认为是M的叔父了</p><p><strong>叔父区块的定义是必须跟当前区块在7代以内有共同的祖先（at most seven generation），超过7代就不认了，换句话说，合法的叔父只有6个辈分</strong></p><p><strong>这么设计的原因</strong>：</p><ol><li>如果不限制叔父的辈分，不限制隔多少代的话，那么实现起来，对于全节点来说，要维护的状态的就太多了，因为可能要记着隔着100代以前有哪些叔父区块，发布的区块包含的叔父区块其他节点同样也是要验证一下的</li><li>设计最多隔着7代，并且这7代以内出块奖励是逐渐递减的，有利于鼓励出现分叉之后，尽早进行合并。一出现分叉就马上合并的时候能得到的出块奖励是最多的，是 7 8 \frac{7}{8} 87​，如果隔着好几代之后，出块奖励就越来越少了，隔得代数太多了就得不到任何出块奖励了</li></ol><p><strong>叔父区块的奖励叫做uncle reward，当前区块包含一个叔父区块，就会得到 1 32 \frac{1}{32} 321​的出块奖励，不管包含的是哪一个辈分的叔父</strong></p><p>设计这个协议主要是为了解决系统中出现的临时性分叉（state fork，对于区块链当前的状态产生了临时性的意见分歧）。比特币和以太坊中为什么规定最长合法链的原则？为了防止篡改，使得交易不容易被篡改，其实也是为了解决临时性分叉。最长合法链提供一个出现临时性分叉之后，进行合并的一种机制，最长链会胜出，如果这个分叉是别的原因造成的，比如说是出于对运行的区块链协议有不同的意见，那么这种方法是解决不了的</p><h5 id="3）、以太坊中的奖励"><a href="#3）、以太坊中的奖励" class="headerlink" title="3）、以太坊中的奖励"></a>3）、以太坊中的奖励</h5><p>比特币发布一个区块，实际上得到的是两部分奖励，一部分叫做block reward（出块奖励，也叫做static reward静态奖励），一部分叫做tx fee（交易费，也叫做动态奖励，因为要执行交易才能得到）</p><p><strong>以太坊中也是类似的，也有一个静态的block reward，就是那3个以太币，动态奖励叫gas fee（汽油费），区块里包含的智能合约，执行智能合约的时候可以得到汽油费。叔父区块得到 7 8 \frac{7}{8} 87​的奖励只限于block reward</strong>，就是 7 8 × 3 \frac{7}{8} \times 3 87​×3个以太币，叔父区块是得不到汽油费的。汽油费所占的比例是非常小的，大部分是出块奖励，跟比特币的情况是类似的，比特币也是tx fee只占很小一部分</p><p><strong>以太坊中没有规定定期要把出块奖励减半</strong>，比特币那么规定是为了人为制造稀缺性，以太坊中5个以太币在17年下半年降为3个以太币，不是为了人为制造稀缺性，实际上跟挖矿难度调整有关。17年出现了挖矿难度计算公式，那个难度炸弹被回调了300万个区块，这样导致挖矿难度大幅度下降，为了维护公平性，也是为了总共以太币的供给量不要出现剧烈变化，所以降到了3个以太币，这是一次性的，并没有说以后会不断地下调</p><p>比特币一般当作数字黄金，以太币有些人比喻成石油，是用来花的，用来消耗，然后可以执行智能合约的。这个比喻不是完全的恰当，因为石油花完之后就没了，以太坊中执行智能合约是要消耗gas的，但这个gas只是从一个账户转移到另外一个账户，因为发布智能合约的时候，要付出gas费，执行这个智能合约的矿工可以得到这个gas费</p><p><strong>问题1：把叔父区块包含进来的时候，叔父区块的交易要不要执行，以太坊是一个交易驱动的状态机，比特币也一样，所以在最长合法链上每次发布一个新的区块都会使当前状态转移到下一个状态，现在引入了叔父区块，要不要执行叔父区块的交易呢？</strong></p><p>不应该执行，最长合法链上的父区块和他的叔父区块包含的交易可能是冲突的。如果它们包含不同的交易，不同交易有可能是不能都执行的，账户余额花两次减两次，但是有可能一个交易花了之后，另一个交易就没法花了，所以这么包含的话，要执行叔父区块的交易，可能有些交易就包含了非法交易，他的叔父区块本身不一定是非法的，执行完父区块的交易，再去执行叔父区块的交易可能就变成非法的</p><p><strong>以太坊中只有在最长合法链上的交易才会被执行，叔父区块这些交易当前区块是不执行的，而且根本就不检查叔父区块交易的合法性，只检查叔父区块是不是一个合法发布的区块，换句话说，这个区块是不是符合挖矿难度</strong>，这个是要查的，如果不查的话，你可能根本没有获得记账权，就发布一个东西出去，也不要求在主链上，把我当成叔父就行了</p><p><strong>问题2：前面举的例子中，叔父区块的共同特点是同时分叉之后第一个区块。如果分叉之后后面还跟着一串，那些怎么办？如下图所示，上面是最长合法链，下面是分叉链，区块2算不算是区块1的叔父区块呢？</strong></p><p><img src="/../article_img/Web3/img5-7.png"></p><p>按辈分是算，那为什么不能设立一个协议，把下面分叉链当作叔父区块，给他们每个一点奖励，鼓励他合并上去，相当于以前招安的时候是单个招安，现在已经拉出一个队伍来，把整个队伍招安过来。<strong>这么规定会出现一个问题，分叉攻击就变得太便宜了</strong></p><p><img src="/../article_img/Web3/img5-8.png"></p><p>比如说在上图位置的区块上有一笔大额的转账交易A-&gt;B，B等了6个确认，认为这个交易肯定没有问题了。然后A发动分叉攻击，把钱转给他自己，这个分叉攻击要成功，需要下面这条链比上面这条链要长，这个代价是比较大的，因为风险很高，如果不能变得比上面链长，那这一长串的区块都白挖了，这就是分叉攻击的代价</p><p>但是如果把GHOST协议改了，把下面链认作叔父区块，每个给一点奖励，让他整体合并上来的话，那样，分叉攻击的风险就大幅度下降了，反正就先分叉攻击你，攻击成功就把交易回滚了，攻击失败那我招安过去，也能得到区块奖励，所以以太坊中规定，<strong>只有分叉后的第一个区块可以得到uncle reward，后面的都不行</strong></p><h4 id="6、ETH-挖矿算法"><a href="#6、ETH-挖矿算法" class="headerlink" title="6、ETH-挖矿算法"></a>6、ETH-挖矿算法</h4><p>对于基于工作量证明的系统来说，挖矿是保障区块链安全的重要手段，有时候说Block chaim is secured by mining</p><p>bug bounty：有的公司悬赏来找软件中的漏洞，如果能找到软件中的安全漏洞就可以得到一笔赏金</p><p>比特币的挖矿算法是一个天然的bug bounty，如果你能找到里面的漏洞，或者是某一个挖矿的捷径就能取得很大的利益。但是到目前为止还没有人发现有什么捷径可走，所以比特币的挖矿算法总的来说是比较成功的，是经受住时间检验的</p><p>但是比特币的挖矿算法也有一些值得改进的地方，其中有一个保守争议的问题就是<strong>挖矿设备的专业化</strong>。用普通的计算机挖不到矿，只能用专门的设备，专用的ASIC芯片来挖矿，很多人认为这种做法和去中心化的理念是背道而驰的，也跟比特币的设计初衷相违背的。中本聪最早的比特币论文，提出：One cpu, one vote。理想状况下，应该让普通老百姓也能参与挖矿过程，就用家里的桌面机、笔记本电脑，甚至手机来挖矿，这样也更安全，因为算力分散之后，有恶意的攻击者想要聚集到51%的算力发动攻击，这个难度就会大得多</p><p>所以比特币之后出现的加密货币包括以太坊设计mining puzzle的时候，一个目标就是要做到ASIC resistance，那么怎么才能设计出对ASIC芯片不友好的mining puzzle呢？</p><p>一个常用的做法就是增加mining puzzle对内存访问的需求，也就是所谓的memory hard mining puzzle。ASIC芯片相对于普通计算机而言，主要优势是算力强，但是在内存访问的性能上没有那么大的优势，同样的价格买一个ASIC矿机和买一个普通的计算机，这个ASIC矿机的计算能力是普通计算机的几千倍，但是内存访问方面的性能差距远远没有这么大，<strong>所以能设计出一个对内存要求很高的puzzle，就能起到遏制芯片的作用</strong></p><h5 id="1）、莱特币的挖矿算法"><a href="#1）、莱特币的挖矿算法" class="headerlink" title="1）、莱特币的挖矿算法"></a>1）、莱特币的挖矿算法</h5><p>莱特币曾经一度成为市值仅次于比特币的第二大货币，他的puzzle基于Scrypt，Scrypt是一个对内存性能要求较高的哈希函数，以前用于计算机安全领域，跟密码相关</p><p><strong>莱特币挖矿算法的基本思想：</strong></p><ol><li><img src="/../article_img/Web3/img5-9.png"></li></ol><p>开一个很大的数组，然后按照顺序填充一些伪随机数。seed为种子节点，通过seed进行一些运算获得第一个数，之后每个数字都是通过前一个位置的值取哈希得到的。伪随机数是说取哈希值后的值你也不知道，看上去就是乱七八糟的数一样，就好像随机数，但我们不可能真的用随机数，真的用随机数没法验证。填充完之后，数组里面的数值是有前后依赖关系的，是从第一个数依次算出来的</p><ol start="2"><li><img src="/../article_img/Web3/img5-10.png"></li></ol><p>在求解这个puzzle的时候，按照伪随机数的顺序从数组当中读取一些数，每次读取的位置跟前一个数相关。例如：第一次，从A位置读取其中数据，根据A中数据计算获得下一次读取位置B，第二次，从B位置读取其中数据，根据B中数据计算获得下一次读取位置C。这个也是一种伪随机数的顺序，因为是经过哈希运算之后得到下一个读取的位置</p><p>如果这个数组开的足够大的时候，对于挖矿的矿工来说就是memory hard，因为如果不保存数组，那么挖矿的计算复杂度会大幅度上升。比如说，在求解puzzle的时候，一开始在A这个位置，如果没有保存数组的话，还得从第一个数，依次算出这个值，然后要读取第二个位置的数，需要再算一遍算到B位置的值，下面是C也是一样，要算到C位置的值，这个计算复杂度会大幅度上升</p><p>所以要想高效的挖矿，这个内存区域是需要保存的，有的矿工可能只保存一部分内存区域的内容。比如说，这个数组当中只保留奇数位置的元素，偶数位置的元素就不存了，这样数组可以少一半，用到偶数位置的数的时候要根据另外一半去算一下，计算复杂度会提高一点，但是内存量可以减小一半，叫做time-memory trade off</p><p>这个设计的核心思想是不能像比特币那样主要进行哈希运算，要增加运算过程中对内存访问的需求。要设计一个对ASIC芯片不友好的，让普通计算机能参与的，设计的任务更像是普通计算机干的事情，而不是像一个挖矿专用的ASIC芯片干的事情。普通计算机内存很大，就要利用这个特性，设计puzzle对资源的需求，特别像是普通计算机对资源的配备比例</p><p><strong>这个puzzle好的地方是对于矿工挖矿的时候是memory hard，坏的地方是对轻节点来说也是memory hard</strong></p><p>设计puzzle的一个原则是difficult to solve, but easy to verify，<strong>这个puzzle设计的问题就在于验证这个puzzle需要的内存区域跟求解这个puzzle需要的区域几乎是一样大的，轻节点验证的时候也得保存这个数组</strong>，不然计算复杂度也是大幅度提高</p><p>这样造成一个结果就是莱特币在真正使用的时候，这个内存区域不敢设置的太大，比如说设置一个1G的数组，这对于计算机来说是不大的，但是如果是一个手机上的app，1G的内存可能就太大了。因为这个原因，实际莱特币在使用的时候，这个数组只有128K，这个是非常小的，连1M都不到，就是为了照顾轻节点，那么最后的效果怎么样呢</p><p>当初莱特币在发行的时候，目标不仅仅是ASIC resistance，还是GPU resistance，就是挖矿最好连GPU都不要用，都用普通的CPU挖矿就行了。结果后来就出现GPU挖矿的，再后来就出现用ASIC芯片挖矿的，实践证明莱特币要求的128K内存不足以对ASIC芯片的生产和设计带来实质性的障碍，所以从这一点来说，莱特币的设计目标没有达到</p><p>但是<strong>莱特币早期宣传的设计目标对于解决冷启动问题是很有帮助的</strong>，任何一个加密货币，都存在冷启动问题，包括比特币。一开始的时候，没有人知道这个加密货币，你就发行一个货币，没有人参与，这对于基于工作量证明的加密货币来说，挖矿人太少是不安全的，因为发动恶意攻击难度太低</p><p>比特币早期也是不安全的，一开始只有中本聪一个人在用，后来变成少数几个人在挖矿，那个时候，如果想对比特币发动恶意攻击是很容易的，那么比特币是怎么解决这个冷启动的问题呢？现在谁也说不清楚了，但总的来说是一个循环迭代的过程，中本聪宣传的多了，对比特币感兴趣的人就多了，然后参与挖矿人就多了，比特币就变得更安全了，价值也提高了，然后对比特币感兴趣的人就更多了，挖矿的人也更多了，然后比特币变得更安全了，价值就更进一步提高了，形成一个良性循坏</p><p>莱特币虽然没有达到当初的设计目标，但是他早期的宣传，这种更民主，让更多人参与的理念对于聚集人气来说是很重要的，所以莱特币一直到现在也是一个比较主流的加密货币。<strong>除了mining puzzle之外，莱特币跟比特币的另一个区别是来特比的出块速度是比特币的4倍，他的出块间隔是两分半，而不是十分钟，除此之外，这两种加密货币基本上是一样的</strong></p><h5 id="2）、以太坊的挖矿算法"><a href="#2）、以太坊的挖矿算法" class="headerlink" title="2）、以太坊的挖矿算法"></a>2）、以太坊的挖矿算法</h5><p>以太坊也是用一种memory hard mining puzzle，但是在设计上跟莱特币有很大的不同</p><p>以太坊用的是两个数据集，一大一小，小的是16M的cache，大的数据集是一个1G的dataset（DAG），这1G的数据集是从16M的cache生成出来的。为什么要设计成一大一小的两个数据集呢？就是为了便于验证，<strong>轻节点只要保存16M cache就行了，只有需要挖矿的矿工才需要保存1G的dataset</strong></p><p><strong>以太坊挖矿算法的基本思想：</strong></p><ol><li><p>16M的cache数据生成方式与莱特币中生成方式是比较类似的，通过seed进行一些运算获得第一个数，之后每个数字都是通过前一个位置的值取哈希获得的</p></li><li><p>和莱特币的不同点：</p><p>莱特币是直接从数组当中按照伪随机数的顺序读取一些数，然后进行运算</p><p>以太坊是要先生成一个更大的数组，以太坊中这两个数组大小并不固定，因为考虑到计算机内存不断增大，因此该两个数组需要定期增大</p><p><img src="/../article_img/Web3/img5-11.png"></p></li><li><p>大的DAG生成方式：</p><p>大的DAG中每个元素都是从小的cache中按照伪随机顺序读取一些元素，方法和莱特币里面求解puzzle的过程是类似的。如第一次读取A位置数据，对当前哈希值更新迭代算出下一次读取位置B，再进行哈希值更新迭代计算出C位置元素，从cache里面来回迭代读取256次，最终算出一个数作为DAG中第一个元素。依次类推，DAG中每个元素都是从cache里面按照伪随机数的顺序读取256次，不断进行迭代更新，最后得到一个哈希值存在里面</p><p><img src="/../article_img/Web3/img5-12.png"></p></li><li><p>求解puzzle的时候，用的是大数据集中的数，这个cache是不用的，按照伪随机数的顺序从大的数据集中读取128个数。根据区块block header和其中的nonce值计算一个初始哈希，根据其映射到某个初始位置A，读取A位置的数及其相邻的后一个位置A’上的数，根据该两个数进行运算，算得下一个位置B，读取B和B’位置上的数，依次类推，迭代64次，每次读两个数，共读取128个数。最后，计算出一个哈希值与挖矿难度目标阈值比较，若不符合就重新更换nonce，重复以上操作直到最终计算哈希值符合难度要求或当前区块已经被挖出</p></li></ol><p><img src="/../article_img/Web3/img5-13.png"></p><h5 id="3）、通过伪代码理解以太坊挖矿算法"><a href="#3）、通过伪代码理解以太坊挖矿算法" class="headerlink" title="3）、通过伪代码理解以太坊挖矿算法"></a>3）、通过伪代码理解以太坊挖矿算法</h5><p><img src="/../article_img/Web3/img5-14.png" alt="在这里插入图片描述"></p><p>第一步首先生成16M cache，cache中每个元素都是64个字节的哈希值，生成的方法与莱特币类似，第一个元素是种子的哈希，就是这个seed的哈希，后面每个元素是前一个的哈希。这个哈希的内容每隔3万个区块会变化一次，这个seed每隔3万个区块会发生变化，然后重新生成cache中的内容，同时cache的容量要增加原始大小的 1 128 \frac{1}{128} 1281​，也就是16M的 1 128 \frac{1}{128} 1281​=128K</p><p><img src="/../article_img/Web3/img5-15.png" alt="在这里插入图片描述"></p><p>第二步是从这个cache生成1G的大数据集。上图这个函数的功能是通过cache来生成dataset中的第i个元素，基本思想是按照伪随机数的顺序读取cache中的256个数，每次读取的位置是由上一个位置的数值经过计算得到的。这里用的两个函数get_int_from_item和make_item，是自己定义的，源代码中是没有的，把源代码中一些相关的内容总结成了这两个函数。这个get_int_from_item函数就是用当前算出来的哈希值求出下一个要读取的位置，然后make_item函数用cache中这个位置的数和当前的哈希值计算出下一个哈希值，这样迭代256轮，最后得到一个64字节的哈希值，作为大数据集中的第i个元素</p><p><img src="/../article_img/Web3/img5-16.png" alt="在这里插入图片描述"></p><p>这个calc_dataset是生成整个1G数据集的过程，就是不断调用calc_dataset_item函数来依次生成大数据集中的每个元素</p><p><img src="/../article_img/Web3/img5-17.png" alt="在这里插入图片描述"></p><p>上图的两个函数，分别是矿工用来挖矿的函数和轻节点用来验证的函数</p><p>先看hashimoto_full这个函数，这个是矿工用来挖矿的函数。它有四个参数，第一个参数header是当前要生成的区块的块头，以太坊和比特币一样，挖矿只用到块头的信息，这样设计的原因是，轻节点只下载块头就可以验证这个区块是否符合挖矿的难度要求；第二个参数nonce就是当前尝试的nonce值，以太坊就像比特币一样，挖矿的时候，也是要尝试大量的nonce才能找到一个符合要求的，第三个参数full_size是大数据集中元素的个数，元素的个数每3万个区块会增加一次，增加原始大小的 1 128 \frac{1}{128} 1281​也就是1G的 1 128 \frac{1}{128} 1281​=8M；最后这个参数dataset就是前面生成的大数据集。挖矿的过程是这样的，首先根据块头的信息，和当前nonce算出一个初始哈希值，然后要经过64轮的循环，每一轮循环读取大数据集中两个相邻的数，读取的位置是由当前哈希值计算出来的，然后再根据这个位置上的数值来更新当前的哈希值，这跟前面生成大数据集的方法是类似的，循环64次，最后返回一个哈希值，跟挖矿难度目标域值相比较</p><p><strong>问题：每次读取大数据集中两个相邻位置的哈希值，这两个哈希值有什么联系吗？</strong></p><p>其实是没有联系的，它们虽然位置相邻，但是生成的过程是独立的，每个都是由前面那个16M的cache中的256个数生成的，而且256个数的位置是按照伪随机数的顺序产生的，这个是<strong>构造大数据集的一个特点，每个元素独立生成，这才给轻节点的验证提供了方便</strong>，所以每次读取的相邻两个位置的哈希值是没有什么联系的</p><p>hashimoto_light这个函数是轻节点用来验证的函数，也是有四个参数，但是含义跟上面那个矿工用的函数有所不同。轻节点是不挖矿的，当他收到某个矿工发的区块的时候，这里用来验证的函数的第一个参数header是这个区块的块头；第二参数是包含在这个块头里的nonce，是发布这个区块的矿工选好的；轻节点的任务是验证这个nonce是否符合要求，验证用的是16M的cache，也就是最后的参数cache；第三个参数full_size仍然是大数据集的元素个数，跟上面那个挖矿的那个full_size含义是一样的，并不是cache中的元素个数</p><p>验证的过程也是64轮循环，看上去与挖矿的过程类似，只有一个地方有区别：每次需要从大数据集中读取元素的时候，因为轻节点没有保留大数据集，所以要从cache中重新生成其他地方的代码逻辑是一样的，每次从当前的哈希值算出要读取的元素的位置，这个位置是指在在大数据集中的位置，但是轻节点并没有这个大数据集，所以要从cache中生成大数据集中这个位置的元素，大数据集中每个元素都可以独立生成出来</p><p><img src="/../article_img/Web3/img5-18.png" alt="在这里插入图片描述"></p><p>最后这个函数，是矿工挖矿的主循环，其实是不断尝试nonce的过程，这里的target就是挖矿的难度目标，跟比特币类似，也是可以动态调整的，nonce的可能取值是从0-2的64次方，对每个nonce用hashimoto_full函数算出一个哈希值，看看是不是小于难度目标，如果不行的话，就再试下一个nonce</p><p><img src="/../article_img/Web3/img5-19.png" alt="在这里插入图片描述"></p><p>最后这一页是前面讲过的所有函数的一个汇总，同时解释了为什么轻节点可以只保存cache，而矿工要保存整个大数据集。其实轻节点做一次验证的计算量也不算少，同样要经过64轮循环，每次循环用到大数据集中的两个数，所以是128个数，每个数是从cache里的256个数计算得到的，跟比特币相比，以太坊中验证一个nonce的计算量要大很多，但是仍然在可以接受的范围内，相比之下，如果矿工每次都这么折腾的话，代价就太大了，因为要尝试的nonce就太多了</p><p>到目前为止，以太坊挖矿主要还是以GPU为主，用ASIC矿机的很少，所以从这一点来说，它比莱特币来说要成功，起到了ASIC resistance的作用，这个跟以太坊的挖矿算法需要的大内存是很有关系的，这个挖矿算法就是ethash，矿工挖矿需要1G的内存，跟莱特币的128K比，差了有八千多倍，即使是16M的cache跟128K比，也要大了一百多倍，所以这个差距是很大的，而且还是按照这两个数据集的最初的大小算的，因为定期会增长嘛，如果按照现在这个2.5G差距就更大了</p><h5 id="4）、权益证明（POS：Proof-of-Stake）"><a href="#4）、权益证明（POS：Proof-of-Stake）" class="headerlink" title="4）、权益证明（POS：Proof of Stake）"></a>4）、权益证明（POS：Proof of Stake）</h5><p>以太坊没有出现ASIC矿机还有另外一个原因，以太坊从很早就计划要从<strong>工作量证明转向权益证明</strong>，所谓的POW-&gt;POS（Proof of Stake）。所谓的<strong>权益证明，就是按照所占的权益进行投票来形成共识</strong>，就不用挖矿了，权益证明是不挖矿，就类似于股份公司按照股票多少来进行投票，这个对于ASIC矿机的厂商来说是个威胁，因为ASIC芯片的研发周期是很长的，一款芯片从设计研发流片到最后生产出来，一年的周期就已经算是很快的了，而且研发的成本也很高，将来以太坊转入权益证明之后，就不挖矿，那些投入的研发费用就白费了</p><h5 id="5）、预挖矿（Pre-Mining）"><a href="#5）、预挖矿（Pre-Mining）" class="headerlink" title="5）、预挖矿（Pre-Mining）"></a>5）、预挖矿（Pre-Mining）</h5><p>以太坊中采用了<strong>预挖矿</strong>（Pre-Mining），所谓预挖矿并不是说真的去挖矿，而是说，<strong>在当初发行货币的时候，预留一部分货币给以太坊的开发者</strong>，有点像创业公司会留一部分股票给创始人和早期员工一样，将来这个加密货币成功了的话，这些预留的币就变得是很值钱了</p><p>跟比特币相比，比特币就没有采用pre-mining的模式，所有的比特币都是挖出来的，只不过早期的时候，挖矿的难度，要容易的多，与pre-mining相关的一个概念叫pre-sale（就是把pre-mining预留的那些币通过出售的方法来换取一些资产用于加密货币的开发工作），有点类似于众筹，如果你看好这个加密货币的未来，可以在pre-sale的时候买入，将来这个加密货币成功之后呢，同样可以赚很大一笔钱</p><h4 id="7、ETH-难度调整"><a href="#7、ETH-难度调整" class="headerlink" title="7、ETH-难度调整"></a>7、ETH-难度调整</h4><h5 id="1）、以太坊难度调整"><a href="#1）、以太坊难度调整" class="headerlink" title="1）、以太坊难度调整"></a>1）、以太坊难度调整</h5><p>比特币是每隔2016个区块会调整一下挖矿难度，目的是维持出块时间在十分钟左右，以太坊是每个区块都有可能调整挖矿难度，调整的方法也比较复杂也改过好几个版本</p><p><img src="/../article_img/Web3/img5-20.png"></p><p>上图是以太坊的难度调整公式，H是指当前这个区块， H i H_i Hi​是这个区块的序号，D(H)是这个区块当前的难度。这个难度调整的公式有两部分，max括号里的是第一部分，管它叫基础部分，目的是为了维持出块时间大概在十五秒左右；后面跟的是第二部分，也称为难度炸弹，主要是为了向权益证明过渡，将来的以太坊想把共识机制从工作量证明逐步转入权益证明</p><p>第一部分调整的方法是在父区块的难度基础上，加上一些自调整的部分，P(H)就是父区块的难度，所谓的父区块就是当前区块链的最后一个区块，对于我们正在挖的这个区块来说，它是这个区块的父区块</p><p>第一部分的难度调整有一个下限，就是这里的 D 0 D_0 D0​，131072，这一部分无论你去怎么调整，最小不能低于这个难度，这是为了保证挖矿有一个最低的难度</p><p><img src="/../article_img/Web3/img5-21.png"></p><p>上图是自适应难度调整部分，先看一下第一部分，x是调整的力度，是父区块的难度除以2048，所以调整难度时，无论上调下调，都是按照这个力度的整数倍进行调整的，按照父区块的难度的 1 2048 \frac{1}{2048} 20481​作为调整的一个单位</p><p>下面那个奇怪的符号是y-后面的一项，这个符号的取值跟两个因素有关，一个是出块时间，另外一个是有没有叔父区块，就是父区块有没有叔父区块，那么为什么要跟叔父区块相关呢？</p><p>因为如果是当前区块的最后一个区块，它包含有一个叔父区块的话，这个时候，系统中的货币总供应量是增加的，因为叔父区块要得到出块奖励，那么包含叔父区块的这个父区块也有得到一定的奖励，所以这两个合在一起就会使货币的总供应量增加，为了维持系统中的总供应量的稳定，一种平衡，所以挖这个区块的难度就要提高一个单元</p><p>后面这个-99是说难度调整系数部分有一个下限，Max前面这部分有可能是正的，有可能是负的，如果是负的话，说明难度要往下调，最多一次性只能调整99个单元，每个单位是父区块难度的 1 2048 \frac{1}{2048} 20481​，所以一次性下调难度最多是 99 2048 \frac{99}{2048} 204899​</p><p><img src="/../article_img/Web3/img5-22.png"></p><p>上图这个公式，y就是我们说的取决于有没有叔父区块，有叔父区块的话，y&#x3D;2，没有叔父区块的话，y&#x3D;1，那么不论是哪种情况，都是常数，所以都是常数减去后面这一项，但如果后面这一项比前面这个常数大的话，减出来是个负数，说明这个难度是要下调的。相反，如果后面那一项比前面那一项要小的话，减出来就是个正数，说明难度要上调</p><p>H S H_S HS​是当前区块的时间戳， P ( H ) H S P(H)H_S P(H)HS​是父区块的时间戳，这两项相减， H S − P ( H ) H S H_S - P(H)H_S HS​−P(H)HS​就是当前区块的出块间隔，这个出块间隔除以9，然后向下取整</p><p>如果当前区块的出块时间在1-8秒之间，后面往下取整的那一部分算出来是0，y-0&#x3D;y，假设没有叔父区块，那么y是等于1的，那么这整个就是等于是1，说明这种情况下，难度要上调一个单位，因为我们希望保证稳定的出块时间是在15秒，现在的出块时间变成了1-8s，说明出块速度有点太快了，把难度上调一个单位维持下平衡</p><p>如果出块时间是在9-17s之间，后面是1，前面也是1，1-1&#x3D;0，说明这个时候出块时间是符合要求的，希望是15s，实际是9-17s之间，这个时候可以不用调，光考虑基础部分，不考虑难度炸弹的话，就是基本上可以不用调</p><p>如果出块时间是在18-26s之间，那么后面那项算出来是2，变成了1-2&#x3D;-1，说明难度要下调一个单位，如果出块时间更长呢，比26s更长，那么下调的幅度也会更大</p><p>上图这个公式里max的第二项有一个-99，如果单次的出块时间非常非常长，你可能前面算出来是个负的很厉害的数，但是你一次性下调也不能超过99个单位，这是为了防止一些系统中出现的异常情况，像一些黑天鹅事件，正常情况下，不能出现这个幅度的下调</p><h5 id="2）、难度炸弹"><a href="#2）、难度炸弹" class="headerlink" title="2）、难度炸弹"></a>2）、难度炸弹</h5><p><strong>为什么要设置难度炸弹？</strong></p><p>以太坊的共识机制要从工作量证明逐步转入权益证明，而权益证明是不挖矿的，这就带来一个问题，那些已经在挖矿设备上投入大量资金的矿工会不会联合起来抵制这个转换</p><p>因为矿工已经花了好多钱购买矿机，现在被告知要搞权益证明了，那这些挖矿设备都没用了，那矿工肯定有意见，所以以太坊就担心大家不愿意转入权益证明，本来从工作量证明转入权益证明就是要经过硬分叉来实现，相当于你改了这个共识协议了，如果因为这些挖矿设备有些人不原意转过来，造成社区的分裂，可能出现的情况是，以太坊可能出现两条平行的链，为了避免这种情况，所以以太坊在设计这个难度调整公式的时候就加了一个难度炸弹</p><p><img src="/../article_img/Web3/img5-23.png"></p><p>最初设计这个难度炸弹的时候，没有第二行，没有减去三百万这一行，第一行直接用的就是 H i H_i Hi​，当前区块的序号，没有 H i ′ H_i’ Hi′​这一项，就是当前的区块号除以10万，向下取整，然后作为2的指数，也就是说，难度炸弹这部分的取值，是从指数形式增长的</p><p>早期的时候，以太坊刚刚上线不久的时候，区块号都比较小，所以难度炸弹这部分算出来的值是很小的，基本上可以忽略不计，那么难度调整主要还是由难度调整的第一部分（基础部分）来决定的，或者说是由系统中的出块时间来决定的</p><p>然而随着时间的推移，区块号变得越来越大，这个时候难度炸弹的威力开始显现出来，指数函数增长到后期，速度是非常恐怖的，所以当初设计的思想是等到这个难度炸弹的威力开始发挥出来的时候，也正是从以太坊需要从工作量证明转入权益证明的时候，那个时候因为挖矿变得越来越难了，所以大家也就原意转入权益证明了，因为如果不转的话，要挖出矿来，就太费劲了</p><p>但实际情况，基于权益证明的共识机制实际设计出来有很多问题要解决，远远没有当初想象的那么顺利，这样造成的结果就是，转入权益证明的时间点被一再的推迟，然后出现的情况就是挖矿已经变得越来越难了，因为难度炸弹的威力已经显现出来了，但是大家还是得继续挖，因为没有别的方法可以达成共识</p><p>原来是担心大家不愿意转，现在变成了想转也没法转，因为权益证明的共识机制还没有开发出来，这个情况到2017年四五月份中旬的时候就已经很明显了，出块时间已经逐渐开始增长了，原来是说要稳定在15秒，那个时候就不断的变成了从15秒不断地增加，16秒，17秒，最后增加到30秒左右，而且如果不采取措施，还会继续增长上去</p><p><strong>难度炸弹调整：</strong></p><p>以太坊最后在一个EIP当中，决定计算难度炸弹地时候，要把区块号回退300万个区块来计算，就这个公式中，把真实的区块号减去三百万，算出 H i ′ H_i’ Hi′​，这个可以看成是假的区块号，然后算难度炸弹的时候是用这个假的区块号算的，这个给权益证明的上限争取了一些时间</p><p><img src="/../article_img/Web3/img5-24.png"></p><p>上图中，y轴是难度炸弹的取值，x轴是区块号，是以10万为单位，可以看到早期的时候，区块号比较小的时候，这个难度炸弹的作用是很不明显的，基本可以忽略不计，难度调整基本上是根据系统中的出块时间进行调整的，然后，这个图的前半部分是按照原来那个公式算的，就是在没有决定回调之间的原始公式算的，直接用正常的区块号算。大概是370万个区块左右，这个难度炸弹的威力开始指数上升，到上面这个尖峰，这个尖峰的位置就是以太坊决定回调这个难度炸弹的时候，减了三百万个区块，所以这个难度炸弹的取值一下就掉下来了，后面看上去好像是个平的直线，其实也是在增长，只不过是因为那个尖峰的位置太高了，所以看上去好像是直线，前面这个部分其实也是在增长，也是因为这个尖峰太高了，所以看不出来</p><h5 id="3）、以太坊发展的四个阶段"><a href="#3）、以太坊发展的四个阶段" class="headerlink" title="3）、以太坊发展的四个阶段"></a>3）、以太坊发展的四个阶段</h5><p><img src="/../article_img/Web3/img5-25.png"></p><p>以太坊的发展被分成了四个阶段，Frontier、Homestead、Metropolis,Serenity，其中Metropolis又分为两个阶段，Byzantium和Constantinople，我们处于Byzantium阶段（拜占庭阶段），难度炸弹的回调就是在Byzantium阶段进行的</p><p>EIP：Ethereum Improvement Proposal，BIP:BitCoin Improvement Proposal</p><p><strong>在难度回调的同时，把出块奖励从5个以太币降到了3个以太币</strong>，因为如果不这么调的话，对于回调之前的矿工是不公平的。这个回调是突然进行的，昨天挖矿的时候挖的很辛苦，得到的是5个以太币，结果今天一夜之间难度降低了，你挖矿也是得了5个以太币，那对我来说就不公平，而且从系统当中获益的总供应量来说要维护总供应量的稳定，现在变得是挖矿要容易了，所以就相应的把出块奖励减少一些，这里说明一点，<strong>比特币当中每隔一段时间出块奖励减半的做法在以太坊中是没有的，像这个把5个以太币降低3个就是一次性的，并不是说以后定期都这么做</strong></p><h5 id="4）、难度调整具体代码实现"><a href="#4）、难度调整具体代码实现" class="headerlink" title="4）、难度调整具体代码实现"></a>4）、难度调整具体代码实现</h5><p><img src="/../article_img/Web3/img5-26.png" alt="在这里插入图片描述"></p><p>上图是Byzantium阶段挖矿难度调整的代码，输入是父区块的时间戳和父区块的难度，计算出当前挖的这个区块的难度。这里面的注释给出了难度计算公式，也是分成两部分，括号里面是第一部分是难度调整的基础部分，后面加上2的periodCount-2次方，这就是难度炸弹，基础部分是在parent_diff的基础上加上后面那一项，后面那一项就是前面这个难度调整的力度，parent_diff&#x2F;2048乘以后面的系数，后面max的前面那一串就是前面ppt公式的那个y，如果有叔父区块是2，没有的话是1，减去后面这个就是出块间隔除以9向下取整，后面这个-99也是难度调整的下限</p><p>下面这几行代码，bigTime就是当前区块的时间戳，bigParentTime就是父区块的时间戳</p><p><img src="/../article_img/Web3/img5-27.png" alt="在这里插入图片描述"></p><p>上图的代码主要是计算基础部分的难度调整，第一行就是把当前时间戳减去父区块的时间戳算出出块时间，然后第二行除以9向下取整</p><p>下面这个if else就是判断一下是不是有叔父区块，有的话，是用2减去前面这个数x，没有的话用1减去前面这个数x，然后接下来跟负的99相比，往下调有一个节限，不能比-99还要小，接下来算的是难度调整的力度，父区块的难度除以这个DifficultyBoundDivisor实际上就是2048，然后跟前面算出的系数相乘，加到父区块的难度上面去，基础部分的难度调整有一个下限，难度再小也不能小于那个 D 0 D_0 D0​，这个MinimumDifficulty就是那个 D 0 D_0 D0​：131072</p><p><img src="/../article_img/Web3/img5-28.png" alt="在这里插入图片描述"></p><p>上图是难度炸弹的计算，fakeBlockNumber假的区块号就是前面讲的 H i ′ H_i’ Hi′​。下面这个if的判断跟2999999相比，比它大的话，就要减掉2999999，为什么不减3000000，前面的公式不是减三百万吗？因为这里判断的是父区块的序号，而我当前挖的这个区块，比父区块要多一个，所以按照父区块的序号算的话，就正好差一个</p><h4 id="8、ETH-权益证明"><a href="#8、ETH-权益证明" class="headerlink" title="8、ETH-权益证明"></a>8、ETH-权益证明</h4><h5 id="1）、POW机制能耗状况"><a href="#1）、POW机制能耗状况" class="headerlink" title="1）、POW机制能耗状况"></a>1）、POW机制能耗状况</h5><p>比特币和以太坊目前都是基于工作量的证明，这种共识机制收到了一个普遍的批评就是浪费电</p><p><img src="/../article_img/Web3/img5-29.png"></p><p>上图展示的是比特币能耗随时间变化的情况，y轴是TWh是Terawatt Hours，这是 1 0 12 10^{12} 1012，KWh&#x3D;Kilowatt hours，是 1 0 3 10^3 103，所谓叫千瓦时，一度电的意思，通过这个图可以看出比特币能耗随时间是不断增长的</p><p><img src="/../article_img/Web3/img5-30.png"></p><p>上图是比特币的能耗统计数据：</p><p>比特币每年的总能耗，大概是70个TWh，相当于治理这个这个国家的能耗，也相当于647万多美国家庭的能耗，占全世界总能耗的0.31%</p><p>具体到每个交易上来说，平均每个交易的能耗是1014个千瓦时，相当于34.26个美国家庭一天的能耗，这个能耗是相当大，一个交易要花1000度电，信用卡公司处理一个交易的能耗远远到不了这个数字</p><p>比特币挖矿的每年总收入是60多亿美元，接近61亿美元，费用是差不多35亿美元，占总收入的57.48%，说明挖矿的利润空间还是很大的</p><p><img src="/../article_img/Web3/img5-31.png"></p><p>上图是以太坊的统计数据，以太坊的能耗也是随时间增长的，中间有一些波动</p><p><img src="/../article_img/Web3/img5-32.png"></p><p>从具体的数据上来看，以太坊一年的能耗大概是20个TWh，跟刚才比特币的70个还是少了不少，相当于冰岛这个国家的能耗，也相当于183万个美国家庭的能耗，能耗占全世界总能耗的0.09%，平均到每个交易上，每个交易是67个千瓦时，相当于2.25个美国家庭一天的能耗</p><p>从道理上讲，比特币的交易是比较简单的，就是一些单纯的转账交易，以太坊的交易有可能包含对智能合约的调用，所以以太坊的能耗应该更高才对，而实际上是比比特币要低了很多，一个是67度电，一个是1000多度电。因为出块时间长，比特币要10分钟才能挖出一个区块，以太坊15秒就可以挖出一个区块，所以以太坊的出块时间很短，挖矿挖的时间就短，所以每个交易平均下来的能耗要小很多，当然以太坊的这个单位交易的能耗仍然比信用卡公司要高的很多</p><p><img src="/../article_img/Web3/img5-33.png"></p><p>以太坊每年挖矿的收入是50多亿美元，费用接近24亿美元。如果把比特币和以太坊的能耗加在一起当作一个国家来算的话，它在国家中的排行榜是这样的，芬兰，比利时，巴基斯坦，然后就是比特币加以太坊，然后是哈萨克斯坦，阿联酋，荷兰</p><h5 id="2）、思考"><a href="#2）、思考" class="headerlink" title="2）、思考"></a>2）、思考</h5><p>挖矿的过程这些能耗是不是必须的，思考几个问题：</p><p>矿工为什么要挖矿？为了取得出块奖励，为了获得收益</p><p>为什么要给矿工这些收益，这些出块奖励呢？为了激励矿工参与区块链的维护</p><p>那矿工具体是怎么挖矿的呢，比如说你决定参与挖矿要成为一个矿工，你需要怎么做？你需要找一笔挖矿资金，然后去买这些设备，可以买矿机、GPU，然后开始挖矿</p><p>那挖矿的收益是由什么决定的？是由你算力所占的比例决定的，是由你有多少矿机，占了多少硬件设备，最终是由你投入的资金决定的</p><p>那既然最终是拼钱，那么直接把钱拿出来比一比不就行了吗。现在是矿工通过竞争算力来决定挖矿的收益如何分配，能不能改成直接靠比钱的多少来决定收益。比如我出100万，你出50万，现在的做法是咱们用这些钱去买矿机，然后用这个矿机开始挖矿，比拼下算力，看谁挖的区块多，那与其这样，还不如我们都<strong>把这些钱投入区块链开发，将来就按照每个人投入的资金的多少来决定收益的分配</strong>。那还挖矿干嘛，直接拼钱不就行了，这个就是权益证明的一个基本思想，有时候管这种方法叫做virtual mining（虚拟挖矿）</p><h5 id="3）、权益证明"><a href="#3）、权益证明" class="headerlink" title="3）、权益证明"></a>3）、权益证明</h5><p><strong>采用权益证明的加密货币，一般在正式发行之前，会先预留一部分货币给开发者，也会出售一部分货币，来换取开发这个加密货币所需要的资金，将来按照权益证明的共识机制，每个人是按照持有货币的数量来进行投票的，那这种方法跟工作量证明相比有什么优点？</strong></p><p>一个明显的好处是，省去了挖矿的过程，也避免了因此产生的能耗和对环境影响，减少了温室气体的排放</p><p>基于工作量证明的共识系统从某种意义上来说，维护区块链安全的资源不是一个闭环，这是什么意思呢？我们说Block chain is secured by mining，用美元可以购买矿机，然后参与挖矿，也就是说，是从加密货币系统的外面得到的。虽然16、17年加密货币的市值有了很大的增长，但是18年开始又下跌了不少，无论怎么说，它跟世界经济总量相比，仍然是微乎其微的，比如说美国股市的总市值相比，这两个完全不在同一个数量级上。所以如果有某个组织想要发动恶意攻击，只需用足够的资金来购买挖矿设备，然后聚集到加密货币总算力一半以上的算力就行了，也就是说，发动这种攻击所要的资源是可以从外面的世界得到的</p><p>像比特币这样比较主流的加密货币，抗攻击的能力还是相对比较强的，因为系统的总算力还是比较大的，如果是一些刚刚发行的小的这种遇到这样的攻击可能就是致命性的。如果这种小的币种刚刚发行不久，就遇到这种攻击，那么很可能这个币价就直线下降甚至归零了，那么对于这个开发者和早期矿工来说，遭受的损失可能是灾难性的，专门有一个词叫做AltCoin Infanticide（Infant：婴儿，Infanticide：扼杀在摇篮里），不等这个加密货币长大，就把它先干掉了</p><p><strong>那么如果采用的是权益证明，情况会有什么不同呢？</strong></p><p>有点类似于股份制公司按每人占的股份进行投票，权益证明是按照你有多少这个币种的币进行投票的，所以如果有某个人想发动恶意攻击，比如说51%的攻击，他首先要获得这个币种发行量一半以上的份额才行，也就是说<strong>发动攻击的资源只能从加密货币系统内部得到，这就是为什么说它是一个闭环</strong></p><p>无论这个组织者在外面有多少钱，都不会对这个加密货币造成直接的影响，必须用这些钱去买币，买到足够多的币然后才能发动攻击。而一旦有人大量买入加密货币，会出现价格大涨，本来一个刚刚发行的小币种，没有多少人买的，价值也不高，突然有人为了搞垮它大量买入这种币种，让它价格大涨，如果你是这个币的开发者或者是早期投资者，出现这种情况你会怎么想？你会觉得这不一定是坏事啊，我正好可以从中大赚一笔，有点类似于股份制公司遭受恶意收购，就为什么说工作量证明的系统维护它安全的资源不是一个闭环，权益证明才是一个闭环</p><p><strong>权益证明和工作量证明并不是互斥的，有的加密货币采用的是一种混合模型，它仍然是要挖矿的，但是挖矿的难度跟你占有的权益，你持有多少币是相关的</strong></p><p>比如说每个矿工持有一定数量的这个币，挖矿的时候你持有的币越多，挖矿的难度就越小，根据你持有的这个币的权益降低你的挖矿难度。但如果就像这么简单去设计，其实是有一定问题的，那样的话，系统中持有币数量最多的那个人，每次挖矿都是最容易的。所以有的加密货币要求你投入的币会被锁定一段时间，不能重复使用，比如挖当前区块的时候，你投入一定数量的币，用于降低挖矿难度，等这个区块发布出来之后，你投入的这些币就会被锁定一段时间，下次再挖下一个区块的时候，这个币就不能再用了，要过一段时间，过多少个区块以后，才能再重复使用，这个有时候管它叫做Proof of Deposit</p><p><strong>基于权益证明的共识机制该怎么设计有很多挑战，其中这种早期的权益证明遇到的一个挑战就是两边下注的问题</strong></p><p><img src="/../article_img/Web3/img5-34.png"></p><p>比如说有这样上图这样一个区块链，出现了分叉。如果是挖矿的话，会沿着上面这条链去挖，因为这个是最长合法链，其实下面那条链也有可能成为最长合法链，如果连续挖出好几个区块，它有可能比上面那条链还要长，但是你不会两个都挖，两边都挖的话，算力分散了，挖到的概率就小了。但是用权益证明的话，可以两边都下注，如果上面那条链成为最长合法链，下面那条链锁定的那些币是没有影响的，比如说，你挖下面区块投入的那些币，只是记录在下面的分叉上，并不影响你在上面分叉的使用，这个叫做nothing at stake，这是早期基于权益证明遇到的一个问题</p><h5 id="4）、以太坊准备采用的权益证明"><a href="#4）、以太坊准备采用的权益证明" class="headerlink" title="4）、以太坊准备采用的权益证明"></a>4）、以太坊准备采用的权益证明</h5><p>以太坊中准备采用的权益证明协议叫做Casper the Friendly Finality Gadget（FFG），该协议在过渡阶段也是要跟工作量证明混合使用的，为工作量证明提供叫做Finality，<strong>Finality是一种最终的状态，包含在Finality中的交易不会被取消</strong></p><p>单纯基于工作量证明就基于挖矿的交易是有可能被回滚的，就比如说，某个交易被写到区块链上，然后有人从前面开始分叉，挖出一条更长的分叉链，这个时候原来写入区块链的那个交易有可能就无效了，比特币当中规定要等六个确定区块，那个只是说等了六个确定区块之后，发生回滚的可能性已经非常小了，但是有个某个有恶意的攻击者，从前面开始分叉，只要他算力足够强占到半数以上的算力，那么仍然有可能让这个分叉链变得比原来的链更长，所以单纯基于挖矿的是缺乏这种Finality</p><p>Casper协议引入了一个概念叫做<strong>验证者Validator，要想成为一个Validator必须要投入一定数量的以太币作为保证金，这个保证金会被系统锁定。Validator的职责是要推动系统达成共识，投票决定那条链是最长合法链，投票的权益决定于保证金的数目大小</strong></p><p>具体的做法有点类似于数据库里的two-phase commit，混用的时候还是有人挖矿的，挖矿的时候，<strong>每挖出100个区块就作为一个epoch，然后决定能不能成为Finality，要进行一些投票，第一轮投票是一个Prepare Message，然后第二轮是Commit Message，Casper规定每一轮投票都要得到 2 3 \frac{2}{3} 32​的验证者才能通过，这是按照保证金的金额大小来算的</strong></p><p><strong>实际系统当中不再区分这两个Message，而且把这个epoch从原来的100个区块减少到50个区块，变成了每50个区块就是一个epoch，每个epoch只用一轮投票的就行了，这一轮投票对于上一个epoch来说是个Commit Message，对于下一个来说是一个Prepare Message，那么要连续两轮投票，两个epoch都得到 2 3 \frac{2}{3} 32​以上的多数，才算有效</strong></p><p><img src="/../article_img/Web3/img5-35.png"></p><p>上图是一条区块链，两个虚线中间间隔了100个区块，原始版本的Casper协议是把中间是间隔了100个区块定义成一个epoch，然后结束有两轮投票，每一个要 2 3 \frac{2}{3} 32​的验证者才能算通过，这是原始的版本</p><p><img src="/../article_img/Web3/img5-36.png"></p><p>优化以后，原来100个区块的epoch，变成了50个区块的epoch，然后每个epoch结束的时候只要一轮投票，对于前一个epoch来说是Commit Message，对于后一个epoch来说是Prepare Message，然后有连续两个投票的都要有 2 3 \frac{2}{3} 32​的验证者支持才算通过</p><p><strong>那验证者参与有什么好处呢？</strong></p><p><strong>如果验证者履行职责的话，可以得到相应的奖励</strong>，就像矿工挖矿能得到出块奖励一样，验证者做这个工作也可以得到这个奖励。<strong>相反如果验证者有不良行为被发现的话，要受到相应的处罚</strong>，比如某个验证者行政不作为，该投票的时候不去投票，结果导致系统迟迟达不成共识，这种情况下要扣掉他的一部分保证金；如果某个验证者，乱作为乱投票，给两个有冲突的分叉都投票，就两边下注，这种情况被发现的话，要没收全部的保证金，没收到保证金被销毁掉了，相当于减少了系统中以太币的总供应量</p><p><strong>每个验证者有一定的任期</strong>，即使你交了保证金也不是可以永远当验证者，<strong>任期满了之后要经过一定时间的等待期</strong>，等待期是为了让其他的验证者检举揭发这个验证者有没有什么不良的行为，进行惩处，如果等待期过了，没有什么问题，验证者可以取回当初的保证金和得到的奖励，这就是Casper协议的一个过程</p><p><strong>Casper协议可以给挖矿完成一个区块链的某一种状态，做一个check point（检查点），那这个check point是不是绝对安全的？换句话说，通过这个验证者投票达成的Finality有没有可能被推翻？</strong></p><p>原来说包含在Finality里的交易是不会被推翻的，这个是不是绝对的，假设有某个有恶意的组织要发动攻击，如果这个组织仅仅是矿工的话，他是没有办法推翻已经达成的Finality，因为Finality是验证者投票投出来的，单纯是有恶意的矿工，无论他算力有多强，如果没有验证者作为同伙是不可能推翻的</p><p>那什么情况下会出现攻击成功的情况，一定是有大量的验证者两边下注，Casper协议要求每轮投票有 2 3 \frac{2}{3} 32​以上的验证者支持才算通过，如果出现这种情况，至少是 1 3 \frac{1}{3} 31​的验证者是两边都投票的，一旦发现，这 1 3 \frac{1}{3} 31​的验证者的保证金将会被没收，所以可以看到基于权益证明的共识机制和基于工作量证明的共识机制是很不一样的</p><p><strong>以太坊是要逐步从工作量证明过渡到权益证明，随着时间的推移，挖矿得到的奖励是越来越少的，权益证明得到的奖励是越来越多的，最后达到完全不用挖矿的境界</strong></p><p><strong>那既然权益证明这么好，以太坊为什么不从一开始就用权益证明呢？</strong></p><p>因为权益证明不是很成熟，工作量证明是比较成熟的，是经过了时间的检验，比特币和以太坊的挖矿算法都经历了bug bounty的检验，没有人发现什么漏洞，很多人认为权益证明是未来的方向，但是目前主流的加密货币用的还是工作量证明</p><h5 id="5）、其他观点"><a href="#5）、其他观点" class="headerlink" title="5）、其他观点"></a>5）、其他观点</h5><p>对于挖矿消耗大量电能这个观点有人提出了不同的看法，他们认为其所消耗的电能所占比值并不大，而且其对于环境的影响是有限的</p><p>挖矿的一个好处是提供了把电能转化成钱的一种手段。而电能本身难以传输和存储，比特币矿产都是建在电力丰富的地方，所以有人认为挖矿消耗电能并不是坏事，可以有效的化解过剩产能，带动当地经济的发展</p><p><strong>对应课程</strong>：</p><p><a href="https://www.bilibili.com/video/BV1Vt411X7JF">北京大学肖臻老师《区块链技术与应用》公开课</a></p><p>本文转自 <a href="https://blog.csdn.net/qq_40378034/article/details/126559694">https://blog.csdn.net/qq_40378034/article/details/126559694</a>，如有侵权，请联系删除。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Web3</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>&lt;ETH&gt; 以太坊概述、账户、状态树&amp;交易树&amp;收据树</title>
    <link href="/2025/05/01/ETH_1/"/>
    <url>/2025/05/01/ETH_1/</url>
    
    <content type="html"><![CDATA[<p>写在前面：<br>前段时间把b站上北大肖老师的区块链课程速通了一遍，这里引一下csdn上的优质课程笔记，便于个人后续温习。<br>博客链接：<a href="https://blog.csdn.net/qq_40378034/category_11862943.html">https://blog.csdn.net/qq_40378034/category_11862943.html</a><br>课程链接：<a href="https://www.bilibili.com/video/BV1Vt411X7JF/">https://www.bilibili.com/video/BV1Vt411X7JF/</a></p><span id="more"></span><h4 id="1、ETH-以太坊概述"><a href="#1、ETH-以太坊概述" class="headerlink" title="1、ETH-以太坊概述"></a>1、ETH-以太坊概述</h4><p>比特币和以太坊是两种最主要的加密货币，比特币被称为区块链1.0，以太坊被称为区块链2.0</p><p>以太坊在系统设计上针对比特币运行过程中出现的问题进行了改进，比如：</p><ol><li><strong>出块时间</strong>，比特币的区块时间是10分钟，以太坊的出块时间大幅度降低到了十几秒，而且为了适应这种新的出块时间，以太坊还设计了一套基于GHOST的共识机制</li><li>以太坊的另一个改进就是<strong>挖矿使用的mining puzzle</strong>，比特币的mining puzzle是计算密集型的，比拼的是计算哈希值的算力，这样造成的结果是挖矿设备的专业化，这样跟以前宣扬的去中心化的理念是不符合的，所以以太坊设计的mining puzzle对内存的要求就是很高的（<strong>memory hard mining puzzle</strong>），这样设计的目的是限制了ASIC芯片的使用（<strong>ASIC resistance</strong>）</li><li>将来以太坊还会有些革命性的改变，用<strong>权益证明</strong>（POS，proof of stake）来替代工作量证明（POW，proof of work）。权益证明就是不挖矿而是按照类似于股份投票的方法决定下一个区块怎么产生</li><li>除此之外，以太坊还增加了一个重要的功能，对<strong>智能合约</strong>（smart contract）的支持</li></ol><h5 id="1）、去中心化的货币-合约的概念"><a href="#1）、去中心化的货币-合约的概念" class="headerlink" title="1）、去中心化的货币&#x2F;合约的概念"></a>1）、去中心化的货币&#x2F;合约的概念</h5><p>比特币实现的是一种去中心化的货币，比特币取得成功之后，很多人就开始思考：除了货币可以去中心化，还有什么可以去中心化？以太坊的一个特性就是增加了对去中心化的合约的支持</p><p>比特币（BitCoin）：decentralized currency（去中心化的货币），符号是BTC，最小计量单位是Satoshi（一聪），1个比特币等于1亿聪，因为比特币的创始人名为中本聪（Satoshi Nakamoto）</p><p>以太坊（Ethereum）：decentralized contract（去中心化的合约），符号是ETH，它的币通俗地叫做以太，也叫Ether，最小计量单位是Wei（一伟），是为了致敬密码学的先驱戴伟（Wei Dai）</p><p><strong>去中心化的货币：</strong></p><p>货币本来是应该由政府发行的，货币的价值建立在政府公信力的基础上，然后政府通过一些司法手段来维护货币的正常运行。比特币的出现用技术手段把政府的这些职能给取代了，通过密码学、共识机制来维护加密货币体系的正常运行</p><p><strong>去中心化的合约：</strong></p><p>现实生活中，合约的有效性也是应该通过司法手段，通过政府来维护的，比如和人签一个合同，这个合同如果出现纠纷，通过打官司&#x2F;法院判决，法院先看一下这个合同是谁签的，有没有当事人的合法签名，合同当中如何规定，是谁违反了合同，看看哪一方有错，对于违约方按照合同中的条款应该给予什么样的处罚，这就是现实生活中的合同，通过司法手段维护合同的有效性。那么我们能不能也用技术手段这些司法手段给取代了，这就是以太坊智能合约的设计目的</p><p>如果合同中的内容是可以通过程序代码来实现出来的，那么就可以把代码放到区块链上，通过区块链的不可篡改性来保证代码的正确运行。当然，不是所有的合同内容都用编程语言来实现，也不是所有的合同条款都是可以被量化的，但是有一些逻辑比较简单，比较清晰的合同是可以写成智能合约的形式</p><h5 id="2）、去中心化的货币-合约的好处"><a href="#2）、去中心化的货币-合约的好处" class="headerlink" title="2）、去中心化的货币&#x2F;合约的好处"></a>2）、去中心化的货币&#x2F;合约的好处</h5><p><strong>去中心化的货币的好处：</strong></p><p>应用场景举例：跨国转账</p><p>比如说从美国转一笔钱到埃及，用法币（fait currency）是很麻烦的，时间很长，要办很多手续，交易费也贵，如果用比特币转账，就会好很多，这是比特币的一个优势。虽然说比特币每十分钟才出一个区块，有各种各样不是很完美的地方，但是用比特币跨国转账还是比法币要快很多</p><p><strong>去中心化的合约的好处：</strong></p><p>应用场景举例：跨国合同签署</p><p>如果合同的签署方是来自世界各地的，没有一个统一的司法管辖权，这个时候用司法手段来维护合同的有效性比较困难。就像在网上弄一个众筹，众筹的参与方来自全国各地，彼此之间不认识，打官司也不知道到哪儿去打。这种情况下，如果通过事先写好的程序代码来保证每个人都只能按照规则来执行，这是一种比较好的解决方法</p><p>就算合同的参与方都在同一个司法管辖权之内的，想通过司法手段来维护合同的执行也是一个比较费时费力的过程，打官司要花好多时间和精力。就算官司赢了，也不一定能拿到钱，还得申请冻结对方资产，申请强制执行之类的。所以最好是用技术手段保证合同的参与方从一开始就不能违约</p><p>智能合约的好处就在于这个代码一旦发布到区块链上，那么区块链的不可篡改性，只能按照代码中制定的规则来执行</p><h4 id="2、ETH-账户"><a href="#2、ETH-账户" class="headerlink" title="2、ETH-账户"></a>2、ETH-账户</h4><h5 id="1）、比特币：基于交易的账本"><a href="#1）、比特币：基于交易的账本" class="headerlink" title="1）、比特币：基于交易的账本"></a>1）、比特币：基于交易的账本</h5><p><strong>比特币中是用的基于交易的账本</strong>（transaction-based ledger），这种模式下，系统中并没有显式的记录每个账户上有多少钱，要根据UTXO里的信息推算，包括想知道这个人一共总资产有多少个比特币，就算一下这个人的所有账户，就是他有私钥的那些账户在UTXO里面一共有多少个币就可以了</p><p>这种模式的好处是隐私保护比较好，你有多少钱，可能连你自己都说不清楚，那别人就更不清楚了。但是这样就带来一个问题，就使用上比较别扭，跟我们的日常体验不太一样</p><p>比如，A要转给B 10个比特币，A要说明这10个<strong>币的来源</strong>，其中7个币是前面某个交易中收到的，另外3个币是之前另外一个交易收到的，<strong>证明币的来源的合法性</strong>。这和我们平时去银行的体验是不太一样的，银行是你存钱的时候要说明钱的来源，花钱的时候是不用说明每一笔钱是从哪儿来的</p><p>另外一个比较别扭的地方，在前面交易中收到一些币，将来要花的时候，<strong>必须要一次性都花出去，不能只花一部分</strong></p><p><img src="/../article_img/Web3/img4-1.png"></p><p>A转给B 10个比特币，将来B要转给C 3个比特币，币的来源是A转给B的这个交易。如上图这样处理，剩下的7个比特币会当做交易费给花出去了</p><p><img src="/../article_img/Web3/img4-2.png"></p><p>如上图，这个时候必须要把剩下的7个比特币转回给自己</p><p>很多比特币钱包可以自动生成接收余额的地址，每次交易换一个新地址，也是有利于隐私保护的，但同样跟我们的日常生活习惯不太一样。比如说，银行当中，别人转给你10万块钱，你要把3万块钱转出去，剩下7万块钱就不用管，就放在账户上就行了。问题在于比特币系统中，没有显式的维护基于账户的交易概念</p><h5 id="2）、以太坊：基于账户的账本"><a href="#2）、以太坊：基于账户的账本" class="headerlink" title="2）、以太坊：基于账户的账本"></a>2）、以太坊：基于账户的账本</h5><p><strong>以太坊采用的是基于账户的模型</strong>（account-based ledger），这种模型跟银行账户是比较相似的，系统中要显式的记录每个账户上有多少个以太币</p><p>比如，A要转给B 10个以太币，这个<strong>交易的合法性只要检查一下A账户上有没有足够的钱</strong>就行了。比如A账户上有100个以太币，要转10个给B，这就没问题，不用说明这100个以太币中是具体把哪10个转给了B，不用说明币的来源，是来自之前哪个交易。将来B要转给C 3个以太币也是可以的，不用把剩下的转给他自己，因为有<strong>显式余额</strong>的概念，所以剩下的币就直接放在账户上就行了。用于说明币的来源的哈希指针也不用了</p><p>比特币中面临的挑战是<strong>双花攻击</strong>（double spending attack），<strong>花钱的人不诚实，以前花过的钱想再花一次</strong></p><p><strong>基于账户模式的好处是对double spending attack有天然的防御作用</strong>，因为不用管币的来源，每花掉一次钱，就从你的账户上扣掉，花两次就扣两次</p><p>以太坊中面临的挑战是<strong>重放攻击</strong>（replay attack），<strong>收钱的人不诚实，别人已经给他转过钱了，他想再转一次</strong></p><p>A把自己转给B 10个以太币的转账交易发布到网络上，过一段时间之后，这个交易被写到区块链里了，A就以为转账交易完成了。假设B是有恶意的，<strong>把这个交易在网上重新广播一遍</strong>，其他节点以为是个新的转账就把A的钱扣了2次</p><p><strong>解决方案</strong>：</p><p>加一个<strong>计数器</strong>（nonce），记录一下这个账户有史以来<strong>一共发布过多少交易</strong>，然后转账的时候，<strong>交易次数要成为交易内容的一部分</strong>，一起包含进去，都是受到发布交易的签名的保护</p><p><img src="/../article_img/Web3/img4-3.png"></p><p>如上图，A转给B 10个以太币，A一共发布过20个交易，这是第21个，所以写上nonce&#x3D;21，然后整个内容写上A的签名</p><p>把这个交易发布到网上，<strong>因为有签名的保护，所以nonce的值，别人是改不了的</strong>。系统中的每个节点维护A这个状态，不仅要维护A账户上的钱（balance），还要维护nonce的值，一开始nonce&#x3D;0，每次收到A发布的一个交易，nonce+1</p><p>这个节点一开始A的nonce&#x3D;20，然后现在发布这个交易，这个节点一看，这个交易是合法的，是可以执行的，同时更新一下nonce&#x3D;21。以后如果有人重放这个交易，这个节点一看，这个nonce已经是21了，已经被执行过了，就不会再执行一遍了</p><h5 id="3）、以太坊账户的分类"><a href="#3）、以太坊账户的分类" class="headerlink" title="3）、以太坊账户的分类"></a>3）、以太坊账户的分类</h5><p>以太坊中有两类账户：外部账户、合约账户</p><p><strong>externally owned account（外部账户）：</strong></p><p>外部账户是由公私钥控制的，本地产生一个公私钥对，私钥掌握账户的控制权（类似于比特币中的账户），也叫普通账户</p><p>外部账户的状态：</p><ul><li>balance（账户余额）</li><li>nonce（计数器）</li></ul><p><strong>smart contract account（合约账户）：</strong></p><p>合约账户不是通过公私钥对控制的</p><p>合约账户的状态：</p><ul><li>balance（账户余额）</li><li>nonce（计数器）</li><li>code（代码）</li><li>storage（相关状态存储，包括每个变量的取值）</li></ul><p>一个合约可以调用另外一个合约，所以要通过nonce值记录一下调用的次数</p><p><strong>合约账户不能主动发起一个交易，以太坊中规定，所有的交易只能由外部账户发起</strong>。外部账户发起一个交易如果调用了一个合约账户，这个合约账户可以发送一个message调用另外一个合约，但是他不能自己平白的发起一个交易</p><p>创建合约会返回一个地址，<strong>知道这个合约的地址，就可以调用这个合约</strong>，调用的过程当中<strong>状态会发生变化</strong>，代码（code）不会变，<strong>存储（storage）会变</strong></p><h5 id="4）、为什么要设计这样一种新的账户模式？"><a href="#4）、为什么要设计这样一种新的账户模式？" class="headerlink" title="4）、为什么要设计这样一种新的账户模式？"></a>4）、为什么要设计这样一种新的账户模式？</h5><p>以太坊的创始人叫Vitalik，是个19岁的小孩，他当初创建以太坊的时候，比特币已经有比较成熟的代码可以作为参考，为什么不用比特币已有的代码，而要另弄一套？为什么不直接在比特币系统设计上改进，比如改出块时间、mining puzzle，为什么非要改账户体系？</p><p>比特币基于交易模型的一个好处是隐私保护，但是以太坊要支持的是智能合约，<strong>对于合约来说，要求参与者有比较稳定的身份</strong></p><p>这跟日常生活当中是比较类似的，比如说，你跟某个人签个合同，如果说你跟他签合同的时候，他是一个身份，签完之后，他身份变了，你找不到了，那这就有问题了，也有可能突然冒出了另外一个人，说他当初就是跟你一块签合同的，只不过换了一个身份，这就给合同的执行带来一些困难。将来出现纠纷的时候，你也是需要知道这个合同当初是跟谁签的</p><p>现在有人提出来用智能合约实现一些金融衍生品（financial derivative）</p><p>比如期权&#x2F;期货，往合约里投一笔钱，预测未来的价格走势，如果预测正确，给你一些收益，把钱还给你。但问题是，如果你投钱的这个账户，投完钱就变了，那到时候怎么把钱还给你呢？</p><p>这个不光是对于外部账户有这个问题。合约账户的问题就更严重了，如果你投钱投到一个合约账户，投完之后合约账户的地址变了，找不到就麻烦了</p><p>所以以太坊创建这个系统的时候，考虑了过去的一些已有的模型的利弊得失，最终没有采用比特币中基于交易的模式，而是采用了基于账户模式</p><p>这个从目前的状况来看，还是比较合适的一个决策，以太坊的账户是希望保持稳定的，无论是个人账户还是合约账户。如果你有隐私保护的需要，同样可以创建很多个账户，根据情况使用不同的账户进行不同的交易</p><h4 id="3、ETH-状态树"><a href="#3、ETH-状态树" class="headerlink" title="3、ETH-状态树"></a>3、ETH-状态树</h4><p>以太坊采用基于账户的模式，系统中显式地维护每个账户上有多少余额，来看一下用什么样的数据结构来实现account-based ledger</p><p>要完成的功能是从账户地址到账户状态的映射：addr-&gt;state</p><p><strong>addr</strong>：账户地址，以太坊中用的账户地址是160位，也就是20个字节，一般表示成40个十六进制的数</p><p><strong>state</strong>：外部账户和合约账户的状态，包括余额、交易次数，合约账户还包括代码、存储</p><p>那么要设计什么样的数据结构来实现这个映射呢？</p><h5 id="1）、思考如何组织账户的数据结构？"><a href="#1）、思考如何组织账户的数据结构？" class="headerlink" title="1）、思考如何组织账户的数据结构？"></a>1）、思考如何组织账户的数据结构？</h5><p><strong>1）方案一： 用哈希表实现</strong></p><p>从直观上看，像一个很典型的key-value pair，给出一个账户地址，要找到相应的账户状态，所以一个直观的想法是用哈希表实现</p><p>系统中的全节点维护一个哈希表，每次有一个新的账户，插入到哈希表里面。查询账户的余额，就直接在哈希表中查询。如果不考虑哈希碰撞的话，基本上查询的效率是常数时间内完成的，更新也是很容易在哈希表中更新的</p><p><strong>问题：如果用这个哈希表要提供Merkle proof怎么提供？</strong></p><p>比如说你要跟一个人签合同，希望他能证明一下他有多少钱，怎么提供证明呢？</p><p>一种方法是把哈希表中的元素组织成一个Merkle Tree，然后算出一个根哈希值，这个根哈希值存在block header里，只要根哈希值是正确的，就能保证底下的树不会被篡改</p><p><strong>如果有新区块发布怎么办？新区块中包含新的交易，执行这个交易必然会使哈希表的内容发生变化，发布下一个区块的时候，再重新把哈希表中的内容（key：账户地址，value：账户状态）组织成一个Merkle Tree吗？</strong></p><p>这个代价太大了。实际上，真正发生变化的账户状态只是一小部分，因为只有那个区块里的交易所关联的账户才会发生变化，大多数账户的状态是不变的。所以每次都重新构造一次Merkle Tree，这个代价是很大的</p><p><strong>比特币系统当中难道不是每出现一个区块也要重新构造一个Merkle Tree吗？那个为什么没有问题？</strong></p><p>比特币是把区块里包含的交易组织成一个Merkle Tree，那区块中的交易每次发布一个新的区块又有一系列新的交易，所以比特币中的Merkle Tree是immutable（不变的）的，每次发布一个新的区块对应一个Merkle Tree，然后这棵Merkle Tree构建完之后是不会再改的，下次再发布一个新的区块再构建一个新的Merkle Tree</p><p>那区块里有多少个交易呢？最多差不多4000个（按照1M字节，每个交易大概是250M字节左右），这个其实是一个上限，很多区块的交易数目根本到不了4000个，有好多区块就只有几百个，甚至有可能还有更少的。所以每次发布一个区块，比特币里构建一个Merkle Tree，是要把这几百个到几千个交易构成一个Merkle Tree</p><p><strong>这里如果采用这种方法会是什么情况？</strong></p><p>是要把所有的以太坊账户一起构成一个Merkle Tree，这个就比刚才讲的几百、几千个交易要高出好几个数量级，相当于每次发布一个区块要把所有的账户遍历一遍构建出一个Merkle Tree，下次再有一个区块，再把所有的账户遍历一遍，再构建出一个Merkle Tree</p><p>除了提供Merkle proof证明账户有多少钱之外，这个Merkle Tree还有另外一个很重要的作用，就是<strong>维护各个全节点之间状态的一致性</strong>。如果没有根哈希值发布出来，每个节点就是在本地维护一个数据结构，那怎么知道你的数据结构的状态跟别人的数据结构的状态是不是一致呢，各个全节点要保持状态的一致才行。这也是为什么比特币中把根哈希值写在块头里的原因，就是对于当前区块中包含哪些交易，所有的全节点要有一个共识</p><p><strong>结论：不可行，因为每次构建Merkle Tree的代价太大</strong></p><p>如果每个全节点在本地维护一个哈希表，然后需要构建Merkle Tree的时候构建出Merkle Tree来，然后根哈希值放到区块头里，这个方法是不行的。哈希表本身的效率是挺好的，插入、更改效率都很好，但是每次构建Merkle Tree的代价太大了</p><p><strong>2）方案二：直接用一个Merkle Tree把所有的账户都放进去</strong></p><p>不要哈希表了，直接用一个Merkle Tree把所有的账户都放进去，要改的时候直接在Merkle Tree里改。因为每个区块更新的只是一小部分账户，所以改的时候只是Merkle Tree里的一小部分</p><p><strong>问题1：Merkle Tree没有提供一个高效的查找、更新的方法</strong></p><p>比特币中的Merkle Tree最底下一层是transaction，然后哈希值放到上面节点里，两两结合，然后再取一个哈希往上整。Merkle Tree没有提供一个快速查找，更新的方法</p><p><strong>问题2：直接把账户放到Merkle Tree里，这个Merkle Tree要不要排序？（Sorted Merkle Tree）</strong></p><p>如果不排序会怎么样？</p><ol><li>查找速度会慢</li><li>这些账户组成了这棵Merkle Tree，叶节点是这些账户的信息，如果不规定这些账户在叶节点出现的顺序，那么这样构建出来的Merkle Tree不是唯一的</li></ol><p>系统中有很多全节点，每个全节点按照自己的某个顺序，比如说他听到某个交易的顺序构建一个Merkle Tree，那么叶结点的顺序是乱的，每个节点都是自己决定的，最后构建出的Merkle Tree是不一样的，算出的根哈希值也是不一样的</p><p><strong>比特币中的Merkle Tree也是不排序的，那为什么比特币就没有问题呢？</strong></p><p>因为比特币中的每个全节点收到的交易的顺序也是不一样的，理论上说构建的Merkle Tree的根哈希值也是不一样的</p><p>比特币中，每个节点在本地组装一个候选区块，这个节点自己决定哪些交易、以什么顺序打包进这个区块里，然后通过挖矿去竞争记账权。如果他没有抢到记账权，他的任何决定其他人没必要知道；只有他有记账权，且发布区块后最终成为被大家接受的区块，那么，这个顺序就是发布这个区块的节点确定的</p><p>也就是说，<strong>比特币中虽然也没用排序的Merkle Tree，但是顺序是唯一的，是由发布区块的那个节点确定的</strong></p><p><strong>那为什么以太坊不能这样做？</strong></p><p>如果以太坊也这么做的话，需要把<strong>账户的状态</strong>发布到区块里。也可以说是每个全节点自己决定怎么把账户组织成一个Merkle Tree，算出跟哈希值、挖出矿，但要怎么让别人知道这个顺序，你得把这个Merkle Tree发布到区块里。但发布的是所有账户的状态，不是交易，这两者差好几个数量级，比特币发布一个区块只需要几百、几千个交易</p><p><strong>结论：不可行，不排序的Merkle Tree是不行的</strong></p><p>交易是必须要发布的，不发布别人就没法知道，但<strong>账户状态可以维护在本地</strong>，而且<strong>大部分账户状态是不变</strong>的。一个区块里的交易只能改很少的账户，大多数账户是不变的，而且重复发布，每隔十几秒发布一个新的区块，把所有状态都打包发布一遍，下次再过十几秒再发布一遍，这个是不可行</p><p><strong>3）方案三：用Sorted Merkle Tree</strong></p><p><strong>问题：新增一个账户怎么办？</strong></p><p>产生一个账户的地址是随机的，他的叶节点的位置很可能是插在中间的，那后面这些树的结构都得变</p><p><strong>新产生一个账户，对外发生了交互，我需要把他加入到我的数据结构里，这是没错的，但问题是，这个加入的代价有多大？</strong></p><p>可能大半棵Merkle Tree需要重构，这个代价太大了</p><p><strong>结论：不可行，用Sorted Merkle Tree，插入、删除代价都太大</strong></p><p>而且，区块链是不可篡改的，是说加东西容易，删东西难。以太坊中没有显式地删除账户的操作，有的账户上就一点钱，就一两个Wei，也不能把他删掉</p><h5 id="2）、以太坊的数据结构"><a href="#2）、以太坊的数据结构" class="headerlink" title="2）、以太坊的数据结构"></a>2）、以太坊的数据结构</h5><p><strong>1）Trie（字典树，前缀树）</strong></p><p>以太坊中是用一个叫<strong>MPT</strong>（Merkle Patricia Tree）的结构，讲这个之前先讲一个简单的数据结构</p><p>Trie也是一种key-value对，一般来说key用字符串用的比较多，比如说一些单词排成一个Trie的数据结构</p><p>举例：general、genesis（创世纪块，区块链的第一个区块）、go、god、good</p><p><img src="/../article_img/Web3/img4-4.png"></p><p>上图就是一个Trie的结构，这几个单词都是以G开头的，然后第二个字母就开始分裂了，左边是E，右边是O。左边这前两个单词都是N和E，然后下面再分开，R和S，然后是后三个字母。右边这个分支，O这个分支，Go就已经结束了，从这个可以看到单词可能在Trie的中间节点结束，然后左边是D，右边是O，左边变成了God，右边下来是Good</p><p>Trie树可以<strong>利用字符串的公共前缀来节约存储空间</strong>。如果系统中存在大量字符串且这些字符串基本没有公共前缀，则相应的Trie树将非常消耗内存，这也是Trie树的一个缺点</p><p><strong>特点1：Trie的每个节点的分叉数目取决于key值里每个元素的取值范围</strong></p><p>这个例子当中，每个都是英文单词，而且是小写的，所以每个节点的分叉数目最多是26个，加上一个结束标志位（表示这个单词到这个地方就结束了）</p><p>在以太坊中地址是表示成40个十六进制的数，因此<strong>分叉数目</strong>（branching factor）是17（十六进制的0~f，再加上结束标志位）</p><p><strong>特点2：Trie的查找效率取决于key的长度。键值越长，查找需要访问内存的次数就越多</strong></p><p>在这个例子当中，不同的单词键值长度是不同的</p><p>在以太坊中，所有键值都是40，因为地址都是40位十六进制的数</p><p>比特币和以太坊的地址是不通用的，两个地址的格式长度都是不一样的。但有一点是类似的，以太坊中的地址也是公钥经过转换得来的。其实就是公钥取哈希，然后前面的不要，只要后面这部分，就得到一个160bit的地址</p><p><strong>特点3：只要两个地址不一样，最后肯定映射到树中的不同分支，所以Trie是不会出现碰撞的</strong></p><p><strong>特点4：不同的节点，不论按照什么顺序插入这些账户，最后构造出来的树是一样的</strong></p><p>前面讲Merkle Tree，如果不排序的话，一个问题是账户插入到Merkle Tree 的顺序不一样，得到的树的结构也不一样</p><p>那Trie呢？比如上图中的这五个单词，换一个顺序插到这个树里面，得到的是一个不同的树吗？其实是一样的，只要给定的输入不变，无论输入怎么打乱重排，最后插入到Trie当中，得到的树是一样的</p><p><strong>特点5：更新操作的局部性很好</strong></p><p>每次发布一个区块，系统中绝大多数账户的状态是不变的，只有个别受到影响的账户才会变，所以更新操作的局部性很重要</p><p>Trie的局部性呢？比如在上图中，我要更新genesis这个key对应的value（这个图当中只画出了key，没有画出value），只要访问genesis的那个分支，其他分支不用访问的，也不用遍历整棵树</p><p><strong>缺点：存储浪费</strong></p><p>比如在上图中左边分支都只有一个子节点，对于这种一脉单传的情况，如果能把节点进行合并，那么可以减小存储的开销，同时也提高了查找的效率，不用一次一个一个的往下找了</p><p>那么就引入了<strong>Patricia Tree</strong>，也有人写成<strong>Patricia Trie</strong>，是经过路径压缩的前缀树，有时候也叫<strong>压缩前缀树</strong></p><p><strong>2）Patricia Tree&#x2F;Patricia Trie</strong></p><p><img src="/../article_img/Web3/img4-5.png"></p><p>Trie中的例子进行路径压缩就变成上图的样子。可以看到，G下面还是E和O进行分叉，E下面之后跟的都是NE，再往下就是E和S分叉，然后后面都和在一起了，右边的分支也是一样的</p><p><strong>这样压缩之后有什么好处？直观上看，这个高度明显缩短了，访问内存的次数会大大减少，效率提高了</strong></p><p><strong>注意：对于Patricia Tree来说，新插入一个单词时，原来压缩的路径可能需要扩展开</strong></p><p>比如这个例子中，加入geometry，左边的分支就不能那样压缩了</p><p><strong>路径压缩在什么情况下效果比较好？键值分布比较稀疏的时候，路径压缩效果比较好</strong></p><p>比如说，这个例子当中是用英文单词，假设每个单词都很长，但是一共没有几个单词，举例：misunderstanding、decentralization（去中心化的）、disintermediation（去中间商，非中介化，intermediaries：中间商）</p><p>这三个单词插入到一个普通的Trie里面就成了下图的样子。可以看到这样的结构效率是比较低的，基本上是一条线了</p><p><img src="/../article_img/Web3/img4-6.png"></p><p>如果用Patricia Tree的话，如下图</p><p><img src="/../article_img/Web3/img4-7.png"></p><p>这个树的高度明显缩短了。所以键值分布比较稀疏的时候，路径压缩效果比较好</p><p>以太坊中键值是不是稀疏的呢？</p><p>以太坊中键值是地址，地址是160位的，地址空间有 2 160 2^{160} 2160，这是一个非常非常大的数。如果设计一个计算机程序的算法，需要进行运算的次数是 2 160 2^{160} 2160，那这个在所有人的有生之年都不可能算出来，全世界的以太坊的账户数目加在一起也远远没有这么大，跟这个数比，是微乎其微的</p><p>为什么要弄这么稀疏，不把地址长度缩短一点，这样访问效率也快，也没必要那么稀疏了？</p><p>以太坊中普通账户跟比特币的创建方法是一样的，没有一个中央的节点，就每个用户独立创建账户。在本地产生一个公私钥对，就是一个账户</p><p>那怎么防止两个人的账户碰撞，产生的一样呢？</p><p>这种可能性是存在的，但是这个概率比地球爆炸还要小。怎么达到这么小的概率，就是<strong>地址要足够长，分布足够稀疏，才不会产生碰撞</strong>。这个可能看上去有点浪费，但是<strong>这是去中心化的系统防止账户冲突的唯一办法</strong>。所以以太坊地址分布非常稀疏的，所以比较适合使用Patricia Tree</p><p><strong>3）MPT（Merkle Patricia Tree）</strong></p><p><strong>Merkle Tree和Binary Tree的区别：</strong></p><p>就是区块链与普通链表的区别，把普通指针换成了哈希指针</p><p><strong>Merkle Patricia Tree和Patricia Tree的区别：</strong></p><p><strong>所有的账户组织成一个Patricia Tree，用路径压缩提高效率，然后把普通指针换成哈希指针，所以就可以计算出一个根哈希值。这个跟哈希值也是写在block header里面</strong></p><p><strong>比特币的block header里只有一个根哈希值：交易树</strong>，就是区块里包含的交易组成的Merkle Tree组成的根哈希值</p><p><strong>以太坊的block header里有三个根哈希值：交易树、状态树、收据树</strong></p><p><strong>账户状态最后组织成了一个Merkle Patricia Tree，状态树的根哈希值的作用：</strong></p><p><strong>作用1：防止篡改</strong></p><p>只要根哈希值不变，整个树的任何部分都没有办法被篡改，也就是说每个账户的状态都能保证是没有被篡改过的</p><p><strong>作用2：Merkle proof</strong></p><p>1）能证明账户的余额是多少</p><p>你这个账户所在的分支自己向上作为Merkle proof发给轻节点，轻节点可以验证你的账户上有多少钱</p><p>2）能证明某个账户是不存在的</p><p>Sorted Merkle Tree的一个作用是能证明non-membership，这里的证明方法跟Sorted Merkle Tree类似</p><p>比如，给一个地址转账之前，验证一下全节点里有没有这个账户信息。说的更直白一点，证明MPT中某个键值是不存在的</p><p>如果存在的话，是在什么样的分支，把这个分支作为Merkle proof发过去，可以证明他是不存在的</p><p><strong>4）Modified MPT</strong></p><p>以太坊中用到的不是原生的MPT，是<strong>Modified MPT</strong>，就是对MPT的结构做一些修改，这些修改不是很本质的修改</p><p><img src="/../article_img/Web3/img4-8.png" alt="在这里插入图片描述"></p><p>上图是Modified MPT的案例，右上角有四个账户，为了简单起见，账户地址都比较短，假设只有7位的地址，而不是40位，账户状态也只显示出了余额，其他账户状态没有显示出来。第一个账户有45个以太币，第二个账户只有1WEI（这个是以太坊中最小的计量单位，1WEI基本上可以忽略不计）</p><p>这个案例当中，节点分为三种：</p><p><strong>Extension Node（扩展节点）：</strong></p><p>如果这个树中出现了<strong>路径压缩</strong>就会有一个Extension Node，这四个地址前两位都是一样的a7，所以Root（根节点）就是一个Extension Node，<strong>shared nibble</strong>（nibble：16进制数，一个nibble就是一个16进制数），这里共享的nibble是a7</p><p><strong>Branch Node（分支节点）：</strong></p><p>案例中第三位就分开了，有1、7、f，所以就跟了一个Branch Node</p><p><strong>Leaf Node（叶节点）：</strong></p><p>先说1，这个1之后就是1355，只有这一个地址，就跟了Leaf Node。这个7有两个地址，连着路径压缩d3，然后再往下3和9分开了，跟着一个Branch Node，下面两个Leaf Node，都是7。最后一个f，就跟着一个Leaf Node：9365</p><p>另外，这个树的根节点取哈希之后得到的一个根哈希值，是要写在块头里的（左上角）</p><p>用的也是哈希指针。比如7这个位置，这里存的是下面这个节点（extension node）的哈希值。如果是普通指针的话，7这个位置存的是下面这个节点的地址</p><p><strong>每次发布一个新的区块的时候，状态树中有一些节点的值会发生变化，这些改变不是在原地改，而是新建一些分支，原来的状态其实是保留下来的</strong></p><p><img src="/../article_img/Web3/img4-9.png" alt="在这里插入图片描述"></p><p>上面这个例子中，有两个相邻的区块：</p><p>Block N Header：State Root就是状态树的根哈希值，下面显示的是这棵状态树</p><p>Block N+1 Header：这个是新的区块的状态树</p><p>可以看到，<strong>虽然每一个区块都有一个状态树，但是这两棵树的大部分节点是共享的。右边这棵树主要都是指向左边这棵树的节点，只有那些发生改变的节点是需要新建一个分支</strong></p><p>这个例子中，这个账户是一个合约账户，因为有Code，还有Storage合约账户的存储也是由MPT保存下来的。这个存储其实也是一个Key Value Store，维护的是从这个变量到这个变量取值的一个映射，在以太坊当中，也是用的一棵MPT。所以<strong>以太坊中的这个结构是一个大的MPT，包含很多小的MPT，每一个合约账户的存储都是一棵小的MPT</strong></p><p>上图中这个账户的新的区块里：Nonce和Balance发生了变化，Code是不变的，所以Codehash指向原来树中那个节点，Storage是变了的（存储下面这个叫存储树），在存储树中，大部分节点也是没有改变。这个例子当中，只有一个节点变了，这个整数变量从29变成了45，所以新建了一个分支</p><p>所以，系统中每个全节点需要维护的不是一棵MPT，而是每次出现一个区块，都要新建一个MPT，只不过这些状态树中，大部分的节点是共享的，只有少部分发生变化的节点要新建分支</p><p><strong>为什么要保留历史状态，为什么不在原地直接改了？</strong></p><p>系统当中有时候会出现分叉，临时性的分叉是很普遍的。以太坊把出块时间降低到十几秒之后，这种临时性的分叉是常态，因为区块在网上传播时间可能也需要十几秒</p><p><img src="/../article_img/Web3/img4-10.png"></p><p>如上图，有个分叉，这两个节点同时获得记账权。这两个分叉最终上面那个胜出了，下面这个分叉的节点这个时候就要回滚（roll back），就是这个节点当前的状态，就接受了下面这个节点的状态要取消掉，退回到上一个节点的状态，然后沿着上面那条链往下推进</p><p>有时候可能要把当前状态退回到没有处理到这个区块中交易的前一个状态</p><p><strong>那怎么实现回滚呢？</strong></p><p>就是要维护这些历史纪录</p><p>这个跟比特币还不太一样，如果是比特币的话，交易类型比较简单，有的时候可以通过这种反向操作推算出前一个状态。如果是一个简单的转账交易，A转给B 10个比特币，这个对账户余额有什么影响呢？A的账户上少了10个比特币，B的状态多了10个比特币。假如这个状态要回滚，退回到前一个状态，那就把B这个账户减少10个比特币，把A这个账户加回去10个比特币就行了。简单的转账交易回滚其实是比较容易的</p><p>以太坊中为什么不行？因为以太坊中有智能合约。智能合约是图灵完备的，编程功能是很强的。从理论上说，可以实现很复杂的功能，跟比特币简单的脚本还不太一样。<strong>以太坊中如果不保存前面的状态，智能合约执行完之后，想再推算出前面是什么状态，这是不可能的，所以要想支持回滚，必须保存历史状态</strong></p><h5 id="3）、以太坊的数据结构实现"><a href="#3）、以太坊的数据结构实现" class="headerlink" title="3）、以太坊的数据结构实现"></a>3）、以太坊的数据结构实现</h5><p><strong>1）block header的结构</strong></p><p><img src="/../article_img/Web3/img4-11.png" alt="在这里插入图片描述"></p><table><thead><tr><th align="center">block header中的属性</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">ParentHash</td><td align="center">父区块块头的哈希值，是区块链中前一个区块块头的哈希值</td></tr><tr><td align="center">UncleHash</td><td align="center">叔父区块块头的哈希值。每个区块还有叔父区块，以太坊中Uncle和Parent不一定是一个辈分的，Uncle比Parent可能大好多辈分</td></tr><tr><td align="center">Coinbase</td><td align="center">挖出这个区块的矿工的地址</td></tr><tr><td align="center">Root</td><td align="center">状态树的根哈希值</td></tr><tr><td align="center">TxHash</td><td align="center">交易树的根哈希值（类似比特币系统中的那个根哈希值）</td></tr><tr><td align="center">ReceiptHash</td><td align="center">收据树的根哈希值</td></tr><tr><td align="center">Bloom</td><td align="center">布隆过滤器，提供一种高效的查询符合某种条件的交易的执行结果（跟收据树是相关的）</td></tr><tr><td align="center">Diffculty</td><td align="center">挖矿难度，要根据需要调整</td></tr><tr><td align="center">GasLimit</td><td align="center">单个区块允许的最多Gas总量（智能合约要消耗汽油费，类似于比特币中的交易费）</td></tr><tr><td align="center">GasUsed</td><td align="center">该交易消耗的总Gas数量</td></tr><tr><td align="center">Time</td><td align="center">区块的大致的产生时间</td></tr><tr><td align="center">Nonce</td><td align="center">是挖矿时猜的那个随机数（类似于比特币的挖矿），以太坊中的挖矿也是要猜很多个随机数，写在块头里的随机数是最后找到的，符合难度要求的</td></tr><tr><td align="center">MixDigest</td><td align="center">混合摘要，从nonce这个随机数经过一些计算，算出一个哈希值</td></tr></tbody></table><p><strong>2）区块的结构</strong></p><p><img src="/../article_img/Web3/img4-12.png" alt="在这里插入图片描述"></p><table><thead><tr><th align="center">block中的属性</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">header</td><td align="center">指向block header的指针</td></tr><tr><td align="center">uncles</td><td align="center">指向叔父区块的header的指针，是个数组，因为一个区块可以有多个叔父区块</td></tr><tr><td align="center">transactions</td><td align="center">这个区块中交易的列表</td></tr></tbody></table><p><img src="/../article_img/Web3/img4-13.png" alt="在这里插入图片描述"></p><p>extblock是区块在网上发布的信息，就是block中的前三项会真正发布出去</p><h5 id="4）、状态树中的value的存储：RLP"><a href="#4）、状态树中的value的存储：RLP" class="headerlink" title="4）、状态树中的value的存储：RLP"></a>4）、状态树中的value的存储：RLP</h5><p>状态树中保存的是key value pair对。key就是地址，前面主要讲的是键值，这个地址的管理方式</p><p>那么这个value呢，这个账户的状态呢，是怎么存储在状态树当中的呢？实际上是要经过一个序列化（RLP）的过程，然后再存储</p><p><strong>RLP</strong>：Recursive Length Prefix，递归长度前缀，是一种序列化方法。特点是简单，极简主义，越简单越好</p><p><strong>Protocal buffer</strong>：简称Protobuf，是个很有名的做序列化的库</p><p>跟这些库相比，RLP的理念就是越简单越好。它只支持一种类型：<strong>nested array bytes</strong>，嵌套数组字节。一个一个字节组成的数组，可以嵌套。以太坊里的所有的其他类型，比如整数或者比较复杂的哈希表，最后都要变成nested array bytes</p><p>所以实现RLP要比实现Protocal buffer简单很多，因为难的东西，都推给应用层了</p><h4 id="4、ETH-交易树和收据树"><a href="#4、ETH-交易树和收据树" class="headerlink" title="4、ETH-交易树和收据树"></a>4、ETH-交易树和收据树</h4><h5 id="1）、交易树和收据树"><a href="#1）、交易树和收据树" class="headerlink" title="1）、交易树和收据树"></a>1）、交易树和收据树</h5><p>每次发布一个区块的时候，区块中所包含的交易会组织成一个交易树，也是一棵Merkle Tree，跟比特币中的情况是类似的</p><p>此外，以太坊还增加了一个收据树，每个交易执行完之后会形成一个收据，记录交易的相关信息，交易树和收据树上的节点是一一对应的。由于以太坊智能合约执行较为复杂，通过增加收据树，便于快速查询执行结果</p><p>从数据结构上，交易树和收据树都是MPT（Merkle Patricia Tree），而比特币中都采用普通的Merkle Tree。以太坊中可能就仅仅是为了三棵树代码复用好所以这样设计的</p><p>MPT的好处是支持查找操作，可以通过键值从顶向下沿着这个树进行查找。对于状态树来说，查找的键值就是这个账户的地址；对于交易树和收据树来说，查找的键值是这个交易在发布的区块中的序号，交易的排列顺序是由发布区块的那个节点决定的</p><p>这三棵树有一个重要的区别：<strong>交易树和收据树都是只把当前发布的这个区块里的交易组织起来的，而状态树是把系统中所有账户的状态都要包含进去，不管这些账户跟当前区块的交易有没有什么关系</strong></p><p><strong>多个区块的状态树是共享节点的，每次新发布一个区块的时候，只有这个区块中的交易改变了状态的那些节点需要新建一个分支，其他节点都是沿用原来状态树上的节点。而每个区块的交易树和收据树都是独立的，是不会共享节点的，一个区块跟另一个区块发布的交易本身也认为是独立的</strong></p><p><strong>交易树和收据树的用途</strong>：</p><ol><li>向轻节点提供Merkle proof。像比特币当中，交易树可以证明某个交易被打包到某个区块里面，可以向轻节点提供这样的Merkle proof，收据树也是类似的，要证明某个交易的结果，也可以在收据树里面提供一个Merkle proof</li><li>以太坊还支持一些更加复杂的查询操作。比如说，想找到过去十天当中，所有跟某个智能合约有关的交易，一种方法是把过去十天产生的所有区块都扫描一遍，看看其中有哪些交易是和智能合约相关的，但是这种方法的复杂度较高，而且对于轻节点来说，实际上，轻节点没有交易列表，只有一个块头的信息，所以也没有办法通过扫描所有交易列表的方法来找到符合这个查询条件的交易。与之类似的一些查询，比如说，找到过去十天中所有的众筹事件或者所有的发行新币的事件，这些都是需要一个比较高效的方法才能支持</li></ol><h5 id="2）、bloom-filter（布隆过滤器）"><a href="#2）、bloom-filter（布隆过滤器）" class="headerlink" title="2）、bloom filter（布隆过滤器）"></a>2）、bloom filter（布隆过滤器）</h5><p>以太坊中引入了bloom filter，<strong>bloom filter支持比较高效的查找某个元素是不是在一个比较大的集合里面</strong></p><p>比如说有一个集合，里面有很多元素，现在想知道某个指定的元素是不是在这个集合里</p><p>一个最笨的方法是，把这集合里面的元素遍历一遍，看看有没有想找的那个元素，这个复杂度是线性的，另外有一个前提是得有足够得存储来保存整个集合的元素，对于轻节点来说，轻节点没有这个交易列表，没有整个集合的元素信息，所以这种方法是用不了的</p><p>bloom filter用一个很巧妙的思想给这个大的、包含很多元素的集合计算出一个很紧凑的摘要</p><p><img src="/../article_img/Web3/img4-14.png"></p><p>如上图，这个例子当中有一个（a,b,c）的集合，要计算出一个digest，底下是一个向量，这个向量初始的时候都是零</p><p><img src="/../article_img/Web3/img4-15.png"></p><p>然后有一个哈希函数H，把每一个元素映射到向量中的某个位置。比如说a这个元素，取哈希之后，映射到相应位置，把这个位置的元素从0变成1。然后，b和c也映射到相应的位置。就是把每个元素都取哈希，找到向量中的对应位置，然后把它置成1，所有元素都处理完了，得到这个向量就是原来集合的一个摘要，这个摘要比原来的集合要小很多，这个例子当中用128bits就可以代表了</p><p>摘要的用处：比如说有一个元素d，想知道这个d元素是不是在这个集合里，但是这个集合本身我们不一定能够保存下来</p><p><img src="/../article_img/Web3/img4-16.png"></p><p>可以用这个哈希函数H对d取哈希值，取完之后发现映射到一个值为0的位置，说明d这个元素一定不在这集合里</p><p><img src="/../article_img/Web3/img4-17.png"></p><p>假设取完哈希，映射到一个值为1的位置，有可能确实是集合中的元素，d&#x3D;b，也有可能不在这个集合里，而是出现了哈希碰撞，恰好映射到了跟集合某个元素一样的位置。所以用bloom filter要注意，有可能会出现false positive，但是不会出现false negative，就是可能出现误报，但是不会出现漏报，元素在里面一定说在里面，元素不在里面也有可能说在里面（或者是说，<strong>bloom filter说某个元素在，可能会被误判，bloom filter说某个元素不在，那么一定不在</strong>）</p><p>bloom filter有各种各样的变种，比如说，解决这样的哈希碰撞，有的bloom filter的设计用的不是一个哈希函数，而是<strong>一组哈希函数</strong>，每个哈希函数独立的把这个元素映射到这个向量中的一个位置，用一组哈希函数的好处是如果出现哈希碰撞，那么一般来说，不会所有的哈希函数都出现哈希碰撞</p><p><strong>bloom filter不支持删除操作</strong>，比如把a删掉了，对应的向量1要不要改，如果改成0的话，集合中可能有另外一个元素也映射到这个位置（哈希碰撞是有可能的），所以简单的bloom filter是不支持删除操作的。如果要支持删除操作，这个地方就不能是0和1了，得改成一个计数器，记录这个位置有多少个元素映射过来，而且还要考虑到计数器会不会溢出，这样数据结构就复杂得多了，和当初设计bloom filter的初衷是相违背的</p><h5 id="3）、以太坊中bloom-filter的用途"><a href="#3）、以太坊中bloom-filter的用途" class="headerlink" title="3）、以太坊中bloom filter的用途"></a>3）、以太坊中bloom filter的用途</h5><p>每个交易执行完之后会形成一个收据，这个收据里面就包含一个bloom filter，记录交易的类型、地址等其他信息，发布的区块，在他的块头里也有一个总的bloom filter，这个总的bloom filter是这个区块里所有交易的一个bloom filter的并集</p><p>比如说要查找过去十天发生的跟某个智能合约相关的交易，先查一下区块的块头里的bloom filter有要找的交易类型，如果没有，这个区块就不是我们想要的，如果有，再去查找区块里面包含的交易所对应的收据树里面的那些bloom filter，看看哪个有，也可能都没有，因为有可能是false positive，如果是有的话，再找到相对应的交易直接进行一下确认</p><p>好处是通过bloom filter的结构能够快速过滤掉大量无关的区块，很多区块一看块头的bloom filter就知道肯定没有我们要的交易，然后剩下的一些少数的候选区块，再仔细查看。比如说一个轻节点，只有块头信息，根据块头就已经能够过滤掉很多区块了，剩下有可能是想要的区块，再问全节点要进一步的信息</p><h5 id="4）、补充"><a href="#4）、补充" class="headerlink" title="4）、补充"></a>4）、补充</h5><p>状态树、交易树、 收据树三棵树的根哈希值都是包括在块头里面的，以太坊的运行过程可以看作是一个<strong>交易驱动的状态机</strong>（transaction-driven state machine）。这个状态机的状态是所有账户的状态，就是状态树中包含的那些内容，交易是每次发布区块里包含的交易，通过执行这些交易会驱动系统从当前状态转移到下一个状态</p><p>比特币也可以认为是一个交易驱动的状态机，比特币中的状态是UTXO（没有被花掉的那些输出），每次新发布一个区块，会从UTXO里用掉一些输出，又会增加一些新的输出，所以发布的区块会驱动状态机从当前状态转移到下一个状态</p><p>而且这两个状态机有一个共同的特点，就是状态转移都得是确定性的，对一个给定的当前状态、一组给定的交易（就是这个区块中包含的交易），能够确定性地转移到下一个状态，因为所有的全节点、所有的矿工，都要执行同样的状态转移，所以状态转移必须是确定性的</p><p><strong>问题1：某人在以太坊发布一个交易，某个节点收到这个交易，转账交易A-&gt;B，有没有可能这个收款人的地址从来没听说过？</strong></p><p>以太坊和比特币是一样的，创建账户是不需要通知其他人的，只有这个账户第一次收到钱的时候，其他的节点才会知道这个账户的存在，这个时候要在状态树中新插入的一个节点，因为这个是新增加的账户</p><p><strong>问题2：状态树、交易树、收据树的区别是，状态树要包含系统中所有账户的状态，无论这些账户是否参与了当前区块的交易，那么能不能把状态树的设计改一下，改成每个区块的状态树也只包含这个区块中的交易相关的那些账户的状态，这样就跟交易树和收据树一致了，而且可以大幅度的削减每个区块所对应的状态树的大小，因为大部分的账户状态是不会变的？</strong></p><p>这样设计的结果是每个区块没有一棵完整的状态树，只有当前区块中所包含的交易涉及到的账户的状态</p><p>这么设计的一个问题就是，如果要想查找某个账户的状态就不方便了。比如说有一个转账交易A转给B 10个以太币，要检查A账户里是不是真的有10个以太币，问题是最近一个区块对应的那个状态树可能没有A这个账户，往前一直找，找到最近的一个包含A账户的区块，才能知道A的账户余额是多少。如果A有较长的一段时间没有发生交易，可能要从后往前，扫描很多个区块，才能找到最近一次的账户状态</p><p>还有一个更大的问题，就是A转给B钱的时候，要知道A账户的状态，才能知道A是不是有足够的钱转给B 10个以太币，也要知道B账户的状态，余额是多少，因为要往B账户余额里加10个以太币，所以也要找B账户的状态，而B账户有可能是个新建的账户，这个时候就要找到创世纪块去，从当前区块一直找到创世纪块，发现这个账户没有，才知道原来是个新建的账户</p><h5 id="5）、代码中具体的数据结构"><a href="#5）、代码中具体的数据结构" class="headerlink" title="5）、代码中具体的数据结构"></a>5）、代码中具体的数据结构</h5><p><img src="/../article_img/Web3/img4-18.png" alt="在这里插入图片描述"></p><p>交易树和收据树的创建过程，在NewBlock函数里创建了交易树和收据树，并且得到了他们的根哈希值</p><p><img src="/../article_img/Web3/img4-19.png" alt="在这里插入图片描述"></p><p>先看一下交易树的代码，首先判断交易列表是否为空，如果是空的话，那么这个区块里块头的交易树的根哈希值就是一个空的哈希值，否则通过调用DeriveSha函数来得到交易树的根哈希值，然后创建区块的交易列表</p><p><img src="/../article_img/Web3/img4-20.png" alt="在这里插入图片描述"></p><p>中间这个代码是收据树，首先判断一下收据列表是否为空，如果为空，块头里收据树的根哈希值就是一个空的哈希值，如果不为空，通过调用DeriveSha函数来得到收据树的根哈希值，然后创建块头里的bloom filter，每个交易执行完之后会得到一个收据，所以交易列表的长度和收据列表的长度是一样的</p><p><img src="/../article_img/Web3/img4-21.png" alt="在这里插入图片描述"></p><p>最下面这段代码是叔父区块的，首先判断叔父列表是否为空，如果是的话，那么块头里叔父区块的哈希值就是一个空的哈希值，否则，通过调用CalcUncleHash函数计算出哈希值，然后通过循坏构建出区块里的叔父数组</p><p><img src="/../article_img/Web3/img4-22.png" alt="在这里插入图片描述"></p><p>DeriveSha函数，前面NewBlock函数创建交易树和收据树的时候，调用的都是这个函数，这里创建的数据结构是trie</p><p><img src="/../article_img/Web3/img4-23.png" alt="在这里插入图片描述"></p><p>而trie的数据结构是一棵MPT，以太坊的三棵树：交易树、收据树、状态树用的都是MPT</p><p><img src="/../article_img/Web3/img4-24.png" alt="在这里插入图片描述"></p><p>这是Receipt的数据结构，每个交易执行完之后形成的一个收据，记录了这个交易的执行结果</p><p>Bloom就是这个收据的bloom filter</p><p>Logs是个数组，每个收据可以包含多个Log，这些收据的bloom filter就是根据这些Log产生出来的</p><p><img src="/../article_img/Web3/img4-25.png" alt="在这里插入图片描述"></p><p>这是区块块头的数据结构，里面的Bloom域就是整个区块的bloom filter，这个是由每个收据的bloom filter合并在一起得到的</p><p><img src="/../article_img/Web3/img4-26.png" alt="在这里插入图片描述"></p><p>这是刚刚的NewBlock函数，红框里的代码就是创建块头里的bloom filter，通过调用CreateBloom这个函数</p><p><img src="/../article_img/Web3/img4-27.png" alt="在这里插入图片描述"></p><p>这是相关的三个函数的代码实现</p><p>CreateBloom函数的参数是这个区块的所有收据，这个for循环对每个收据调用LogsBloom函数来生成这个收据的bloom filter，然后把这些bloom filter用Or操作合并起来得到整个区块的bloom filter</p><p>LogsBloom函数的功能是生成每个收据的bloom filter，他的参数是这个收据的Log数组，刚才看过Receipt的数据结构，每个Receipt里面包含一个Logs的数组，这个函数有两层for循环，外层循环对Logs数组里的每一个Log进行处理，首先把Log的地址取哈希后，加到bloom filter里面，这里的bloom9是bloom filter中用到的哈希函数，然后内层循环把Log中包含的每个Topics加入到bloom filter里，这样就得到了这个收据的bloom filter</p><p>bloom9是bloom filter中用到的哈希函数，这里的bloom9函数是把输入映射到digest中的三个位置，把三个位置都置为1</p><p>第一行调用crypto里面的函数，生成一个256位的哈希值，b这个变量是个32个字节的哈希值</p><p>第二行的r是要返回的bloom filter，在这里初始化为0</p><p>接下来是个循环，把刚才生成的32个字节的哈希值取前六个字节，每两个字节组成一组拼接在一起，然后and上2047，相当于对2048取余，得到一个位于0到2047这个区间里的数，这样做是因为以太坊中bloom filter的长度是2048位。这个循环的最后一行，把t左移这么多位然后合并到上一轮得到的bloom filter里，通过Or运算合并到前面的bloom filter里，经过三轮循环，把三个位置置为1后，返回所创建的bloom filter</p><p><img src="/../article_img/Web3/img4-28.png" alt="在这里插入图片描述"></p><p>前面是生成bloom filter的过程，那么怎么查询某个bloom filter里面是否包含了我们感兴趣的topic呢?</p><p>这是通过调用BloomLookup函数来实现的，查一下bin的bloom filter里有没有包含要找的第二个参数topic，首先用bloom9函数把topic转化成一个bytesBacked，然后把他跟bloom filter取and操作，看看得到的结果是不是和bytesBacked相等。注意bloom filter里面可能包含除了我们要查找的topic之外其他的topic，所以要做一个and，然后再跟他自身比较，相当于判断一下我们要查找的这个topic在bloom filter中对应的位置是不是都是1</p><p><strong>对应课程</strong>：</p><p><a href="https://www.bilibili.com/video/BV1Vt411X7JF">北京大学肖臻老师《区块链技术与应用》公开课</a></p><p>本文转自 <a href="https://blog.csdn.net/qq_40378034/article/details/126458525">https://blog.csdn.net/qq_40378034/article/details/126458525</a>，如有侵权，请联系删除。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Web3</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>&lt;BTC&gt; 分叉、匿名性</title>
    <link href="/2025/05/01/BTC_3/"/>
    <url>/2025/05/01/BTC_3/</url>
    
    <content type="html"><![CDATA[<p>写在前面：<br>前段时间把b站上北大肖老师的区块链课程速通了一遍，这里引一下csdn上的优质课程笔记，便于个人后续温习。<br>博客链接：<a href="https://blog.csdn.net/qq_40378034/category_11862943.html">https://blog.csdn.net/qq_40378034/category_11862943.html</a><br>课程链接：<a href="https://www.bilibili.com/video/BV1Vt411X7JF/">https://www.bilibili.com/video/BV1Vt411X7JF/</a></p><span id="more"></span><h4 id="9、BTC-分叉"><a href="#9、BTC-分叉" class="headerlink" title="9、BTC-分叉"></a>9、BTC-分叉</h4><p>分叉指的是，原来的系统中是一条链，现在分成了两条链。分叉可能是多种原因造成的，例如：</p><ol><li>挖矿时两个节点差不多同时挖出矿，都会发布区块，这种分叉称为<strong>state fork，由于对区块链当前的状态有意见分歧而产生的分叉</strong></li><li><strong>分叉攻击（forking attack）也属于state fork</strong>，只不过这种意见分歧是<strong>人为造成的</strong>，这种情况也称为<strong>deliberate fork</strong></li><li>比特币协议改变，要修改比特币协议需要软件升级，<strong>在去中心化的系统中，没办法要求所有的节点都升级软件</strong>。假设大部分节点升级了软件，少部分节点没有升级（可能是没来得及升级，也可能是不同意协议的修改），这时候也会出现分叉，这种分叉称为<strong>protocol fork，即对比特币协议产生了分歧，使用不同版本的协议而产生的分叉</strong></li></ol><p>在protocol fork中，根据<strong>对协议修改的内容的不同</strong>，又可以分为<strong>硬分叉</strong>和<strong>软分叉</strong></p><h5 id="1）、硬分叉（hard-fork）"><a href="#1）、硬分叉（hard-fork）" class="headerlink" title="1）、硬分叉（hard fork）"></a>1）、硬分叉（hard fork）</h5><p>如果对比特币协议增加一些新的特性，扩展一些新的功能，这时候没有升级协议的那些节点是不认可这些特性的，认为它们是非法的</p><p>硬分叉的一个例子就是比特币中的区块大小限制，比特币规定每个区块不超过1M，可以包含的交易最大数量为4000笔左右。而平均10分钟产生一个区块，算下来大约平均每秒只能写入7个交易。所以有的人就认为区块太小了，限制了交易上链的速度</p><p><strong>假设协议更新了，将区块大小的限制从1M提高到4M</strong>，同时假设大多数节点更新了软件以支持这个协议（节点的多数和少数不是按账户数目来算的，而是根据<strong>算力</strong>来算的，假设系统中拥有大多数哈希算力的节点都更新了软件）</p><p>这样会有什么后果？</p><p><img src="/../article_img/Web3/img3-1.png"></p><p>上图1为当前区块链，此时软件更新，如上图2有一个新节点挖出了一个大区块（因为新的协议只要不小于4M）。但对于旧节点来说，该区块是一个非法区块，旧节点是不认可这个区块的，不会沿着这个区块继续往下挖，而是继续沿着之前的区块往下挖下一个区块，如上图3</p><p>需要注意的是，旧节点挖出的区块新节点是认可的（因为并未超过4M限制）。对旧节点来说，上图3中下面的链才是合法链，而对于新节点来说，这两条链都是合法的链。因为新节点算力强，所以出现上图4中情况可能性大。对于新节点来说，上面的链才是最长合法链，新节点都会沿着上面的链继续挖；对于旧节点来说，上面的链无论多么长，都是一条非法链，不会认可该链，所以旧节点就会沿着下面的链继续挖矿</p><p>此时就出现了新节点永远沿着上面的链挖矿，旧节点永远沿着下面的链挖矿，由于新节点算力足够强，所以形成两条永远都在延伸且平行的链。当然，上面的链也有可能会挖出大小在1M内的小区块，但对旧节点来说，该链上存在非法区块，不会认可该链。这种分叉是<strong>永久性的</strong>，只要这部分旧节点永远不更新软件，下面的链就永远不会消失</p><blockquote><ol><li>比特币社区中有些人很保守，不愿意加大区块大小</li><li>区块大小也不是越大越好，比特币网络传输是尽力而为的，区块加大会造成传输变慢等问题</li><li>单纯增加区块大小，对交易数量的增加远不能达到数量级的提升</li></ol></blockquote><p>出现硬分叉之后，就相当于社区分裂了，<strong>出现了两条平行运行的链，两条链上的比特币也是不相干的，各挖各的矿</strong>。在某条链上的出块奖励，对于认可这条链为最长合法链的节点而言是有效的，对认可另一条链的则是无效的，而分裂之前产生的比特币则是在两条链上都认可的。从这个意义上来看，硬分叉可以认为是产生了新的一种加密货币</p><p>硬分叉之后，如果不采取任何措施，两条链互相之间会产生一定影响。因为两条链上的账户的私钥、公钥等都是一样的，仅仅是运行的协议不同，按理来说两条链上的账户余额应该不一样才对</p><p><img src="/../article_img/Web3/img3-2.png"></p><p>如上图，在新链上有一笔B-&gt;C的交易，对旧链而言这笔交易也是完全合法的，旧节点挖矿时就会把这个交易回放了。这样就相当于B从一个钱包中拿出一定数量的币给C，导致B的另一个钱包中也转给了C同样数额（注意不是价值，如以太经典ETC和以太坊ETH）的币到相应的钱包中</p><p>为了解决这个问题，可以在<strong>硬分叉后设置chainId来标识这两条链为两条独立的链</strong></p><h5 id="2）、软分叉（soft-fork）"><a href="#2）、软分叉（soft-fork）" class="headerlink" title="2）、软分叉（soft fork）"></a>2）、软分叉（soft fork）</h5><p>如果对比特币协议加了一些限制，使得原本某些合法的交易或区块，在限制后的新协议中变得不合法，就会引起软分叉</p><p>假设协议更新将区块的限制大小变小了，从1M变成了0.5M（实际肯定不会这样做）</p><blockquote><p>需要注意的是，区块链中区块大小调整并非简单修改一个参数，调改大小就很有可能会引发分叉，由于参数修改方式不同，有可能会是硬分叉，也有可能是软分叉</p></blockquote><p>假设系统中大多数节点更新了软件，认为区块限制为0.5M；少部分节点是旧节点，仍然认为区块限制为1M</p><p><img src="/../article_img/Web3/img3-3.png"></p><p>上图为当前区块链，此时软件更新，如上图2有一个新节点挖出了一个小区块（因为新的协议不小于0.5M）。对于旧节点来说，该区块符合1M大小限制，旧节点认可这个区块，会沿着这个新的小区块开始挖矿，如上图3。但是新节点会认为旧节点挖出的区块超过0.5M限制，为一个非法区块，不会认可该区块，会从前一个小区块开始挖矿，如上图4。因为旧节点认可新区块，最终会造成如上图5中的效果，旧节点挖出的区块一直被抛弃，无法得到出块奖励（因为不在最长合法链上）。这就倒逼旧节点升级软件，最终会实现区块链上的所有矿工共同认可新协议，实现软件协议的升级</p><p>需要注意的是，旧节点如果不升级软件，挖出的区块可能就白挖了（大于0.5M），但对于系统来说，不会存在永久性分叉</p><p><strong>实际当中可能出现软分叉的情况：</strong></p><p><strong>1）给某些目前协议中未规定的域赋予新的含义</strong></p><p>最经典的就是，coinbase transaction（铸币交易）中CoinBase域。在CoinBase域中写入任何内容都可以，没有任何规定。挖矿本质是调整block header中的nonce，但其本身只有4个字节，搜索空间太小。所以实际使用中，将CoinBase域前8个字节作为extra nonce，此时搜索空间从原本 2 32 2^{32} 232增长到 2 96 2^{96} 296，对于目前挖矿难度来说已经足够</p><p>但CoinBase中并不是只有8个字节，还剩下很多空间。有人就提出将其作为UTXO（当前还没花掉的交易的输出）集合的根哈希值。目前UTXO是每个全节点自己在内存中维护的，主要是为了快速查找来判断交易是否是double spending，但UTXO内容并未写入区块链</p><p>由于UTXO存在本地，如果查询某账户余额，轻节点需要询问全节点，全节点根据UTXO中信息可以计算得到账户余额，如何证明全节点返回给轻节点的是正确的呢？轻节点自己没有维护一个UTXO集合，所以是证明不出来的</p><p>因此有人提出将UTXO中的交易也组织成一个Merkle Tree，将其根哈希值写在coinbase transaction的CoinBase域里面，而coinbase transaction中的此内容也会随着影响交易的Merkle Tree的根哈希值，这在轻节点里是保存了的。所以在这种方式下就可以像Merkle proof的方式一样证明账户里有多少钱（需要提供UTXO的Merkle Tree对应位置的哈希）</p><p><strong>2）增加新的功能</strong></p><p>P2SH（Pay to Script Hash）在最初的比特币系统中是没有的，是后来通过软分叉的方式加进去的</p><p>P2SH在支付时输出不是收款人公钥的哈希，而是一个赎回脚本（Redeem Script）的哈希</p><p>在赎回（把这些比特币花出去）时分为两阶段，第一阶段验证输入脚本中给出的赎回脚本，和前面交易的输出脚本中的赎回脚本的哈希对得上，第二阶段执行赎回脚本，验证输入脚本中给出的签名是合法的</p><p>对于旧节点而言，并不知道赎回脚本的这些特性，旧节点只会做第一阶段的验证，即验证赎回脚本是不是正确的（和哈希对得上）。只有新节点才会把两阶段的验证都做完</p><p>所以旧节点验证通过的交易，可能是第二阶段验证无法通过的P2SH形式的交易，在新节点上无法验证通过。而新节点验证通过的交易，旧节点也都验证通过</p><h5 id="3）、小结"><a href="#3）、小结" class="headerlink" title="3）、小结"></a>3）、小结</h5><p><strong>软分叉的特点</strong>：只要系统中拥有半数以上算力的节点更新了软件，就不会出现永久性的分叉</p><p><strong>硬分叉的特点</strong>：必须系统中所有的节点都更新了软件，才不会出现永久性的分叉</p><h4 id="10、BTC-问答"><a href="#10、BTC-问答" class="headerlink" title="10、BTC-问答"></a>10、BTC-问答</h4><ol><li><p>转账交易时候，如果接收者不在线（没有连在比特币网络上）怎么办？</p><p>转账交易只需要在区块链上记录，将某账户比特币转到另一账户，而接收方是否在线并无影响</p></li><li><p>假设某全节点收到某个转账交易，会不会有可能转账交易中收款人地址该全节点从未听过？</p><p>可能，因为比特币账户只需要本地产生即可。只有该账户第一次收到钱时，其他节点才能知道该节点的存在</p></li><li><p>如果账户私钥丢失怎么办？</p><p>没有办法。因为比特币是去中心化货币，没有第三方中心机构可以重置密码，所以账户上的钱也就变成了死钱</p><p>通过加密货币交易所（中心化机构），一般需要提供身份证明，如果忘记私钥可以找交易所申请追回私钥。但目前这类货币的交易所还处于缺少监管的状态，并不一定具有可信力</p><p>在历史上，有很多次交易所被黑客攻击偷走大量加密货币的事情，其中最著名的为Mt.Gox（门头沟）事件。该交易所曾经为全球最大比特币交易所，交易量占到全球比特币交易量的70%左右，设于日本。后来由于被攻击丢失大量比特币，导致交易所破产，其CEO被判刑入狱</p></li><li><p>私钥泄露怎么办？</p><p>尽快将剩余比特币转到其他安全账户上，没有第三方中心机构重置密码或冻结账户，只能自己对自己负责</p><p>比特币系统中账户就是公私钥对，密码就是私钥，无法更改</p></li><li><p>转账写错地址怎么办？</p><p>没有办法，无法取消已经发布的交易。如果转入不存在地址，则该部分比特币就成为了死钱。比特币系统中UTXO会永久保存该交易，记录该并不存在的地址。因此，对全节点来说，这是不友好的</p></li><li><p>比特币脚本中的OP_RETURN指令的执行结果是无条件返回错误，而交易返回错误，区块又怎么会包含它？区块链又如何会接收这个区块？</p><p>OP_RETURN是写在当前交易的输出脚本中，而验证交易合法性时，使用的当前交易的输入脚本和前一个交易（币来源的交易）的输出脚本进行验证。也就是说，验证当前交易合法性时，并不会执行该语句。只有在有人想花这笔钱时候，才会执行该语句</p></li><li><p>比特币系统挖矿会不会有矿工偷答案？比如，某个矿工发现其他矿工发布了nonce，收到后验证该区块合法，将该nonce作为自己找到的nonce发布出去</p><p>实际上这是不可能的。发布的区块中包含coinbase transaction（铸币交易），其收款人地址为挖到矿的矿工地址，如果要偷答案，需要修改该收款地址，而地址改变，coinbase transaction内容也发生改变，从而引发Merkle Tree根哈希值改变，从而导致原本的nonce作废。也就是说，不可能会偷答案</p></li><li><p>交易费是交易者为了自己交易可以上链而给出的小费，那么事先如何得知哪个矿工可以挖到矿？</p><p>事先不需要知道谁会挖到矿，交易中总输入和总输出差额就是交易费。哪个矿工挖到矿，在打包交易时，可以将这些交易费收集起来作为自己获得的交易费</p></li></ol><h4 id="11、BTC-匿名性"><a href="#11、BTC-匿名性" class="headerlink" title="11、BTC-匿名性"></a>11、BTC-匿名性</h4><p>匿名性（anonimity） 总是和隐私保护相关，即用户做的事情不想被别人知道。因为比特币系统中账户的产生不会暴露用户个人信息，用户可以产生很多对账户，然后用不同的账户做不同的事情。但这种不暴露个人信息的账户显然不是完全的匿名，可以称为假名（<strong>pseudonymity</strong>）。所以比特币系统中的匿名只是一种假的匿名，就像作家写作用笔名，网民上网交流用网名一样</p><h5 id="1）、比特币的匿名性能提供什么程度的隐私保护"><a href="#1）、比特币的匿名性能提供什么程度的隐私保护" class="headerlink" title="1）、比特币的匿名性能提供什么程度的隐私保护"></a>1）、比特币的匿名性能提供什么程度的隐私保护</h5><p><strong>和现金相比：</strong></p><p>和现金相比，比特币的匿名性没有现金好，现金上没有任何持有者的信息，所以很多非法交易用的都是大额现金。现金的劣势就是不便于保管和运输</p><p><strong>和银行存款相比：</strong></p><p>如果银行允许化名的话（以前国内银行不要求实名），比特币的匿名性没有银行好。因为比特币系统中所有有效的交易都写在区块链上，所有人都可以看到，而银行中的交易信息是受控制的，只有银行本身或者司法手段能获取到</p><h5 id="2）、比特币系统中什么情况下可能破坏匿名性"><a href="#2）、比特币系统中什么情况下可能破坏匿名性" class="headerlink" title="2）、比特币系统中什么情况下可能破坏匿名性"></a>2）、比特币系统中什么情况下可能破坏匿名性</h5><p><strong>1）地址账户之间产生关联</strong></p><p>表面上看，每次交易可以更换公私钥对，从而每次都是新的账户，具有很强的匿名性。但实际上，这些账户在一定情况下是可以被关联起来的</p><p>例如出现下图这样的交易：</p><p><img src="/../article_img/Web3/img3-4.png"></p><p>从这个交易中，可以推断地址1和地址2很可能是同一个人持有，因为买东西时候很可能一个比特币账户中的钱不是正好够用，就要用到多个账户的钱</p><p>而地址3和地址4很可能有其中之一还是这个人持有，因为一个地址是卖家的账户地址，另一个地址就是找零的地址</p><p>这些地址可能都是比特币钱包的软件自动生成的，在找零时自动生成一个新的地址，以更好的进行隐私保护</p><p>比特币生成交易的时候并没有规定找零的地址在输出中的位置，但可能可以分析出来，如下面是这几个输入输出中的比特币数量：</p><p><img src="/../article_img/Web3/img3-5.png"></p><p>可以猜测地址4就是找零的地址，因为如果只要买价格是3个比特币的东西，不需要使用地址1和地址2这两个账户，只动用其中一个就可以了</p><p>现在常用的比特币钱包就那些种，搞清它们生成交易输入输出的方式，比特币系统中的大多交易匿名性也就低了很多</p><p><strong>2）地址账户和现实身份产生关联</strong></p><p>任何让虚拟货币和现实世界发生联系的时候都可能泄露身份，其中最明显的就是<strong>资金的转入和转出</strong>。比如很多人获得比特币的过程肯定不是挖矿挖出来的，而是买过来的，可以在交易所买（需要在交易所注册登记），也可以场外交易（两个人私下交易）</p><p>很多国家有反洗钱法，如何防范用比特币洗钱的行为？只要盯住大额度的转入和转出，即大量买入比特币和大量比特币转出为法币的情况</p><p><strong>用比特币支付</strong>的时候也会引起隐私泄露，因为这时候也是将自己的比特币账户和自己身份关联起来了。不仅仅是向收款方泄露了自己的比特币账户，同时周围的人可以知道这个人在这个时间用比特币消费了这家店，然后知道了这家店的收款账户，再根据这个时间很容易就能在区块链上找到对应的交易记录，然后就知道这个人的比特币账户地址了</p><p>中本聪的比特币匿名性保持的最好，就是因为他一点比特币也没有花出去</p><h5 id="3）、如何提高匿名性"><a href="#3）、如何提高匿名性" class="headerlink" title="3）、如何提高匿名性"></a>3）、如何提高匿名性</h5><p>比特币系统运行在应用层，其下层是P2P网络，所以可以在这两层考虑提高匿名性</p><p><strong>网络层：</strong></p><p>当本地节点将交易发布到比特币网络上时，其它节点如果发现一直收到此账户的交易都是来自这个或这几个ip地址，那么就可以根据ip地址来查验身份</p><p>好在虽然区块链是新生事物，但网络层的匿名性已经有了很好的解决方案，比如<strong>多路径转发</strong></p><p><strong>应用层：</strong></p><p>破坏匿名性的一个原因就是同一个人的不同比特币账户会被关联起来，而在区块链上可以看到所有具体的交易及其来源，所以可以考虑<strong>将不同人的币混起来（coin mixing）</strong></p><p>有一些专门的网站，收取一定的费用，将所有要做coin mixing的人给的币混合起来，然后经过coin mixing再取出来再做交易。在现在的比特币环境下，没有什么信誉度很高的coin mixing服务。因为做coin mixing服务的机构的账户本身也要保持匿名，如果他们卷款跑了也很难把钱追回来</p><p>没有必要特意去做coin mixing，有些应用本身带有coin mixing的性质，比如某些在线钱包以及交易所。交易所天然带有coin mixing的性质，比如将比特币存入到交易所，过一段时间卖出得到法币，然后又用法币买进比特币，那么买进的就不是当初存入的比特币了。但这样保持匿名性的前提是交易所不会泄露个人信息以及提币和买入币的信息</p><h5 id="4）、零知识证明（zero-knowledge-proof）"><a href="#4）、零知识证明（zero-knowledge-proof）" class="headerlink" title="4）、零知识证明（zero-knowledge proof）"></a>4）、零知识证明（zero-knowledge proof）</h5><p><strong>零知识证明是指一方（证明者）向另一方（验证者）证明一个陈述是正确的，而无需透露除该陈述是正确的之外的任何信息</strong></p><p>例如：A想要向B证明某一账户属于A，这说明A知道该账户的私钥。但不可能通过A公布私钥的方法来证明，该账户确实属于A。因此，A可以产生一个用私钥进行的签名，B通过公钥验证签名的正确性（实际上该证明是否属于零知识证明存在争议，因为泄露了用私钥产生的签名）</p><p><strong>同态隐藏：</strong></p><p><img src="/../article_img/Web3/img3-6.png"></p><p>零知识证明的数学基础就是同态隐藏，上图为同态隐藏的三个性质：</p><p>第一个性质说明加密函数E不会出现碰撞，反过来说明如果有E(x)&#x3D;E(y)，则必然有x&#x3D;y</p><p>第二个性质说明加密函数不可逆，知道加密值无法反推出密码值</p><p>第三个性质最为重要，称为同态运算，说明对加密后的函数值进行某些代数运算，等价于对输入直接进行代数运算再加密</p><p>案例：Alice想要向Bob证明她知道一组数x和y使得x+y&#x3D;7，同时不让Bob知道x和y的具体数值</p><p>其中证明者为Alice，验证者为Bob。最简单的证明版本如下：</p><ol><li>Alice把E(x)和E(y)的数值发给Bob（Bob知道E(x)和E(y)的数值无法反推出x和y的具体数值，利用了性质2）</li><li>Bob通过收到的E(x)和E(y)计算出E(x+y)的值（利用了性质3）</li><li>Bob同时计算E(7)的值，如果E(x+y)&#x3D;E(7)，那么验证通过，否则验证失败（如果有E(x)&#x3D;E(y)，则必然有x&#x3D;y，利用了性质1）</li></ol><p>缺陷：Bob可以用蛮力算法猜出x和y的值，Bob虽然通过E(x)无法知道x是多少，但是可以遍历x的各种取值，用蛮力算法一个个比较，看哪个恰好和E(x)相等</p><p><strong>盲签：</strong></p><p>央行发布虚拟货币：</p><p>方案一：发布的货币带有央行的签名，支付的时候把带签名的货币给出就可以了。这个方案是不行的，因为签名可以复制，无法防止双花攻击</p><p>方案二：每个数字货币需要有个编号，央行数据库中记录编号的钱有没有被花过，是在谁的手里，可以防止双花攻击。这个方案不利于匿名性，每一笔交易都必须通过央行，央行知道用户所有的交易信息。盲签可以解决这个问题</p><p><img src="/../article_img/Web3/img3-7.png"></p><p><strong>零币和零钞——专门为匿名性设计的货币：</strong></p><p>比特币在一定程度上提供了匿名性，但无法完全消除关联性。零币和零钞就是为此问题设计的加密货币，运用密码学原理保证匿名性</p><p><img src="/../article_img/Web3/img3-8.png"></p><p>这里基础币是既有的一种币，比如比特币，然后将其变成花不出去的状态换取零币。在花零币的时候，只要通过零知识证明证明花的是系统中的多少币，而不需要说明花的是哪些币</p><p>零币和零钞还不是很流行，原因是很多方面的：</p><ul><li>为了匿名性，损失了一些性能</li><li>对初始化有比较严格的要求，初始化使用的随机源要能很好的销毁掉，否则会有安全漏洞</li><li>需要强匿名性的用户不多（大多不做非法洗钱之类的事情）</li><li>与现实世界发生交互时，仍然会破坏匿名性</li></ul><h4 id="12、BTC-思考"><a href="#12、BTC-思考" class="headerlink" title="12、BTC-思考"></a>12、BTC-思考</h4><h5 id="1）、哈希指针"><a href="#1）、哈希指针" class="headerlink" title="1）、哈希指针"></a>1）、哈希指针</h5><p>比特币系统中很多地方使用到了哈希指针。指针保存的本地内存地址，只有在本地计算机上才有意义，如果发送给其他计算机就没有意义了。那么<strong>在区块发布的时候，哈希指针如何通过网络进行传输？</strong></p><p>所谓的哈希指针只是一种形象的说法，实际系统中用的时候只有哈希没有指针</p><p><img src="/../article_img/Web3/img3-9.png"></p><p>在block header中只有hash值，没有指针。那么如何查找到前一个区块的内容？</p><p>全节点一般将区块存储于一个key-value数据库中，key是区块的哈希，value是区块内容。常用的key-value数据库是LevelDB，只要掌握了最后一个区块的哈希值，就可根据哈希值一直往前找到区块链所有内容</p><p>有些节点只保存区块链部分信息，如果需要用到前面的区块，可以问其他节点要。哈希指针的性质保证了整个区块链内容是不可篡改的</p><h5 id="2）、区块恋"><a href="#2）、区块恋" class="headerlink" title="2）、区块恋"></a>2）、区块恋</h5><p>有情侣一起买比特币，将私钥从中截断，每人保留其中一部分。如果未来两人依旧感情很好，就可以将钱取出；如果分手，这部分钱就会永久锁死，谁也无法取出，通过区块链的不可篡改性作为两人的爱情见证。这样做有什么问题？如此下来，N个人的账户该怎么办？</p><p>如果按照这种方法，将私钥分为N份。但这样会有一系列问题：</p><ol><li>如果N个人中任意一个人忘记私钥，则无法将钱取出</li><li>截断私钥的做法会降低账户的安全性。比特币系统中每个账户的安全性跟所用的私钥的长度是相关的，256位的私钥用暴力破解的方法是不可行的，计算量太大。 2 256 2^{256} 2256远远大于 2 128 2^{128} 2128，之间难度差距远远不止一倍。对于多个人的共享账户，应该使用多重签名，而非截断私钥的方法</li><li>如果分手，该钱变成死钱，一直保存在UTXO集合中，对矿工不友好</li></ol><h5 id="3）、分布式共识"><a href="#3）、分布式共识" class="headerlink" title="3）、分布式共识"></a>3）、分布式共识</h5><p>理论上来说，分布式系统中不可能达成共识。为什么比特币系统能够绕过分布式共识中的那些不可能结论？</p><p>严格来说，比特币系统并没有取得真正意义上的共识，因为取得的共识随时可能被推翻。比如出现了分叉攻击，本来以为已经达成了某个共识，分叉攻击后系统会回滚到前一个状态，从理论上说甚至可能一直回滚到创世纪块。按照分布式系统理论的要求，共识一旦达成之后就不应该再改了，从这个意义上来说比特币并没有绕过分布式共识中的那些不可能结论，因为并没有达到真正意义上的共识</p><p>理论和实际往往是有距离的。不可能结论只是针对某种特定模型的，实际中对模型稍微修改就可以将不可能变为可能</p><h5 id="4）、比特币的稀缺性"><a href="#4）、比特币的稀缺性" class="headerlink" title="4）、比特币的稀缺性"></a>4）、比特币的稀缺性</h5><p>为什么要挖矿？因为有收益，且收益大于开销。早期比特币难度低且出块奖励高，从而吸引矿工</p><p>比特币总量固定，有人认为其是一个精妙的设计。但实际上，总量固定的东西是不适合作为货币的，这也就决定了比特币并不能在未来完全颠覆现有货币体系。以太坊中就没有比特币中出块奖励定期减半的做法，此外，某些新型货币会自带通货膨胀的功能</p><p>对个人来说，通货膨胀并不是好事，因为钱不值钱了。但人类每年创造的价值，如果用总量固定的东西作为货币，则其只会越来越值钱，而这会导致拥有者不断看着其升值，其他没有的人无论如何奋斗都赶不上</p><h5 id="5）、量子计算"><a href="#5）、量子计算" class="headerlink" title="5）、量子计算"></a>5）、量子计算</h5><p>会不会比特币这种建立在密码学上的加密货币，在量子计算出来后会不会变得不安全？</p><ol><li>量子计算距离使用仍然有很长距离</li><li>量子计算若真正使用到破坏现有加密算法，对传统金融业的破坏是最大的</li><li>实际中使用的不是公钥，而是使用公钥的哈希。而哈希函数一般都是不可逆的，所以即使量子计算也无法反推私钥</li></ol><p>比特币中用的SHA-256，无论输入多大，最终结果都为256位，必然会导致信息丢失，无法反推原本数据</p><p>加密和哈希的区别：<strong>加密可逆，哈希不可逆；加密不损失信息，哈希破坏信息</strong></p><p><strong>对应课程</strong>：</p><p><a href="https://www.bilibili.com/video/BV1Vt411X7JF">北京大学肖臻老师《区块链技术与应用》公开课</a></p><p>本文转自 <a href="https://blog.csdn.net/qq_40378034/article/details/126199309">https://blog.csdn.net/qq_40378034/article/details/126199309</a>，如有侵权，请联系删除。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Web3</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>&lt;BTC&gt; 网络</title>
    <link href="/2025/05/01/BTC_2/"/>
    <url>/2025/05/01/BTC_2/</url>
    
    <content type="html"><![CDATA[<p>写在前面：<br>前段时间把b站上北大肖老师的区块链课程速通了一遍，这里引一下csdn上的优质课程笔记，便于个人后续温习。<br>博客链接：<a href="https://blog.csdn.net/qq_40378034/category_11862943.html">https://blog.csdn.net/qq_40378034/category_11862943.html</a><br>课程链接：<a href="https://www.bilibili.com/video/BV1Vt411X7JF/">https://www.bilibili.com/video/BV1Vt411X7JF/</a></p><span id="more"></span><h4 id="5、BTC-网络"><a href="#5、BTC-网络" class="headerlink" title="5、BTC-网络"></a>5、BTC-网络</h4><p>用户将交易发布到比特币网络上，节点收到交易后打包到区块中，然后将区块发布到比特币网络上，那么新发布的交易和区块在比特币网络上是如何传播的呢？</p><p>比特币工作于网络应用层，其底层（网络层）是一个P2P Overlay Network（P2P覆盖网络）</p><ul><li>应用层：Bitcoin Blockchain</li><li>网络层：P2P Overlay Network</li></ul><p>比特币系统中所有节点都是对等的，不像一些其他网络存在超级节点（super node或master node）。要加入网络，至少需要知道一个<strong>种子节点</strong>（seed node），通过种子节点告知自己它所知道的节点。节点之间的通信采用了TCP协议，便于穿透防火墙。当节点离开时，只需要自行退出即可，其他节点在一定时间后仍然没有收到该节点消息，便会将其删掉</p><p>比特币网络设计原则：<strong>简单、鲁棒（最坏情况下能达到最优状况，即健壮性）而非高效</strong>（simple,robust,but not efficient）</p><p>每个节点维护一个邻居节点集合，消息传播在网络中采用洪泛法（flooding），某个节点在收到一条消息会将其发送给所有邻居节点并标记，下次再收到便不会再发送该消息。邻居节点选取随机，没有考虑网络底层拓扑结构，也与现实世界物理地址无关。该网络具有极强鲁棒性，但牺牲了网络效率</p><h5 id="1）、新发布的交易的传播"><a href="#1）、新发布的交易的传播" class="headerlink" title="1）、新发布的交易的传播"></a>1）、新发布的交易的传播</h5><p>比特币系统中，<strong>每个节点要维护一个等待上链的交易集合</strong>。第一次听到交易，如果是合法交易，则将其加入该交易集合并转发给邻居节点，以后再收到该交易就不再转发（避免网络上交易无限传输）</p><p>如果有冲突的交易几乎同时发布到网络上，每个节点根据其位置的不同，可能先收到的交易是不同的，那么另一个交易对于这个节点来说就是非法的了，不会放到集合中</p><p><img src="/../article_img/Web3/img2-1.png"></p><p>如上图，以左边的节点为例，它先听到A-&gt;B的交易，将其写入到了自己的交易集合中</p><p>如果它收到了一个新发布的区块，其中包含A-&gt;B这个交易，说明这个交易已经被写入区块链了，所以就要在自己的交易集合中将其删除掉</p><p>如果它收到了一个新发布的区块中包含A-&gt;C这个交易，这时也要将集合中A-&gt;B的交易删除掉，因为检查可以发现此时集合中的A-&gt;B这个交易是非法交易，它和新发布的区块中的A-&gt;C这个交易冲突了</p><h5 id="2）、新发布的区块的传播"><a href="#2）、新发布的区块的传播" class="headerlink" title="2）、新发布的区块的传播"></a>2）、新发布的区块的传播</h5><p>新发布区块在网络中传播方式与新发布交易传播方式类似，每个节点除检查该区块内容是否合法，还要检查是否位于最长合法链上。区块越大，则网络上传输越慢。BTC协议对于区块大小限制为不大于1M大小</p><p>区块大小越大，网络上传播时延越长；区块大小越小，则可以包含的交易数目越少</p><p>此外，比特币网络传播属于<strong>Best effort</strong>（尽力而为），不能保证一定传输成功。以一个交易发布到网络上，未必所有节点都能收到，也未必所有节点收到交易顺序都一致</p><h4 id="6、BTC-挖矿难度"><a href="#6、BTC-挖矿难度" class="headerlink" title="6、BTC-挖矿难度"></a>6、BTC-挖矿难度</h4><h5 id="1）、挖矿难度？"><a href="#1）、挖矿难度？" class="headerlink" title="1）、挖矿难度？"></a>1）、挖矿难度？</h5><p>挖矿就是不断尝试block header中的nonce值，使得整个block header的哈希值小于等于给定的目标阈值。即H(block header)&lt;&#x3D;target（target是目标阈值，target越小，目标难度就越大）。<strong>调整挖矿难度就是调整目标空间在整个输出空间中所占比例大小</strong></p><p>比特币系统采用的哈希算法是SHA-256，所以整个输出空间大小是 2 256 2^{256} 2256，调整目标空间所占比例简单的说需要目标值前需要多少个0<br>d i f f i c u l t y &#x3D; d i f f i c u l t y _ 1 _ t a r g e t t a r g e t difficulty&#x3D;\frac{difficulty\_1\_target}{target} difficulty=targetdifficulty_1_target​<br>挖矿难度和目标阈值成反比，如上公式中，其中difficulty_1_target为是挖矿难度为1时候的target，即最小挖矿难度</p><h5 id="2）、为什么要调整挖矿难度？"><a href="#2）、为什么要调整挖矿难度？" class="headerlink" title="2）、为什么要调整挖矿难度？"></a>2）、为什么要调整挖矿难度？</h5><p>系统中的总算力越来越强，如果挖矿难度保持不变，那么平均出块时间会越来越短。出块时间缩短，那么交易可以很快便被写入区块链，并且提高了系统响应时间，增加了区块链系统效率。但是，出块时间不是越短越好，出块时间太短也会造成一定的问题</p><p>假设平均出块时间减小到了1秒钟，但这个区块在比特币网络上传播给大多数节点可能就要几十秒，如果有两个节点几乎同时发布了区块，那么就会出现分叉</p><p><img src="/../article_img/Web3/img2-2.png"></p><p>这是一个二分叉的情况，<strong>如果出块时间很短，就会导致这种分叉成为常态。而且不仅仅是二分叉，可能会出现很多分叉</strong></p><p>分叉过多对于比特币系统达成共识没有好处，并且会危害比特币系统的安全</p><p>比如分叉攻击，正常情况下大部分节点是诚实的，有恶意的节点想要在6个确认后拿这段时间集中算力算出的新链去覆盖掉最长合法链是很难的，因为诚实节点也都在集中算力扩展最长合法链。如果出块时间很短，就会导致分叉过多，这样诚实节点的算力就被分散了，这时恶意节点要进行51% attack很可能就不需要50%以上的算力了，可能百分之十几就足够了，这样大大降低了比特币系统的安全性</p><p><strong>10分钟的出块时间也不是最优解，只是说系统出块时间需要维持在一个定值附近，不能无限的减少下去</strong>。以太坊中平均出块时间仅为15秒左右，同样在以太坊中也有相应难度调整算法维持其平均出块时间，当然15s的时间明显会产生经常性的分叉，所以以太坊设计了新的共识协议Ghost。在这个协议中，分叉产生的orphan block（孤儿区块）不能简单丢弃掉，而是也要给予一些奖励（uncle reward）</p><h5 id="3）、比特币中如何调整挖矿难度？"><a href="#3）、比特币中如何调整挖矿难度？" class="headerlink" title="3）、比特币中如何调整挖矿难度？"></a>3）、比特币中如何调整挖矿难度？</h5><p>比特币协议中规定，每隔2016个区块需要调整一次目标阈值target，根据10分钟产生一个新区块，大概需要14天的时间，调整共识如下：<br>t a r g e t &#x3D; t a r g e t × a c t u a l   t i m e e x p e c t e d   t i m e target &#x3D; target \times \frac{actual \ time}{expected \ time} target=target×expected timeactual time​<br>expected time是预期的两次调整的间隔时间，即 2016 × 10 分钟 &#x3D; 14 天 2016 \times 10分钟 &#x3D; 14天 2016×10分钟=14天；而actual time是系统中产生最近的2016个区块实际花费的时间</p><p>如果实际时间超过14天，说明平均下来出块间隔超过10分钟，这时应该降低挖矿难度，让出块更容易。对应的公式中 a c t u a l   t i m e e x p e c t e d   t i m e &gt; 1 \frac{actual \ time}{expected \ time} &gt; 1 expected timeactual time​&gt;1，target会变大，target和挖矿难度成反比，target变大挖矿难度降低</p><p>如果实际时间小于14天，说明出块速度太快，这时应该提高挖矿难度。对应的公式中 a c t u a l   t i m e e x p e c t e d   t i m e &lt; 1 \frac{actual \ time}{expected \ time} &lt; 1 expected timeactual time​&lt;1，target会变小，挖矿难度提高</p><p>为了避免系统中出现某些意外情况，导致系统出现非常大的波动，<strong>每次对目标阈值target的调整最大不能超过4倍，最小不能小于 1 4 \frac{1}{4} 41​</strong>。也就是公式中的 a c t u a l   t i m e e x p e c t e d   t i m e \frac{actual \ time}{expected \ time} expected timeactual time​即使超过4也按4使用，即使小于 1 4 \frac{1}{4} 41​也按 1 4 \frac{1}{4} 41​使用</p><p><strong>如何让所有矿工都同时调整这个挖矿难度呢？</strong></p><p>调整算法是写在比特币的代码里的，如果有恶意节点故意不调，其所产生的区块不会被大多数诚实的节点承认</p><p>在block header中有一个nbits的域，它是对target的编码存储（target为256位，nbits为32位，也就是说block header并未直接存储target），其他节点在进行合法性验证时候会验证nbits域是否合法，不合法则不会接受该区块</p><h4 id="7、BTC-挖矿"><a href="#7、BTC-挖矿" class="headerlink" title="7、BTC-挖矿"></a>7、BTC-挖矿</h4><h5 id="1）、全节点和轻节点"><a href="#1）、全节点和轻节点" class="headerlink" title="1）、全节点和轻节点"></a>1）、全节点和轻节点</h5><p>比特币中有两种节点：全节点和轻节点</p><table><thead><tr><th align="center">全节点</th><th align="center">轻节点</th></tr></thead><tbody><tr><td align="center">一直在线</td><td align="center">不是一直在线</td></tr><tr><td align="center">在本地硬盘上维护完整的区块链信息</td><td align="center">不用保存整个区块链，只要保存每个区块的块头</td></tr><tr><td align="center">在内存中维护UTXO集合，以便快速检验交易的正确性</td><td align="center">不用保存全部交易，只保存与自己相关的交易</td></tr><tr><td align="center">监听比特币网络上的交易信息，验证每个交易的合法性</td><td align="center">无法检验大多数交易的合法性，只能检验与自己相关的那些交易的合法性</td></tr><tr><td align="center">决定哪些交易会被打包到区块里</td><td align="center">无法检测网上发布的区块的正确性</td></tr><tr><td align="center">监听别的矿工挖出来的区块，验证其合法性</td><td align="center">可以验证挖矿的难度</td></tr><tr><td align="center">挖矿：</td><td align="center"></td></tr><tr><td align="center">1. 决定沿着哪条链挖下去</td><td align="center"></td></tr><tr><td align="center">2. 当出现等长分叉，选择哪一个分叉</td><td align="center">只能检测哪个是最长链，不知道哪个是最长合法链</td></tr></tbody></table><p>比特币网络中，大多数节点都是轻节点。如果只是想进行转账，而不是去挖矿的话，只用轻节点就可以了</p><h5 id="2）、挖矿"><a href="#2）、挖矿" class="headerlink" title="2）、挖矿"></a>2）、挖矿</h5><p>在挖矿过程中，如果监听到别人发布了一个区块，这个区块是合法的也是在延伸最长合法链，此时应该停止已有的挖矿，在本地重新组装一个指向最后这个新合法区块的候选区块，重新开始挖矿。因为一方面这个区块中的交易可能和刚刚在挖的那个区块有重复，另一个本质的原因就是<strong>候选区块的块头有指向前一个区块的哈希指针</strong>。因为最新的区块已经变了，这个哈希指针也要跟着改变</p><p><strong>1）这样是不是有些可惜？之前的工作都白费了</strong></p><p>实际上并不可惜。挖矿本身具有无记忆性（memoryless或progress free），前面无论挖多久，对后续继续挖矿没有影响</p><p><strong>2）比特币是怎么保证安全性的？</strong></p><p>一方面是密码学的保证：别人没有自己的私钥，就无法伪造其合法签名，从而无法将其账户上的钱转走（前提是系统中大多数算力掌握在诚实的矿工手中，不会接受没有合法签名的交易）</p><p>另一方面是共识机制：保证了恶意交易不被系统承认</p><h5 id="2）、挖矿设备演化"><a href="#2）、挖矿设备演化" class="headerlink" title="2）、挖矿设备演化"></a>2）、挖矿设备演化</h5><p><strong>第一代挖矿设备：CPU</strong></p><p>最早时候大家都是用普通计算机来挖矿，但如果专门搞一台计算机来挖矿是很不划算的。因为计算机大部分内存是闲置的（挖矿只要用到很少一部分内存），CPU大部分部件是闲置的（计算哈希值的操作只用到通用CPU中的很少一部分指令），硬盘和其它很多资源也都是闲置的。随着挖矿难度提高，用通用计算机上的CPU挖矿很快就无利可图了</p><p><strong>第二代挖矿设备：GPU</strong></p><p>GPU主要用来做通用的大规模并行计算，用来挖矿还是会有不少浪费，而且GPU的噪音很大，其中很多部件还是浪费了（如用于浮点数计算的部件）。近些年GPU价格涨得很快，这不仅是深度学习火热的原因，实际上很多GPU是买来挖矿的。不过现在挖矿的难度已经提高到用GPU也有些划不来了，不会再有那么多人买GPU来挖比特币</p><p><strong>第三代挖矿设备：ASIC芯片</strong></p><p>ASIC即Application Specific Integrated Circuit，这是专门为了挖矿而设计的芯片，没有多余的电路，干不了别的事，它的性价比是最高的，而且为某一种加密货币设计的ASIC芯片只能挖这一种加密货币的矿，除非两个货币用同一个mining puzzle（挖矿难题）</p><p>有些加密货币在刚启动的时候，为了吸引更多的人来挖矿，特意用一个和已有的其它加密货币一样的mining puzzle，这种情况叫merge mining</p><p>研制挖特定加密货币的ASIC芯片需要一定周期，但和研制通用芯片的速度相比已经是非常快的了，比如研制比特币挖矿的ASIC芯片大约用一年的时间。不过加密货币的价格变化是比较剧烈的，曾经就发生过比特币价格在几个月内下跌80%，因为加密货币多变的价格，这些挖矿设备的研制风险也是很大的</p><p>挖矿的竞争越来越激烈，定制的ASIC芯片可能用了几个月就过时了，到时候又要买新的ASIC芯片参与竞争。ASIC矿机上市后的大部分利润也就在前几个月，这个设备的迭代也是很块的</p><p>要买ASIC矿机往往要先交钱预定，过一段时间厂商才会发过来。实际上有些黑心厂商在生产出来以后也不交付给用户，声称还没成产好，然后自己在这段黄金时间用矿机挖矿赚取比特币。不过这其实看得出来，比特币系统中算力突然有了大的提高，那一般是某个大的厂商生产出了新的矿机。所以真正赚钱的未必是挖矿的，而是卖矿机的</p><p>为了让通用计算机也能参与挖矿过程，抗ASIC芯片化，有些加密货币采用alternative mining puzzle（可替代的挖矿难题），以去对抗那些只为了解决特定mining puzzle而设计出来的ASIC矿机</p><h5 id="4）、大型矿池"><a href="#4）、大型矿池" class="headerlink" title="4）、大型矿池"></a>4）、大型矿池</h5><p>单个矿工挖矿的收益是很不稳定的，平均出块时间10分钟是对于比特币系统中的所有矿工而言的。一个矿工用一个矿机挖出矿的时间可能要很久，并且除了挖矿之外还要承担全节点的其它责任</p><p>矿池将很多矿工组织起来，一般的架构就是一个<strong>矿主</strong>（pool manager）全节点去驱动很多矿机，下属矿工只负责计算哈希值，全节点的其他职能只由矿主来承担。有了收益以后再大家一起分配</p><p><img src="/../article_img/Web3/img2-3.png"></p><p><strong>1）矿池收益怎么分配？</strong></p><p>如果矿池中的矿机都是属于同一个机构的，那怎么分配就只是公司内部怎么发工资的问题了</p><p>如果矿机来自不同机构，这时候矿工很可能分布在世界各地，只是都加入了这个矿池。矿工和矿主联系，矿主将要计算的哈希值的任务分配给他，矿工计算好后将结果发给矿主，最终得到出块奖励后一起参与分红</p><p>能否平均分配？挖到区块后奖励平分给所有矿工。这样就完全是吃大锅饭的模式了，有的矿工完全可以不干活或者少干活，所以需要按矿工的贡献大小进行分配，所以这里也需要<strong>工作量证明</strong>，来证明每个矿工所做的工作</p><p>每个矿工自己挖矿之所以收入不稳定，是因为挖矿难度太大了（相比比特币系统的平均出块时间），所以可以考虑矿池将挖矿的难度降下来</p><p>比如原来要求矿工找一个nonce计算的block header的哈希值前面至少有70个0才是合法的区块，现在矿池只要求前面有60个0，这样挖到叫做一个<strong>share</strong>（almost valid block），即这个区块<strong>差不多在一定程度上是符合难度要求的</strong>。矿工挖到这样的区块之后，将其提交给矿主，矿主拿到这些区块并没有什么用，<strong>仅仅是因为目标空间是这个问题的解空间的子集，并且求解两个问题的过程是一样的（都是计算哈希），因此这些区块可以作为证明矿工所做的工作量的证明</strong>。等到某个矿工真正挖到矿，获取出块奖励之后，再按照大家提交的share的多少来进行分配</p><p><strong>2）矿工能否在参与矿池时独吞出块奖励？</strong></p><p>是否会有这样的矿工：挖到share提交给矿主，挖到真正的矿自己发布出去以获得出块奖励？矿工没办法独吞出块奖励，因为每个矿工的任务是由矿主来分配的，矿主负责组装好区块，然后交给矿工去不断尝试nonce和coinbase transaction（铸币交易）中的extra nonce，有可能就是讲它们划分一下，然后分配给不同的矿工去做，要注意<strong>coinbase transaction中的收款人地址是矿主的地址，不是任何一个矿工的地址</strong></p><p>如果矿工把coinbase transaction的地址改成自己的，然后去挖矿，这样提交上去的share矿主是不认可的，所以还是没用的</p><p><strong>3）矿池之间的竞争</strong></p><p>矿池之间是有竞争的，一种竞争方式就是到对方的矿池里去捣乱，派遣一些矿工去加入到对方的矿池里去挖矿，只提交share，但挖到真正的矿就将其丢弃掉，故意不提交。然而如果这个对手矿池仍然获得了出块奖励，这些矿工也能参与分红</p><p><strong>4）大型矿池带来的危害</strong></p><p>如果没有矿池，要发动51%攻击，攻击者要花费大量的硬件成本。有了矿池以后，矿池实际上将算力集中了起来，攻击者未必拥有很多算力，只要吸引矿工将算力集中到自己的矿池就可以</p><p>在2014年的时候GHash矿池的总算力就超过了比特币系统中总算力的一半，引起了恐慌，然后GHash主动减少了算力，以防止大家对比特币失去信心</p><p>如今的矿池的算力还算比较分散，有好几家矿池在竞争，但一个集体的算力完全可以潜伏分散在不同矿池中，等到攻击时再集中起来，矿工要转换矿池是很容易的</p><p>矿池要收取管理费，有的收取出块奖励中的一部分，有的收取赚取的交易费。有恶意的矿池可以在发动攻击之前故意将管理费降得很低，吸引大量矿工进入矿池</p><p><strong>5）51%算力矿池可以发动哪些攻击</strong></p><p><strong>[1]分叉攻击</strong></p><p><img src="/../article_img/Web3/img2-4.png"></p><p>因为算力占了半数以上，并且矿工挖矿任务被分配开并行进行，分叉出来的链的增长速度很快，最终势必成为最长合法链</p><p><strong>[2]封锁交易（Boycott）</strong></p><p><img src="/../article_img/Web3/img2-5.png"></p><p>假如攻击者不喜欢某个账户A，不想让和A有关的所有交易上链，在监听到有其他人发布了含有和A有关交易的区块，立刻发动分叉攻击竞争最长合法链</p><p>即使大部分节点是诚实的，记账权也可能落在有恶意的节点手里，它完全可以不发布某些交易，但在那种情形下总有诚实的节点愿意发布这些交易，所以是没关系的</p><p>但如果攻击者拥有半数以上的算力，依仗自己算力强公开抵制某些交易，只要一出现这些交易，马上进行分叉攻击，因为攻击者有半数以上的算力可以让分叉链变得更长。<strong>这样一来别的矿工也不敢随便打包这些交易了，因为一打包就分叉，自己辛苦挖的矿最后沦为丢弃的区块</strong></p><p><strong>[3]盗币（将其他人账户的钱转走）</strong></p><p>这个是不可能的，不论算力再强，因为没法伪造别人账户的签名（除非获得其私钥），所以没法伪造交易将别人账户上的钱转走。即便是仗着自己算力强，强行将不合法的区块发布到区块链上并沿着这条链继续延伸，诚实的节点依然不会沿着这条不合法的长链延伸，所以还是没用的</p><p><strong>6）矿池出现的优劣</strong></p><p>优点：解决了矿工收入不稳定的问题，减轻了矿工的负担</p><p>缺点：威胁到了区块链系统的安全，使得51%攻击变得容易起来</p><h4 id="8、BTC-比特币脚本"><a href="#8、BTC-比特币脚本" class="headerlink" title="8、BTC-比特币脚本"></a>8、BTC-比特币脚本</h4><h5 id="1）、交易实例"><a href="#1）、交易实例" class="headerlink" title="1）、交易实例"></a>1）、交易实例</h5><p><img src="/../article_img/Web3/img2-6.png"></p><p>比特币系统中使用的脚本语言非常简单，唯一可以访问的内存空间只有栈，所以也被称为基于栈的语言</p><p><strong>交易结构：</strong></p><p><img src="/../article_img/Web3/img2-7.png"></p><p><strong>交易的输入：</strong></p><p><img src="/../article_img/Web3/img2-8.png"></p><p>交易的输入是一个数组，一个交易可以有多个输入，这个例子中输入只有一个。如果一个交易有多个输入，那么每个输入都要说明币的来源，并给出签名</p><p><strong>交易的输出：</strong></p><p><img src="/../article_img/Web3/img2-9.png"></p><p>交易的输出也是一个数组结构，这里例子中有两个输出</p><h5 id="2）、输入输出脚本的执行"><a href="#2）、输入输出脚本的执行" class="headerlink" title="2）、输入输出脚本的执行"></a>2）、输入输出脚本的执行</h5><p><img src="/../article_img/Web3/img2-10.png"></p><p>上图中两个交易分属两个区块，中间隔了两个区块，B-&gt;C的这个交易的比特币的来源是前面A-&gt;B的这个交易。所以<strong>右边这个交易中的相应输入的txid是左边这个交易的id，右边这个交易中的vout指向的是左边这个交易的对应输出</strong></p><p>在早期的比特币系统中，要验证这个交易的合法性，就要把B-&gt;C这个交易的输入脚本，和A-&gt;B这个交易的输出脚本拼在一起执行，看看能不能执行通过</p><p>后来，出于安全因素的考虑，这两个脚本改为分别执行，首先执行输入脚本，如果没有出错，那么再执行输出脚本，如果能顺利执行，并且最后得到非零值（true），那么这个交易就是合法的</p><p>如果一个交易有多个输入，<strong>每个输入脚本都要去找到前面币的来源区块中所对应的输出脚本</strong>，匹配之后来进行验证。全部验证通过后，这个交易才是合法的</p><h5 id="3）、输入输出脚本的几种形式"><a href="#3）、输入输出脚本的几种形式" class="headerlink" title="3）、输入输出脚本的几种形式"></a>3）、输入输出脚本的几种形式</h5><p><strong>1）P2PK（Pay to Public Key）</strong></p><p><img src="/../article_img/Web3/img2-11.png"></p><p>输入脚本中直接给出付款人的签名（<strong>付款人用自己的私钥对输入脚本所在的整个交易的签名</strong>），输出脚本中直接给出收款人（这里的收款人和前面的付款人是同一个人）的公钥，最后的CHECKSIG是检查签名时用的指令</p><p>P2PK是最简单的一种形式，因为Public Key是直接在输出脚本中给出的</p><p><strong>执行情况</strong>：</p><p>一共三条语句，从上往下执行</p><p><img src="/../article_img/Web3/img2-12.png"></p><p>第一条语句，将输入脚本中的签名压入栈</p><p><img src="/../article_img/Web3/img2-13.png"></p><p>第二条语句，将输出脚本中的公钥压入栈</p><p><img src="/../article_img/Web3/img2-14.png"></p><p>第三条语句，弹出栈顶的两个元素，用公钥PubKey检查一下签名Sig是否正确。如果正确，返回True，说明验证通过</p><p><strong>实例：</strong></p><p><img src="/../article_img/Web3/img2-15.png"></p><p><strong>2）P2PKH（Pay to Public Key Hash）</strong></p><p><img src="/../article_img/Web3/img2-16.png"></p><p>P2PKH是最常用的一种形式。输出脚本中没有给出收款人的公钥，给出的是公钥的哈希值，公钥是在输入脚本中给出的。输入脚本既要给出签名也要给出公钥。其它的都是一些操作指令，用来验证签名的正确性</p><p><strong>执行情况</strong>：</p><p>一共七条语句，从上往下执行</p><p><img src="/../article_img/Web3/img2-17.png"></p><p>第一条语句，将输入脚本中的签名压入栈</p><p><img src="/../article_img/Web3/img2-18.png"></p><p>第二条语句，将输入脚本中的公钥压入栈</p><p><img src="/../article_img/Web3/img2-19.png"></p><p>第三条语句，将栈顶元素复制一遍（所以又压入了一次公钥）</p><p><img src="/../article_img/Web3/img2-20.png"></p><p>第四条语句，将栈顶元素取出来取哈希，再将得到的哈希值压入栈，所以栈顶的公钥变成了其哈希值</p><p><img src="/../article_img/Web3/img2-21.png"></p><p>第五条语句，将输出脚本中提供的公钥的哈希值压入栈</p><p><img src="/../article_img/Web3/img2-22.png"></p><p>第六条语句，弹出栈顶的两个元素，比较它们是否相等，防止有人用自己的公钥冒充币的来源的交易的收款人的公钥</p><p><img src="/../article_img/Web3/img2-23.png"></p><p>第七条语句，弹出栈顶的两个元素，用公钥PubKey检查一下签名Sig是否正确。如果正确，返回True，说明验证通过</p><p><strong>实例：</strong></p><p><img src="/../article_img/Web3/img2-24.png"></p><p><strong>3）P2SH（Pay to Script Hash）</strong></p><p><img src="/../article_img/Web3/img2-25.png"></p><p>P2SH是最复杂的一种形式，这种形式下<strong>输出脚本给出的不是收款人的公钥的哈希，而是收款人提供的赎回脚本（Redeem Script）的哈希</strong>。将来要花这个输出脚本的比特币的时候，相应交易的输入脚本要给出赎回脚本的具体内容，同时还要给出让赎回脚本能正确运行所需要的签名</p><p><strong>验证过程：</strong></p><ol><li>验证输入脚本给出的赎回脚本内容，是否和对应输出脚本给出的赎回脚本哈希值相匹配</li><li>反序列化并执行赎回脚本，以验证输入脚本给出的签名是否正确</li></ol><p><strong>赎回脚本的形式：</strong></p><ul><li>P2PK形式</li><li>P2PKH形式</li><li>多重签名形式</li></ul><p><strong>用P2SH实现P2PK：</strong></p><p><img src="/../article_img/Web3/img2-26.png"></p><p>赎回脚本中给出公钥，输入脚本中给出交易签名和序列化后赎回脚本的具体内容，输出脚本中给出了赎回脚本的哈希值</p><p><strong>第一阶段的验证，先验证输入脚本和输出脚本在一起执行的结果</strong></p><p><img src="/../article_img/Web3/img2-27.png"></p><p>第一步，将输入脚本中的交易签名压入栈</p><p><img src="/../article_img/Web3/img2-28.png"></p><p>第二步，将输入脚本中给出的赎回脚本压入栈</p><p><img src="/../article_img/Web3/img2-29.png"></p><p>第三步，弹出栈顶元素取哈希再压栈，也就得到了赎回脚本的哈希（Redeem Script Hash）</p><p><img src="/../article_img/Web3/img2-30.png"></p><p>第四步，将输出脚本中给出的赎回脚本的哈希值压入栈</p><p><img src="/../article_img/Web3/img2-31.png"></p><p>第五步，比较栈顶两个元素是否相等，相当于用之前的输出脚本给出的赎回脚本哈希，验证了输入脚本提供的赎回脚本是否是正确的</p><p><strong>第二阶段的验证，是对输入脚本提供的赎回脚本的验证，首先要将其反序列化，得到可以执行的赎回脚本。然后执行这个赎回脚本</strong></p><p><img src="/../article_img/Web3/img2-32.png"></p><p>第一步，将赎回脚本中的公钥压入栈</p><p><img src="/../article_img/Web3/img2-33.png"></p><p>第二步，验证输入脚本中给出的交易签名的正确性。验证通过就会返回True</p><p><strong>为什么要弄这么复杂？使用P2PK不就可以了吗？为什么要将这部分功能嵌入到赎回脚本？</strong></p><p>针对这个例子，这样做确实复杂了。实际上P2SH在比特币系统中起初并没有，后来通过软分叉加入了这个功能。实际上，该功能的常见应用场景是对多重签名的支持</p><p>在比特币系统中，一个输出可能需要多个签名才能取出钱来。例如，对于公司账户，可能会要求5个合伙人中任意3个的签名才能取走钱，这样便为私钥泄露和丢失提供了一定程度的保护</p><p><strong>多重签名：</strong></p><p><img src="/../article_img/Web3/img2-34.png"></p><p>该功能通过CHECKMULTISIG来实现，输入脚本提供M个签名，输出脚本给出N个公钥和阈值M（N&gt;&#x3D;M），输入脚本只需要提供N个公钥中M个合法签名就能通过验证，且给出的M个签名顺序要和N个公钥中相对顺序一致</p><p>输入脚本的第一行有一个红色的X，是因为比特币中CHECKMULTISIG的实现存在一个bug，执行时会从堆栈上多弹出一个元素。这个bug现在已经无法修改，因为去中心化系统中软件升级代价极大，需要硬分叉修改。所以，实际中采用的方案是在输入脚本往栈中多压入一个无用元素</p><p>如下是一个N&#x3D;3，M&#x3D;2的多重签名脚本执行过程，给出的2个签名顺序和在公钥中相对顺序一致：</p><p><img src="/../article_img/Web3/img2-35.png"></p><p>第一步，将输入脚本中多余的元素压入栈</p><p><img src="/../article_img/Web3/img2-36.png"></p><p>第二步，将输入脚本中两个签名依次压入栈</p><p><img src="/../article_img/Web3/img2-37.png"></p><p>第三步，将输出脚本中阈值M压入栈</p><p><img src="/../article_img/Web3/img2-38.png"></p><p>第四步，将输出脚本中的三个公钥依次压入栈</p><p><img src="/../article_img/Web3/img2-39.png"></p><p>第五步，将输出脚本中的N值压入栈</p><p><img src="/../article_img/Web3/img2-40.png"></p><p>第六步，执行输出脚本中CHECKMULTISIG，是否栈中包含3个公钥对应签名中的2个，如果是，验证通过</p><p>早期的实际应用中，多重签名就是这样写的。但是，在应用中体现出了一些问题。例如，在网上购物时候，某个电商使用多重签名，要求5个合伙人中任意3个人才能将钱取出。这就要求用户在生成，转账交易时候，要给出五个合伙人的转账公钥以及N个M的值。而对于用户来说，需要购物网站公布出来才能知道这些信息。不同电商对于数量要求不一致，会为用户转账交易带来不便之处（因为这些复杂性全暴露给了用户）</p><p>为了解决这一问题，就需要用到P2SH</p><p><strong>用P2SH实现多重签名：</strong></p><p><img src="/../article_img/Web3/img2-41.png"></p><p>本质上是将复杂度从输出脚本转移到输入脚本，此时输出脚本只有三行，原来的复杂度被转入到赎回脚本redeemScript中。输出脚本只需要给出赎回脚本的哈希值即可。赎回脚本里要给出N个公钥还有N和M的值，赎回脚本在输入脚本提供，即收款人提供</p><p>像前面提到的网上购物的例子，收款人是电商，只要在网站上公布赎回脚本的哈希值。用户生成转账交易的时候，把这个哈希值包含在输出脚本里即可。至于电商使用什么样的多重签名规则，对于用户来说是不可见的，用户也无需知道，这样做对用户更加友好</p><p>输入脚本是电商在花掉这笔输出的时候提供的，其中包含序列化后赎回脚本的具体内容、让这个赎回脚本验证通过所需的M个签名。如果电商改变了所采用的多重签名规则，只要改变输入脚本和赎回脚本的内容，然后把新的哈希值公布出去即可，对用户来说，只不过是付款的时候要包含的哈希值发生了变化</p><p><strong>第一阶段的验证，先验证输入脚本和输出脚本在一起执行的结果</strong></p><p><img src="/../article_img/Web3/img2-42.png"></p><p>第一步，将输入脚本中为解决CHECKMULTISIG引入的bug添加的无用元素压入栈</p><p><img src="/../article_img/Web3/img2-43.png"></p><p>第二步，将输入脚本中两个签名依次压入栈</p><p><img src="/../article_img/Web3/img2-44.png"></p><p>第三步，将输入脚本中序列化的赎回脚本作为数据压入栈</p><p><img src="/../article_img/Web3/img2-45.png"></p><p>第四步，弹出栈顶元素取哈希再压栈，也就得到了赎回脚本的哈希</p><p><img src="/../article_img/Web3/img2-46.png"></p><p>第五步，将输出脚本中给出的赎回脚本的哈希值压入栈</p><p><img src="/../article_img/Web3/img2-47.png"></p><p>第六步，判断两个哈希值是否相等</p><p><strong>第二阶段的验证，把赎回脚本展开后执行</strong></p><p><img src="/../article_img/Web3/img2-48.png"></p><p>第一步，先把M压入栈</p><p><img src="/../article_img/Web3/img2-49.png"></p><p>第二步，依次把三个公钥和N压入栈</p><p><img src="/../article_img/Web3/img2-50.png"></p><p>第三步，检查多重签名正确性，3个里面有2个是正确的</p><p><strong>用P2SH实现多重签名实例：</strong></p><p><img src="/../article_img/Web3/img2-51.png"></p><p>现在的多重签名，大多都采用P2SH的形式</p><h5 id="4）、一个特殊的脚本"><a href="#4）、一个特殊的脚本" class="headerlink" title="4）、一个特殊的脚本"></a>4）、一个特殊的脚本</h5><p><img src="/../article_img/Web3/img2-52.png"></p><p>以RETURN开始，后面可以跟任何内容。RETURN操作无条件返回错误，所以包含该操作的脚本永远不可能通过验证。执行到RETURN，后续操作不会再执行。该脚本是证明销毁比特币的一种方法</p><p><strong>为什么要销毁比特币？现在比特币价值很高，销毁是不是很可惜？</strong></p><ol><li>部分小币种（AltCoin）要求销毁部分比特币才能得到该种小币种。例如，销毁一个比特币可以得到1000个小币。即使用这种方法证明付出了一定代价，才能得到小币种</li><li>往区块链中写入内容。我们经常说，区块链是不可篡改的账本，有人就利用该特性往其中添加想要永久保存的内容。例如：股票预测情况的哈希、知识产权保护（知识产权的哈希值）</li></ol><p>有没有觉得第二个应用场景有些熟悉？实际上，之前谈到比特币发行的唯一方法，便是通过铸币交易凭空产生。在铸币交易中，有一个CoinBase域，其中便可以写入任何内容。那么为什么不使用这种方法呢，而且这种方法不需要销毁比特币，可以直接写入</p><p>因为这种方法只有获得记账权的节点才可以写入内容。而上面的方法，可以保证任何一个比特币系统中节点乃至于单纯的用户，都可以向区块链上写入想写入的内容。<strong>发布交易不需要有记账权，发布区块需要有记账权</strong></p><p>任何用户都可以使用这种方法，通过销毁很小一部分比特币，换取向区块链中写入数据的机会</p><p>实际上，很多交易并未销毁比特币，而是支付了交易费</p><p><img src="/../article_img/Web3/img2-53.png"></p><p>上图为一个coinbase transaction，这个交易包含两个输出，第一个输出脚本是正常的Pay to Public Key Hash，输出的金额就是得到的出块奖励+交易费；第二个输出的金额是0，输出脚本开头是RETURN，第二个输出的目的就是为了往区块链里写入一些内容</p><p><img src="/../article_img/Web3/img2-54.png"></p><p>上图是一个普通的转账交易，输出脚本也是以RETURN开头的，这个交易的输入是0.05个比特币，输出金额是0，说明输入金额全部用于支付交易费了。这个交易并没有销毁任何比特币，只不过把输入里的比特币作为交易费转给挖到矿的矿工了</p><p>这种交易永远不会兑现，所以矿工不会将其保存在UTXO中，对全节点比较友好</p><p><strong>实际中的脚本，都需要加上OP前缀，如：CHECKSIG应该为OP_CHECKSIG</strong></p><p><strong>对应课程</strong>：</p><p><a href="https://www.bilibili.com/video/BV1Vt411X7JF">北京大学肖臻老师《区块链技术与应用》公开课</a></p><p>本文转自 <a href="https://blog.csdn.net/qq_40378034/article/details/126085809">https://blog.csdn.net/qq_40378034/article/details/126085809</a>，如有侵权，请联系删除。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Web3</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>&lt;BTC&gt; 密码学原理，数据结构，协议，实现</title>
    <link href="/2025/05/01/BTC_1/"/>
    <url>/2025/05/01/BTC_1/</url>
    
    <content type="html"><![CDATA[<p>写在前面：<br>前段时间把b站上北大肖老师的区块链课程速通了一遍，这里引一下csdn上的优质课程笔记，便于个人后续温习。<br>博客链接：<a href="https://blog.csdn.net/qq_40378034/category_11862943.html">https://blog.csdn.net/qq_40378034/category_11862943.html</a><br>课程链接：<a href="https://www.bilibili.com/video/BV1Vt411X7JF/">https://www.bilibili.com/video/BV1Vt411X7JF/</a></p><span id="more"></span><h4 id="1、BTC-密码学原理"><a href="#1、BTC-密码学原理" class="headerlink" title="1、BTC-密码学原理"></a>1、BTC-密码学原理</h4><p>比特币被称为<strong>加密货币</strong>(crypto-currency)，但其实加密货币是不加密的，区块链上所有交易内容（包括账户地址、转账金额等）都是公开的。比特币中主要用到了密码学中的两个功能：哈希和签名</p><h5 id="1）、hash（哈希）"><a href="#1）、hash（哈希）" class="headerlink" title="1）、hash（哈希）"></a>1）、hash（哈希）</h5><p>在密码学中用的哈希函数被称为cryptographic hash function，其两个重要性质分别为collision resistance（抗碰撞性）和hiding（隐藏性）</p><p><strong>哈希碰撞：</strong></p><p>有两个输入x和y，且x!&#x3D;y，给定一个哈希函数H()，算出来H(x)&#x3D;H(y)，则称为哈希碰撞，即两个不同的输入算出来的哈希值是相等的。一般来说，哈希碰撞是不可避免的，因为输入空间是远远大于输出空间的</p><p><strong>collision resistance：</strong></p><p>collision resistance保证，如果有H(x)!&#x3D;H(y)，必然可以得到x!&#x3D;y。当然这是理想状态，在实际应用中哈希碰撞是客观存在的。给定一个x，很难找到一个y，能够在x!&#x3D;y的前提下，使得H(x)&#x3D;H(y)就认为其是collision resistance的（目前并不存在一个哈希函数可以从数学上证明具有collision resistance的性质）</p><p><strong>collision resistance的用处：</strong></p><p>比如我们有一条信息m，m的哈希值H(m)，H(m)可以作为message digest（信息摘要），用来检测对这个信息的篡改。如果有人修改信息的内容，哈希值就会发生变化，collision resistance的性质保证，找不到另外一个m’，使得H(m)&#x3D;H(m’)，所以没有办法篡改内容而又不被检测出来</p><p><strong>hiding：</strong></p><p>哈希函数的计算过程是单向的、不可逆的。给定一个输入x和哈希函数H()，可以算出x的哈希值H(x)，但没有办法在已知H(x)和H()的情况下，反推出x的值。换句话说哈希值没有泄露有关输入的任何信息</p><p>hiding性质成立的前提是输入空间要足够大，使得蛮力求解的方式是不可行的，而且输出结果分布要比较均匀，各种取值的可能是差不多的</p><p><strong>collision resistance和hiding结合实现digital commitment（数据保证）：</strong></p><p>比如说某个人说他可以预测股市，可以预测第二天哪些股票会涨停。怎么证明这个人预测的是不是准确的？最简单的是提前公布，等待实际结果出现后验证。但实际中，当提前发布预测后，可能会由于预测者本身对股市实际结果造成影响。所以，应该将提前将预测结果写于纸上并密封，交给第三方机构保管，等到实际结果出现后开启密封与实际对比，这就是digital commitment。而第三方机构需要能够使人信服，在实际生活中，很多场景并不存在一个这样的第三方机构，而<strong>区块链技术</strong>正为此提供了一个很好的解决方法</p><p>把预测结果看作x，提前公布H(x)，hiding的性质保证此时不知道预测结果是什么。第二天开盘之后，公布预测结果x，collision resistance的性质保证预测结果不会被篡改。然后根据股市实际情况判断预测是否准确</p><p>实际使用中，为了保证输入足够随机，会在x后拼接一个nonce（随机数），对其整体取哈希</p><p><strong>puzzle friendly（谜题友好）：</strong></p><p>比特币中还需要第三个性质puzzle friendly。该性质要求哈希值计算事先不可预测，仅仅根据输入很难预测出输出。比如需要得到一个哈希值，存在于某一个范围内，只能通过不停运算查找出来</p><p>比特币是区块链，区块链是一个个区块组成的链表，每个区块有一个块头（block header），block header有很多域，其中有一个域是可以设置的随机数nonce，挖矿的过程就是不停地试各种随机数，使得整个block header的哈希值小于等于某个目标阈值，即H(block header)&lt;&#x3D;target</p><p>puzzle friendly性质保证挖矿的过程没有捷径，只能不停地去试大量的nonce才能找到符合要求的解，所以这个过程才可以用来作为<strong>工作量证明</strong>（proof of work，简称POW）。虽然挖矿的过程需要很多工作量才能找到符合要求的nonce，但是一旦有人找到了这个nonce发布出去后，其他人验证nonce是不是符合要求只需要算一次哈希值就可以了。所以说，挖矿很难，验证很容易（difficult to solve,but easy to verify）</p><p>比特币中采用SHA-256哈希函数，满足collision resistance、hiding、puzzle friendly三个性质</p><h5 id="2）、签名"><a href="#2）、签名" class="headerlink" title="2）、签名"></a>2）、签名</h5><p>在第三方中心化系统中，账户开通依赖于第三方。但去中心化的比特币系统中，不能进行申请账户。比特币中，申请账户是用户自己来处理的，即自己创建一个公钥-私钥对（public key,private key）。公私钥对的概念是来源于非对称加密（asymmetric encryption algorithm）</p><p>比特币中，公钥相当于银行账号，别人给你转账只要知道你的公钥就可以了，私钥相当于账户密码，知道了私钥就可以把账户上的钱转走。比特币中，公私钥用于验证签名。比如A要转10个比特币给B，A把交易发布到区块链里。别人怎么知道这个交易确实是A发起的？需要A在发布交易的时候用自己的私钥对交易进行签名，其他人收到交易后，再用A的公钥验证签名的正确性</p><p>比特币中一般是先对一个message取哈希，然后再对这个哈希值签名</p><h4 id="2、BTC-数据结构"><a href="#2、BTC-数据结构" class="headerlink" title="2、BTC-数据结构"></a>2、BTC-数据结构</h4><h5 id="1）、Hash-pointer（哈希指针）"><a href="#1）、Hash-pointer（哈希指针）" class="headerlink" title="1）、Hash pointer（哈希指针）"></a>1）、Hash pointer（哈希指针）</h5><p><img src="/../article_img/Web3/img1-1.png" alt="哈希指针"></p><p>指针存储的是某个结构体在内存中的地址，如上图P是指向结构体的指针</p><p>哈希指针除了要存储结构体的内存地址之外，还要保存结构体的哈希值，如上图H()是指向结构体的哈希指针。哈希指针不光是可以找到结构体的位置，同时还能够通过结构体的哈希值检测出结构体的内容有没有被篡改</p><p>比特币中一个最基本的数据结构就是区块链，区块链是一个个区块组成的链表</p><p><strong>区块链和普通链表的区别：</strong></p><p>一个区别就是用哈希指针代替普通指针（Block chain is a linked list using hash pointer）</p><p><img src="/../article_img/Web3/img1-2.png" alt="区块链结构示意"></p><p>如上图是一个小型的区块链，最前面的区块是系统中产生的第一个区块，叫genesis block（创世纪区块），最后一个区块是最近产生的区块most recent block。每个区块（除创世纪区块）都包含指向前一个区块的哈希指针</p><p>通过这样的数据结构可以实现tamper-evident log（防篡改日志）。篡改一个区块的内容的，后面一个哈希指针就对不上，后面一个哈希指针改了，再后面的也要改。所以只要保存最后一个哈希值，就能检测出对区块链中任何部分的修改</p><p>普通链表可以改变其中一个元素而不会对其他元素产生影响。区块链是牵一发动全身，改变前面任何一个区块后面所有的区块都要跟着改，所以只要保存最后一个哈希值，就能检测出对区块链中任何部分的修改</p><p>有了这个性质，比特币中有些节点只需要保存最近的几千个区块数据就行了，不需要保存整条区块，用到的时候问别人要就行了。有些节点可能是恶意的，所以要验证，算一下别人给我们的区块的哈希值跟我们保存的哈希值是否相等就可以了</p><h5 id="2）、Merkle-Tree（默克尔树）"><a href="#2）、Merkle-Tree（默克尔树）" class="headerlink" title="2）、Merkle Tree（默克尔树）"></a>2）、Merkle Tree（默克尔树）</h5><p><img src="/../article_img/Web3/img1-3.png" alt="Merkle Tree"></p><p>如上图是一棵Merkle Tree，最下面的一层是数据块（data blocks），上面的内部节点都是哈希指针。两两结合取哈希，一层层推上去，最后根节点也取哈希叫做根哈希值（root hash）</p><p>该数据结构的好处在于：只需要记住根哈希值，就可以检测出对树中任何部位的修改</p><p><img src="/../article_img/Web3/img1-4.png"></p><p>如上中，Merkle Tree中最后一层第二个节点的内容发生了改变，则对应的第三层第一个节点中第二个哈希值也会发生改变，以及第二层第一个节点中第一个哈希值也会发生改变，进而根节点中第一个哈希值也会发生改变，从而导致根哈希值也发生了改变</p><p>在比特币中，不同区块通过哈希值指针连接，在同一个区块中的多个交易（数据块），则通过Merkle Tree的形式组织在一起。区块本身分为两部分：block header（块头）和block body（块身），在block header中保存着根哈希值（没有交易的具体信息），block body中保存着交易列表</p><p><strong>Merkle Tree的实际用途：</strong></p><p>Merkle Tree可以用于提供Merkle Proof。比特币中节点分为<strong>轻节点</strong>和<strong>全节点</strong>。全节点保存整个区块的所有内容，而轻节点仅仅保存区块的block header</p><p>当需要向轻节点证明某条交易是否被写入区块链，就需要用到Merkle proof。我们将交易到根节点这一条路径称为Merkle proof，全节点将整个Merkle proof发送给轻节点，轻节点即可根据其算出根哈希值，和自己保存的对比，从而验证该交易是否被写入区块链。只要沿着该路径，所有哈希值都正确，说明内容没有被修改过</p><p><img src="/../article_img/Web3/img1-5.png"></p><p>如上图，轻节点想知道标为黄色的交易是否被包含在这棵Merkle Tree里面。轻节点没有保存交易列表，没有这棵Merkle Tree的具体内容，只有一个根哈希值，因为轻节点只保存区块头信息</p><p>轻节点向某个全节点发出请求，请求一个能够证明这个交易被包含在Merkle Tree里面的Merkle proof。全节点收到请求后，需要把标为红色的哈希值发给轻节点。有了这些哈希值之后，轻节点可以在本地计算出标为绿色的哈希值</p><p><img src="/../article_img/Web3/img1-6.png"></p><p>轻节点首先算出标为黄色的交易的哈希值，然后和全节点提供的右边标为红色的哈希值拼接起来，可以算出上层节点里标为绿色的哈希值</p><p><img src="/../article_img/Web3/img1-7.png"></p><p>然后再和左边红色的哈希值拼接起来，可以算出上层节点里标为绿色的哈希值</p><p><img src="/../article_img/Web3/img1-8.png"></p><p>然后再和右边红色的哈希值拼接起来，就可以算出整个Merkle Tree的根哈希值。轻节点把这个根哈希值和block header中的根哈希值比较一下就能知道标为黄色的交易是否被包含在这棵Merkle Tree里面</p><h4 id="3、BTC-协议"><a href="#3、BTC-协议" class="headerlink" title="3、BTC-协议"></a>3、BTC-协议</h4><h5 id="1）、数字货币中经常出现的问题"><a href="#1）、数字货币中经常出现的问题" class="headerlink" title="1）、数字货币中经常出现的问题"></a>1）、数字货币中经常出现的问题</h5><p>比如央行发行的数字货币都有央行的私钥签名，公钥是公开的，用了密码学的非对称加密体系。买东西的时候把数字货币给别人，别人用央行的公钥验证一下，证明这确实是央行发行的。那么面临什么问题呢？</p><p><strong>double spending attack（双花攻击）：</strong></p><p>数字货币本身是带有签名的数据文件，可以进行复制。即对用户来说，可以将同一货币花两次</p><p>现在改进一下，还是央行发行数字货币，每个数字货币上给个编号，央行来维护数据库，就是一个大的表，上面记录下每个编号的数字货币在谁手里。每次交易都必须向央行报备。这个方案是中心化的方案，每一次交易必须要央行确认才能证明其合法性</p><h5 id="2）、去中心化货币要解决的问题"><a href="#2）、去中心化货币要解决的问题" class="headerlink" title="2）、去中心化货币要解决的问题"></a>2）、去中心化货币要解决的问题</h5><p><strong>1）数字货币的发行由谁执行？发行多少？什么时候发行？</strong></p><p>在传统中心化货币体系中，这些问题我们可以交给第三方机构（如：央行）。当引入去中心化思想后，系统中节点平等，交易不通过第三方，那么货币发行权的分配必然是一个需要解决的问题</p><p>在比特币中由挖矿来决定货币发行权和发行量</p><p><strong>2）如何验证交易是否有效？如何防止双花攻击？</strong></p><p>在传统中心化体系中，该问题的解决由第三方机构来完成。而剔除这一机构后，交易双方如何能够验证交易的有效性？如何防止系统中恶意用户作恶获取收益？这也是去中心化交易系统需要解决的问题</p><p>该问题的解决依赖于系统中维护的一个数据结构，记录货币的使用情况（是否被花过？被谁花过？）。该数据结构由系统中全体用户共同维护，保证了交易的有效性。该数据结构就是区块链</p><h5 id="3）、比特币中如何验证交易是否有效？如何防止双花攻击？"><a href="#3）、比特币中如何验证交易是否有效？如何防止双花攻击？" class="headerlink" title="3）、比特币中如何验证交易是否有效？如何防止双花攻击？"></a>3）、比特币中如何验证交易是否有效？如何防止双花攻击？</h5><p><img src="/../article_img/Web3/img1-9.png"></p><p>如上图，假定A获得发行货币的权利，称为<strong>铸币权</strong>，发行了10个比特币（该交易称为铸币交易）。A将10个比特币转给了B（5个）和C（5个），A对该交易进行签名，同时该交易需要说明所花掉10个比特币来源（来自铸币交易）</p><p><strong>比特币中每个交易都包含了输入和输出两部分，输入部分要说明币的来源，输出部分要给出收款人的公钥的哈希</strong>。比如A要转给B钱就要说明B的公钥的哈希是什么</p><p>之后，B将自己的5个比特币转给C（2个）和D（3个），该交易需要B的签名，该交易需要说明所花掉的5个比特币来自于第二个交易中</p><p>然后，C将自己所拥有的全部7个比特币都转给E，并对该交易签名，可以发现该交易中C的比特币来源于两个交易中</p><p><strong>如何防止双花攻击？</strong></p><p>需要注意的是，<strong>这里面有两种哈希指针。第一种为指向前面的区块，使得各个区块形成链，第二种则是为了说明比特币的来源</strong>。说明比特币的来源并非凭空捏造，可以防止双花攻击</p><p><img src="/../article_img/Web3/img1-10.png"></p><p>比如，B已经把全部的比特币转给C和D，B又要转给F 5个比特币，说明的币的来源来自于第二个交易中。别的节点收到这个交易后，从这个新的区块往币的来源回溯一下，到第三个交易时发现这5个比特币已经在这个交易（B将自己的5个比特币转给C 2个和D 3个）中被花出去了，就说明新的这个交易是不合法的，不会把它接受到区块链里</p><p><strong>如何验证交易是否有效？</strong></p><p>在进行交易时，需要付款人的签名和收款人的地址。在比特币中，该收款的地址即为收款人的公钥的哈希，可以将其视为银行账户，根据此进行转账交易（虽然公钥可以公开，但实际中更多公开的是公钥的哈希）</p><p>在A给B转账的交易中，收款方B需要知道付款方A的公钥，从而验证A的签名是否有效，即A需要提供自己的公钥。区块链上每个节点是独立验证的，其他节点都需要知道付款方A公钥，A通过自己的私钥进行签名，其他节点通过A的公钥来验签，从而验证交易的合法性</p><p><strong>比特币交易中输入部分除了要说明币的来源，还要说明付款人的公钥，而且付款人的公钥需要和币的来源里的公钥的哈希对得上</strong>。A给B转账的时候提供的公钥需要和铸币交易中公钥的哈希对的上，这样就防止了恶意节点伪造A的公钥来偷走A的比特币</p><p>在比特币中，通过执行脚本实现上述验证过程。将当前交易输入脚本与前一个交易输出脚本（说明币的来源的交易）拼接执行，如果可以正确执行，说明交易合法</p><p>上图中一个区块仅含有一个交易，实际中一个区块中包含多个交易，交易通过Merkle Tree组织起来，在区块中存储</p><h5 id="4）、比特币区块信息"><a href="#4）、比特币区块信息" class="headerlink" title="4）、比特币区块信息"></a>4）、比特币区块信息</h5><p>每个区块包含两部分：block header（块头）和block body（块身）</p><p>block header里包含区块宏观信息</p><table><thead><tr><th align="center">block header</th></tr></thead><tbody><tr><td align="center">version（使用比特币哪个版本的协议）</td></tr><tr><td align="center">hash of previous block header（指向前一个区块指针）</td></tr><tr><td align="center">merkle root hash（Merkle Tree的根哈希值）</td></tr><tr><td align="center">target（挖矿难度目标阈值）</td></tr><tr><td align="center">nonce（随机数）</td></tr></tbody></table><ol><li>挖矿求解问题：H（block header）&lt;&#x3D;target</li><li>Hash of previous block header只计算区块块头部分的哈希（Merkle root hash保证了block body内容不被篡改，所以只需要计算block header即可保证整个区块内容不会被篡改）</li><li>区块链系统中，轻节点（只存储区块block header信息）只利用区块链，但并不参与区块链系统维护和构造</li></ol><h5 id="5）、分布式共识"><a href="#5）、分布式共识" class="headerlink" title="5）、分布式共识"></a>5）、分布式共识</h5><p>可否各个节点独立完成区块链构建？</p><p>很明显不行，各个节点独立打包交易，形成区块链，必然无法避免区块链内容不一致。从分布式系统角度来说，<strong>账本内容需要取得分布式共识</strong>（distribute consensus），从而保证区块链内容在不同节点上的一致性</p><p>根据FLP不可能结论，在一个异步系统中，网络时延无上限，即使只有一个成员是有问题的，也不可能达成共识</p><p>根据CAP定理（Consistency一致性、Availability可靠性、Partition tolerance分区容错性），任何一个分布式系统中，最多只能满足其中两个性质</p><h5 id="6）、比特币中的共识协议"><a href="#6）、比特币中的共识协议" class="headerlink" title="6）、比特币中的共识协议"></a>6）、比特币中的共识协议</h5><p><strong>比特币中共识协议要解决的问题是有些节点可能是有恶意的。假设系统中大多数节点是好的，有恶意的占小部分，在这种情况下如何设计共识协议？</strong></p><p>想法一：直接投票</p><p>某个节点打包交易到区块，将其发给其他节点，其他节点检查该候选区块，检查若正确投赞成票，若票数过半数，加入区块链</p><p>存在的问题：</p><ol><li>恶意节点不断打包不合法区块，导致一直无法达成共识，时间全花在投票上</li><li>无强迫投票手段，某些节点不投票（行政不作为）</li><li>网络延迟事先未知，投票需要等多久？效率上会产生问题</li><li>更大的一个问题：membership。如果这个区块链对加入成员有要求（比如联盟链），可以基于投票。但比特币系统，任何人都可以加入，且创建账户及其简单，只需要本地产生公私钥对即可。只有转账（交易）的时候，比特币系统才能知道该账户的存在。这样，黑客可以使用计算机专门生成大量公私钥对，当其产生大量公私钥对超过系统中一半数目时，就可以获得支配地位（<strong>女巫攻击</strong>）。所以，这种简单的投票方案也是不可行的。</li></ol><p><strong>比特币中的共识协议：</strong></p><p>比特币系统中采用了很巧妙的方案解决这个问题。虽然仍然是投票，但并非简单的根据账户数目，而是依据计算力进行投票</p><p>比特币中，每个节点都可以自行组装一个候选区块，而后尝试各种nonce值，这就是<strong>挖矿</strong></p><p>当某个节点找到了符合要求的nonce（H（block header）&lt;&#x3D;target），就获得了<strong>记账权</strong>，从而可以将区块发布到系统中。记账权就是往比特币这个去中心化的账本里写入下一个区块的权力，只有掌握的记账权的节点才能写入下一个区块</p><p>其他节点收到区块后，验证区块合法性，比如：</p><ol><li>验证H（block header）&lt;&#x3D;target</li><li>验证block body中每个交易都是合法的，要有合法的签名并以前没有被花过</li></ol><p>如果系统中绝大多数节点验证通过，则接收该区块为最新的区块并加入到区块链中</p><p><strong>最长合法链（longest valid chain）：</strong></p><p><img src="/../article_img/Web3/img1-11.png"></p><p>区块链正常运行场景下可能会产生分叉。当两个节点同时获得记账权时，会有两个等长的合法链。在缺省情况下，节点接收最先收到的区块，该节点会沿着该区块继续延续。但随着时间延续，必然有一个链胜出，由此保证了区块链的一致性（被扔掉的区块称为孤儿区块orphan block）</p><p><img src="/../article_img/Web3/img1-12.png"></p><p>如上图，发生分叉的情况下暂时保存分叉情况，但区块链只承认最长合法链，随着时间推移，必然存在某一条链变成最长合法链</p><p><strong>分叉攻击（forking attack，通过在中间插入区块来回滚已发生的区块）：</strong></p><p><img src="/../article_img/Web3/img1-13.png"></p><p>如上图，A用户对上面的A转账给B的记录回滚，从而非法获取利益。在两条链上发现交易都合法。这是一个典型的双花攻击。A给B转账后，用分叉攻击将钱又转回来，覆盖掉原来的记录</p><p>在比特币中，这种情况实际上很难发生。因为大多数矿工认可的是最长的合法链，会沿着上面的链继续挖下去。而A这个攻击者要想回退记录，就必须使得下面的链变得比上面的链还长。理论上来说，攻击者需要达到整个系统中51%的计算力，才能使得这种攻击成功</p><h5 id="7）、比特币激励机制"><a href="#7）、比特币激励机制" class="headerlink" title="7）、比特币激励机制"></a>7）、比特币激励机制</h5><p>为什么系统中节点要竞争记账权？需要提供算力和电力成本，节点为什么要去做？</p><p>比特币系统设计之初就考虑到了这个问题，于是引入了激励机制。比特币通过设置<strong>出块奖励</strong>（block reward）来解决该问题，一个获得合法区块的节点可以在区块中加入一个特殊交易：<strong>铸币交易</strong>（coinbase transaction）。事实上，这种方式也是唯一一个产生新比特币的途径</p><p>比特币系统设计规定，起初每个区块可以获得50个比特币，但之后每隔21万个区块奖励减半</p><p>区块中保存交易记录，那么，会不会存在节点只想发布区块而不想打包交易？中本聪在设计系统时引入了<strong>交易费</strong>。在一个区块中，其输入大于输出，差值就是给区块所属节点的手续费</p><h4 id="4、BTC-实现"><a href="#4、BTC-实现" class="headerlink" title="4、BTC-实现"></a>4、BTC-实现</h4><h5 id="1）、UTXO"><a href="#1）、UTXO" class="headerlink" title="1）、UTXO"></a>1）、UTXO</h5><p>区块链是一个去中心化的账本，比特币采用了<strong>基于交易的账本模式</strong>（transaction-based ledger）。每个区块里记录的是交易信息，有转账交易，有铸币交易，但是系统中没有显示记录每个账户包含多少个比特币，实际上其需要通过交易记录进行推算。在比特币中，全节点需要维护一个名为<strong>UTXO</strong>（Unspent Transaction Output，尚未被花掉的交易输出）的数据结构</p><p><img src="/../article_img/Web3/img1-14.png"></p><p>如上图，A转给B 5个比特币，转给C 3个比特币，B将5个比特币花掉，则该交易记录不保存在UTXO中，C没有花掉，则该交易记录保存在UTXO中</p><p>UTXO集合中每个元素要给出产生这个输出的交易的哈希值，以及其在交易中是第几个输出。通过这两个信息就可以定位到UTXO中的输出</p><p><strong>为什么要维护这样一个数据结构？</strong></p><p>为了防范double spending（双花攻击），判断一个交易是否合法，要查一下想要花掉的比特币是否在该集合中，只有在集合中才是合法的。如果想要花掉的比特币不在UTXO中，那么说明这个比特币要么根本不存在，要么已经被花过。所以，全节点需要在内存中维护一个UTXO，以便快速检测double spending</p><p>每个交易会消耗输出，但也会产生新的输出</p><p><img src="/../article_img/Web3/img1-15.png"></p><p>如上图，A转给B 5个比特币，之后B将其转给D，则UTXO中会删掉A-&gt;B这一交易记录，同时会添加B-&gt;D这一交易记录</p><p>加入有人收到比特币转账，但一直不花，那么这个信息会一直保存在UTXO中。这种情况可能是该用户不想花这些比特币（比如中本聪），也有可能是忘记了私钥导致无法花掉。所以，UTXO是逐渐增大的，但该数据目前来说，一个普通的服务器内存中是可以完全保存这些数据的</p><h5 id="2）、Transaction-fee（交易费）"><a href="#2）、Transaction-fee（交易费）" class="headerlink" title="2）、Transaction fee（交易费）"></a>2）、Transaction fee（交易费）</h5><p>每个交易可以有多个输入，也可以有多个输出，但输入之和要等于输出之和（total inputs &#x3D; total outputs）。存在一些交易的total inputs略大于total outputs，这部分差额作为<strong>交易费</strong>（Transaction fee）给获得记账权的节点</p><p>区块中保存交易记录，那么，会不会存在节点只想发布区块而不想打包交易呢？因此比特币设计了交易费，对于获得记账权节点来说，除了出块奖励之外，还可以得到打包交易的交易费。但目前来说，交易费远远小于出块奖励。等到未来出块奖励变少，可能区块链的维护便主要依赖于交易费了</p><p>比特币中，每隔21万个区块出块奖励减半。比特币中平均出块时间是10分钟，基本上出块奖励每4年（ 21 万 × 10 分钟 60 分钟 × 24 小时 × 365 天 ≈ 4 年 \frac{21万 \times 10分钟}{60分钟 \times 24小时 \times 365天} ≈ 4年 60分钟×24小时×365天21万×10分钟​≈4年）减半</p><p>比特币是基于交易的模式，与之对应还有一种基于账户的模式（比如以太坊）。基于账户的模式要求系统中显示记录账户余额。也就是说，可以直接查询当前账户余额。比特币这种基于交易的模式隐私性较好，但也要付出一定代价，在进行交易时，因为没有账户这一概念，无法知道账户剩余多少比特币，所以就必须说明币的来源。而基于账户的模式则避免了这种缺陷，转账交易就是对一个或多个账户余额的数字减和另一个或多个账户余额的数字加</p><h5 id="3）、比特币中具体的区块信息"><a href="#3）、比特币中具体的区块信息" class="headerlink" title="3）、比特币中具体的区块信息"></a>3）、比特币中具体的区块信息</h5><p><img src="/../article_img/Web3/img1-16.png"></p><p>如上图是一个区块的信息，字段具体含义如下：</p><table><thead><tr><th align="center">Summary</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">Number of Transactions</td><td align="center">总交易数</td></tr><tr><td align="center">Output Total</td><td align="center">总输出</td></tr><tr><td align="center">Transaction Fees</td><td align="center">总交易费（所有交易的交易费之和）</td></tr><tr><td align="center">Height</td><td align="center">区块的序号</td></tr><tr><td align="center">Timestamp</td><td align="center">区块的时间戳</td></tr><tr><td align="center">Difficulty</td><td align="center">挖矿难度，每隔2016个区块要调整挖矿难度保持出块时间在10分钟左右</td></tr><tr><td align="center">Nonce</td><td align="center">挖矿时尝试的符合要求的随机数</td></tr><tr><td align="center">Block Reward</td><td align="center">出块奖励</td></tr></tbody></table><table><thead><tr><th align="center">Hashes</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">Hash</td><td align="center">区块块头的哈希值</td></tr><tr><td align="center">Previous Block</td><td align="center">前一个区块块头的哈希值</td></tr><tr><td align="center">Merkle Root</td><td align="center">Merkle Tree根哈希值</td></tr></tbody></table><p>如上图，可以看到，区块块头的哈希值与前一个区块块头的哈希值都是以一长串0开头的，挖矿本身就是尝试各种nonce，使得产生的区块块头的哈希值小于等于目标阈值。该目标阈值表示成16进制就是前面含有一长串的0，所以凡是符合难度要求的区块的块头的哈希值算出来前面都含有一长串的0</p><p><img src="/../article_img/Web3/img1-17.png"></p><p>上图是block header的代码中实现的数据结构，可以看到nonce是一个32位的无符号整型数据，在挖矿的时候要不断调整nonce，但是nonce的取值最多有 2 32 2^{32} 232种。由于近年来，挖矿人员越来越多，挖矿难度已经调整的比较大了，而 2 32 2^{32} 232这一搜索空间太小，所以仅调整nonce很大可能找不到正确的结果</p><p><strong>还有哪些域可以调整呢？</strong></p><p><img src="/../article_img/Web3/img1-18.png"></p><p>仅仅调整nonce是不够的，所以这里可以通过修改Merkle Tree的根哈希值来进行调整。这个怎么能修改呢？</p><p><strong>铸币交易（coinbase transaction）：</strong></p><p>每个发布的区块里有一个特殊的铸币交易，这也是BTC系统中产生新比特币的唯一方式</p><p><img src="/../article_img/Web3/img1-19.png"></p><p>铸币交易中有一个CoinBase域，可以写入任何内容。只要改变了CoinBase域写入内容，就可以改变Merkle Tree的根哈希值</p><p><img src="/../article_img/Web3/img1-20.png"></p><p>如上图，左下角交易为coinbase transaction，该交易发生改变会逐级向上传递，最终导致Merkle Tree的根哈希值发生改变</p><p>在实际的挖矿中包含两层循环。外层循环调整coinbase域（可以规定只将其中前x个字节作为另一个nonce），算出block header中根哈希值后，内层循环再调整header里的nonce</p><p><strong>普通转账交易：</strong></p><p><img src="/../article_img/Web3/img1-21.png"></p><p>如果将输入脚本和输出脚本拼接起来可以顺利执行不出现错误，则说明交易合法</p><h5 id="4）、挖矿过程的概率分析"><a href="#4）、挖矿过程的概率分析" class="headerlink" title="4）、挖矿过程的概率分析"></a>4）、挖矿过程的概率分析</h5><p>挖矿本质上是不断地尝试各种nonce，来求解这样一个puzzle。每次尝试nonce可以看做是一次<strong>Bernoulli trial</strong>（伯努利试验：a random experiment with binary outcome）。最典型的伯努利试验就是投掷硬币，正面和反面朝上概率为p和1-p。在挖矿过程中，一次伯努利试验成功的概率极小，失败的概率极大。挖矿就是多次进行伯努利试验，且每次随机。这些伯努利试验便构成了a sequence of independent Bernoulli trials（一系列独立的伯努利试验）。根据概率论相关知识，伯努利试验本身具有无记忆性。也就是说，无论之前做多少大量试验，对后续继续试验没有任何影响</p><p><img src="/../article_img/Web3/img1-22.png"></p><p>对于挖矿来说，就是多次伯努利试验尝试nonce，最终找到一个符合要求的nonce。在这种情况下，可以采用<strong>Poisson process</strong>（泊松分布）进行近似，由此通过概率论可以推断出，系统出块时间服从指数分布</p><p>通过定期调整挖矿难度使得币平均出块时间维持在10分钟左右</p><p>指数分布本身也具有无记忆性。也就是说，对整个系统而言，已经过去10分钟，仍然没有人挖到区块，那么平均仍然还需要等10分钟。也就是说，将来要挖多久和已经挖多久无关</p><p>虽然过去的工作可能都会白做，但实际上这才是挖矿公平性的保障。对算力有优势的矿工来说，其之前所做大量工作仍有可能会白费</p><h5 id="5）、比特币总量"><a href="#5）、比特币总量" class="headerlink" title="5）、比特币总量"></a>5）、比特币总量</h5><p>出块奖励是系统中产生新比特币的唯一途径，每隔21万个区块（4年）出块奖励减半<br>21 万​ × ​ 50 + 21 万​ × ​ 25 + 21 万​ × ​ 12.5 + … … &#x3D; 21 万​ × ​ 50 ​ × ​ ( 1 + 1 2 + 1 4 + … … ) &#x3D; 21 万​ × ​ 50 ​ × ​ 2 &#x3D; 2100 万 21万 ​\times​ 50 + 21万 ​\times​ 25 + 21万 ​\times​ 12.5 + ……\\ &#x3D;21万 ​\times​ 50 ​\times​ ( 1 + \frac{1}{2} + \frac{1}{4} + ……)\\ &#x3D;21万 ​\times​ 50 ​\times​ 2\\ &#x3D;2100万 21万​×​50+21万​×​25+21万​×​12.5+……=21万​×​50​×​(1+21​+41​+……)=21万​×​50​×​2=2100万<br>系统中已经挖出和未挖出的比特币总量是2100万个</p><p>挖矿操作并不是在解决数学难题，而是单纯的算力比拼。也就是说，挖矿操作并没有实际意义，但挖矿的过程对于维护比特币系统的安全性是至关重要的（BitCoin is secured by mining）</p><p><strong>比特币越来越难被挖到，且出块奖励越来越少，是否说明其未来挖矿的动力将越来越低呢？</strong></p><p>实际上恰恰相反。在早期比特币很容易挖到的时候，比特币并不被人们所看好，后来比特币估值上涨，吸引其他人参与挖矿，又进一步促进了比特币价值上涨，进而又吸引更多人参与进来</p><p>当出块奖励趋于0时，则整个系统将依赖于交易费运行，这时交易费将成为维护比特币系统运行的重要保障</p><h5 id="6）、比特币安全性分析"><a href="#6）、比特币安全性分析" class="headerlink" title="6）、比特币安全性分析"></a>6）、比特币安全性分析</h5><p>假设大多数算力掌握在诚实的矿工手中，能否保证写入区块链的交易都是合法的？</p><p>需要注意的是，算力低的矿工并非完全不能获得记账权，仅仅是概率上较低的问题。但实际上，即使拥有少量算力的恶意节点，也有一定概率获得某个区块的记账权</p><p><strong>1）能否偷币（恶意节点能不能将其他账户上比特币转给自己）？</strong></p><p>不能。因为转账交易需要签名，恶意节点无法伪造他人签名</p><p><img src="/../article_img/Web3/img1-23.png"></p><p>如果恶意节点获得记账权并硬往区块中写入该交易，大多数用户会认为其是一个非法区块，大多数算力将不认可该区块，从而沿着其他路径挖矿，随着时间推移，拥有大多数算力的诚实的节点将会仍然沿着原来区块挖矿，从而形成一条最长合法链，该区块变成孤儿区块</p><p>对于攻击者来说，不仅不能偷到其他人的比特币，而且得不到出块奖励，还浪费了挖矿花费的电费等成本</p><p><strong>2）能否将已经花过的币再花一遍（double spending）？</strong></p><p><img src="/../article_img/Web3/img1-24.png"></p><p>M发布一个转账交易给A，已经写到区块链里了。M获得了记账权，把钱再转回给自己，如上图的方式，很明显为一个非法区块，不会被其他节点承认</p><p><img src="/../article_img/Web3/img1-25.png"></p><p>所以，M只能通过上图的方式将M转账给B的记录回滚掉（分叉攻击）。如上图，此时就有了两条等长合法链，取决于其他节点沿着哪条链往下扩展，最后有一个会胜出，另一个就作废</p><p>需要注意的是，区块插入到哪一个区块之后是在刚开始挖矿的时候就要决定的（而不是在获得记账权之后），因为区块头里要填上前一个区块块头的哈希值</p><p><img src="/../article_img/Web3/img1-26.png"></p><p>如果M转给A的钱产生了某种不可逆的外部效果，下面再把交易回滚，那么M就可以从中不当获益。比如说网上购物，这个网站接受比特币支付，M购买一些商品，M发起交易把账转给这个网站。这个网站监听到交易写入到区块链里了，以为支付成功了，就把商品给了M。M拿到商品后，又发起一个交易，把钱转给自己，把下面这条链扩展成最长合法链，上面的区块就作废了。M这样攻击既得到了商品又把花出去的钱收回来了</p><p><strong>如何防范这种攻击？</strong></p><p><img src="/../article_img/Web3/img1-27.png"></p><p>如果M转账给A的交易不是在最后一个区块，而是后面又跟了几个区块，那么这种攻击的难度就大大增加。M要想回滚交易，要想办法让下面这条链成为最长合法链。诚实的节点不会沿着下面的区块往下扩展，相当于是恶意节点挖下面的链，其他节点挖上面的链的算力比拼。如果大部分算力是掌握在诚实的节点，则最终上面链会胜出，而恶意节点的链会不被认可，从而导致投入成本白费</p><p><img src="/../article_img/Web3/img1-28.png"></p><p>所以，一种简单防范就是<strong>多等几个确认区块</strong>（confirmation）。比特币协议中，缺省需要等6个确认区块，此时才认为该记录是不可篡改的。平均出块时间10分钟，6个确认区块就需要1小时，等待时间还是相对较长的</p><p><img src="/../article_img/Web3/img1-29.png"></p><p><strong>zero confirmation</strong>是指交易刚发布出去，还没有写入区块链中的时候，就认为交易已经不可篡改了</p><p>zero confirmation实际使用的比较广泛，有两个原因：</p><ul><li>两个交易有冲突，节点接收最先听到的交易。上面分叉攻击的例子中M-&gt;A后的M-&gt;M’大多诚实节点会将其拒绝</li><li>购物网站委托全节点监听区块链，从支付成功到发货其实还有比较长的处理时间，如果发现这个交易最后没有写到最长合法链，购物网站可以选择取消发货</li></ul><p><strong>3）能否故意不包含某些合法交易？</strong></p><p>这个是没关系的，因为比特币协议也没有规定获得记账权的节点必须发布哪些交易，而且没有写进这个区块也可以写进下一个区块，总有诚实的节点愿意发布这些交易。而且比特币系统在正常工作时候也会出现某些交易被滞后发布的情况，可能就是一段时间内的交易太多了，毕竟一个区块不能超过1M</p><p><strong>4）selfish mining</strong></p><p>正常情况下节点挖到一个区块就立即发布，这是为了得到出块奖励和收取交易费。<strong>selfish mining就是挖到的区块都留着</strong>，这样的动机是，比如在前面的分叉攻击中，一直等到6个confirmation过了，再一口气把算好的很长的分叉发布出去，替换掉最长合法链</p><p>实际上这样做的难度还是很大，因为这个恶意节点的算力要超过那些诚实的算力才可能在一定时间后比它长。另外就是大多诚实的节点已经扩展那个M-&gt;A的交易所在的区块了，这个恶意节点的同伙节点也要很多才行</p><p>即便不是为了做什么攻击，就是为了赚取出块奖励和收取交易费，selfish mining也有好处：能够减少自己的竞争对手</p><p><img src="/../article_img/Web3/img1-30.png"></p><p>如上图，大家都在从A挖下一个区块，然后某个节点挖出了B先藏着，这时候别人还在从A挖下一个区块，然后这个节点紧接着挖出了C，将B和C一起发布出去，这样就少了一个节点C的竞争</p><p>或者是继续往下挖，当听到有人发布D时，将B和C一起发布出去，这样最长合法链是沿着ABC的，别人挖出的D就作废了</p><p>但这样会带来不小的风险，假设在挖出C之前就有人挖出D并且发布了，这时候就只能赶紧把B发布出去，很可能连这个记账权都竞争不到了</p><p>在这个动机下，selfish mining的回报并非很高，只是让别人做了无用功，自己少了些竞争，但风险却是挺大的</p><p><strong>对应课程</strong>：</p><p><a href="https://www.bilibili.com/video/BV1Vt411X7JF">北京大学肖臻老师《区块链技术与应用》公开课</a></p><p>本文转自 <a href="https://blog.csdn.net/qq_40378034/article/details/125961174">https://blog.csdn.net/qq_40378034/article/details/125961174</a>，如有侵权，请联系删除。</p>]]></content>
    
    
    
    <tags>
      
      <tag>Web3</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RLHF(三)：基于TRL的GrpoTrainer详解</title>
    <link href="/2025/04/19/RLHF(%E4%B8%89)/"/>
    <url>/2025/04/19/RLHF(%E4%B8%89)/</url>
    
    <content type="html"><![CDATA[<p>写在前面：目前主流的LLM post-training框架主要有<a href="https://github.com/huggingface/trl">trl</a>, <a href="https://github.com/OpenRLHF/OpenRLHF">OpenRLHF</a>, <a href="https://github.com/volcengine/verl">verl</a>。后两者集成度较高，适合对LLM零代码训练，而trl灵活性较强，这里主要对GRPO Trainer的训练流程进行梳理</p><span id="more"></span><h3 id="GRPOTrainer类"><a href="#GRPOTrainer类" class="headerlink" title="GRPOTrainer类"></a>GRPOTrainer类</h3><p>它继承了transformers.Trainer，并重写或拓展了若干方法，包括：<br><strong><strong>init</strong></strong><br>作用：初始化模型、参考模型（ref_model）、奖励模型（reward_funcs）等，并作一些超参数设置（如 num_generations, beta 等）。</p><ul><li>model: 加载策略模型, 可以是字符串（模型ID或路径）或预训练模型对象。仅支持因果语言模型</li><li>reward_funcs: 加载奖励函数，可以是预训练模型(仅支持<code>SequenceClassification</code>模型);用户自定义Python函数；或者是一个列表，意味着多种奖励函数一起用</li><li>args: GRPOConfig对象，包含训练的所有参数</li><li>train_dataset: 训练数据集，必须包含名为’prompt’的列，可以是Dataset或IterableDataset</li><li>eval_dataset: 评估数据集</li><li>processing_class: 数据处理器类，用于对训练和评估数据进行预处理 typing.Optional[transformers.tokenization_utils_base.PreTrainedTokenizerBase] &#x3D; None</li><li>reward_processing_class: 奖励函数对应的分词器，支持单个分词器或多个分词器的列表</li><li>callback: 自定义训练回调列表，可扩展或覆盖默认的训练过程 typing.Optional[list[transformers.trainer_callback.TrainerCallback]] &#x3D; None</li><li>optimizer</li><li>peft_config</li></ul><p>补充说明：</p><ol><li>processing_class 填充侧必须设置为 “left”。如果为 None，则使用 from_pretrained 从模型名称加载处理类。</li><li>reward_processing_class: 可选，默认为None。在自定义时，必须与 reward_funcs 中奖励函数的顺序和长度匹配。</li></ol><p><strong>_prepare_inputs</strong><br>作用：在训练循环中，每一个 batch 先对 prompt 进行采样生成多条回答，调用奖励模型打分，计算组内相对优势。<br>简要流程：</p><ol><li>对batch中每个prompt调用模型一次性生成 <code>num_generations</code>条回答。若生成中提前出现EOS，对EOS之后的token使用completion_mask进行掩码</li><li>使用ref_model对完整序列(prompt+completion) 计算token级对数概率，用于后面进行KL</li><li>调用reward model对每条回答打分，形成[B*G]的reward</li><li>计算相对优势：[B*G]-reshape-&gt;[B,G], 对同一个 prompt 的 G 条回答做“均值、标准差”，再 broadcast 回去，以得到每条回答的相对 advantage<br>全部代码：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_prepare_inputs</span>(<span class="hljs-params">self, inputs: <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Union</span>[torch.Tensor, <span class="hljs-type">Any</span>]]</span>) -&gt; <span class="hljs-built_in">dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Union</span>[torch.Tensor, <span class="hljs-type">Any</span>]]:<br>    device = <span class="hljs-variable language_">self</span>.accelerator.device<br>    prompts = [x[<span class="hljs-string">&quot;prompt&quot;</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> inputs]<br>    prompts_text = [maybe_apply_chat_template(example, <span class="hljs-variable language_">self</span>.processing_class)[<span class="hljs-string">&quot;prompt&quot;</span>] <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> inputs]<br>    prompt_inputs = <span class="hljs-variable language_">self</span>.processing_class(<br>        prompts_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, padding=<span class="hljs-literal">True</span>, padding_side=<span class="hljs-string">&quot;left&quot;</span>, add_special_tokens=<span class="hljs-literal">False</span><br>    )<br>    prompt_inputs = <span class="hljs-built_in">super</span>()._prepare_inputs(prompt_inputs)<br>    prompt_ids, prompt_mask = prompt_inputs[<span class="hljs-string">&quot;input_ids&quot;</span>], prompt_inputs[<span class="hljs-string">&quot;attention_mask&quot;</span>]<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.max_prompt_length <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        prompt_ids = prompt_ids[:, -<span class="hljs-variable language_">self</span>.max_prompt_length :]<br>        prompt_mask = prompt_mask[:, -<span class="hljs-variable language_">self</span>.max_prompt_length :]<br><br>    <span class="hljs-comment"># Generate completions using either vLLM or regular generation</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.args.use_vllm:<br>        <span class="hljs-comment"># First, have main process load weights if needed</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.state.global_step != <span class="hljs-variable language_">self</span>._last_loaded_step:<br>            <span class="hljs-keyword">with</span> unwrap_model_for_generation(<br>                <span class="hljs-variable language_">self</span>.model, <span class="hljs-variable language_">self</span>.accelerator, gather_deepspeed3_params=<span class="hljs-variable language_">self</span>.args.ds3_gather_for_generation<br>            ) <span class="hljs-keyword">as</span> unwrapped_model:<br>                <span class="hljs-keyword">if</span> is_compiled_module(unwrapped_model):<br>                    state_dict = unwrapped_model._orig_mod.state_dict()<br>                <span class="hljs-keyword">else</span>:<br>                    state_dict = unwrapped_model.state_dict()<br>            <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.accelerator.is_main_process:<br>                llm_model = <span class="hljs-variable language_">self</span>.llm.llm_engine.model_executor.driver_worker.model_runner.model<br>                llm_model.load_weights(state_dict.items())<br>            <span class="hljs-variable language_">self</span>._last_loaded_step = <span class="hljs-variable language_">self</span>.state.global_step<br><br>        <span class="hljs-comment"># Generate completions using vLLM: gather all prompts and use them in a single call in the main process</span><br>        all_prompts_text = gather_object(prompts_text)<br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.accelerator.is_main_process:<br>            outputs = <span class="hljs-variable language_">self</span>.llm.generate(all_prompts_text, sampling_params=<span class="hljs-variable language_">self</span>.sampling_params, use_tqdm=<span class="hljs-literal">False</span>)<br>            completion_ids = [out.token_ids <span class="hljs-keyword">for</span> completions <span class="hljs-keyword">in</span> outputs <span class="hljs-keyword">for</span> out <span class="hljs-keyword">in</span> completions.outputs]<br>        <span class="hljs-keyword">else</span>:<br>            completion_ids = [<span class="hljs-literal">None</span>] * <span class="hljs-built_in">len</span>(all_prompts_text) * <span class="hljs-variable language_">self</span>.num_generations<br><br>        <span class="hljs-comment"># Broadcast the completions from the main process to all processes, ensuring each process receives its</span><br>        <span class="hljs-comment"># corresponding slice.</span><br>        completion_ids = broadcast_object_list(completion_ids, from_process=<span class="hljs-number">0</span>)<br>        process_slice = <span class="hljs-built_in">slice</span>(<br>            <span class="hljs-variable language_">self</span>.accelerator.process_index * <span class="hljs-built_in">len</span>(prompts) * <span class="hljs-variable language_">self</span>.num_generations,<br>            (<span class="hljs-variable language_">self</span>.accelerator.process_index + <span class="hljs-number">1</span>) * <span class="hljs-built_in">len</span>(prompts) * <span class="hljs-variable language_">self</span>.num_generations,<br>        )<br>        completion_ids = completion_ids[process_slice]<br><br>        <span class="hljs-comment"># Pad the completions, and concatenate them with the prompts</span><br>        completion_ids = [torch.tensor(ids, device=device) <span class="hljs-keyword">for</span> ids <span class="hljs-keyword">in</span> completion_ids]<br>        completion_ids = pad(completion_ids, padding_value=<span class="hljs-variable language_">self</span>.processing_class.pad_token_id)<br>        prompt_ids = torch.repeat_interleave(prompt_ids, <span class="hljs-variable language_">self</span>.num_generations, dim=<span class="hljs-number">0</span>)<br>        prompt_mask = torch.repeat_interleave(prompt_mask, <span class="hljs-variable language_">self</span>.num_generations, dim=<span class="hljs-number">0</span>)<br>        prompt_completion_ids = torch.cat([prompt_ids, completion_ids], dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># Regular generation path</span><br>        <span class="hljs-keyword">with</span> unwrap_model_for_generation(<span class="hljs-variable language_">self</span>.model, <span class="hljs-variable language_">self</span>.accelerator) <span class="hljs-keyword">as</span> unwrapped_model:<br>            prompt_completion_ids = unwrapped_model.generate(<br>                prompt_ids, attention_mask=prompt_mask, generation_config=<span class="hljs-variable language_">self</span>.generation_config<br>            )<br><br>        <span class="hljs-comment"># Compute prompt length and extract completion ids</span><br>        prompt_length = prompt_ids.size(<span class="hljs-number">1</span>)<br>        prompt_ids = prompt_completion_ids[:, :prompt_length]<br>        completion_ids = prompt_completion_ids[:, prompt_length:]<br>        prompt_mask = prompt_mask.repeat_interleave(<span class="hljs-variable language_">self</span>.num_generations, dim=<span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># Mask everything after the first EOS token</span><br>    is_eos = completion_ids == <span class="hljs-variable language_">self</span>.processing_class.eos_token_id<br>    eos_idx = torch.full((is_eos.size(<span class="hljs-number">0</span>),), is_eos.size(<span class="hljs-number">1</span>), dtype=torch.long, device=device)<br>    eos_idx[is_eos.<span class="hljs-built_in">any</span>(dim=<span class="hljs-number">1</span>)] = is_eos.<span class="hljs-built_in">int</span>().argmax(dim=<span class="hljs-number">1</span>)[is_eos.<span class="hljs-built_in">any</span>(dim=<span class="hljs-number">1</span>)]<br>    sequence_indices = torch.arange(is_eos.size(<span class="hljs-number">1</span>), device=device).expand(is_eos.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>    completion_mask = (sequence_indices &lt;= eos_idx.unsqueeze(<span class="hljs-number">1</span>)).<span class="hljs-built_in">int</span>()<br><br>    <span class="hljs-comment"># Concatenate prompt_mask with completion_mask for logit computation</span><br>    attention_mask = torch.cat([prompt_mask, completion_mask], dim=<span class="hljs-number">1</span>)  <span class="hljs-comment"># (B*G, P+C)</span><br><br>    logits_to_keep = completion_ids.size(<span class="hljs-number">1</span>)  <span class="hljs-comment"># we only need to compute the logits for the completion tokens</span><br><br>    <span class="hljs-keyword">with</span> torch.inference_mode():<br>        <span class="hljs-keyword">if</span> <span class="hljs-variable language_">self</span>.ref_model <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            ref_per_token_logps = <span class="hljs-variable language_">self</span>._get_per_token_logps(<br>                <span class="hljs-variable language_">self</span>.ref_model, prompt_completion_ids, attention_mask, logits_to_keep<br>            )<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">with</span> <span class="hljs-variable language_">self</span>.accelerator.unwrap_model(<span class="hljs-variable language_">self</span>.model).disable_adapter():<br>                ref_per_token_logps = <span class="hljs-variable language_">self</span>._get_per_token_logps(<br>                    <span class="hljs-variable language_">self</span>.model, prompt_completion_ids, attention_mask, logits_to_keep<br>                )<br><br>    <span class="hljs-comment"># Decode the generated completions</span><br>    completions = <span class="hljs-variable language_">self</span>.processing_class.batch_decode(completion_ids, skip_special_tokens=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">if</span> is_conversational(inputs[<span class="hljs-number">0</span>]):<br>        completions = [[&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: completion&#125;] <span class="hljs-keyword">for</span> completion <span class="hljs-keyword">in</span> completions]<br><br>    <span class="hljs-comment"># Compute the rewards</span><br>    prompts = [prompt <span class="hljs-keyword">for</span> prompt <span class="hljs-keyword">in</span> prompts <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-variable language_">self</span>.num_generations)]  <span class="hljs-comment"># repeat prompts</span><br><br>    rewards_per_func = torch.zeros(<span class="hljs-built_in">len</span>(prompts), <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.reward_funcs), device=device)<br>    <span class="hljs-keyword">for</span> i, (reward_func, reward_processing_class) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<br>        <span class="hljs-built_in">zip</span>(<span class="hljs-variable language_">self</span>.reward_funcs, <span class="hljs-variable language_">self</span>.reward_processing_classes)<br>    ):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(reward_func, nn.Module):  <span class="hljs-comment"># Module instead of PretrainedModel for compat with compiled models</span><br>            <span class="hljs-keyword">if</span> is_conversational(inputs[<span class="hljs-number">0</span>]):<br>                messages = [&#123;<span class="hljs-string">&quot;messages&quot;</span>: p + c&#125; <span class="hljs-keyword">for</span> p, c <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prompts, completions)]<br>                texts = [apply_chat_template(x, reward_processing_class)[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> messages]<br>            <span class="hljs-keyword">else</span>:<br>                texts = [p + c <span class="hljs-keyword">for</span> p, c <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prompts, completions)]<br>            reward_inputs = reward_processing_class(<br>                texts, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, padding=<span class="hljs-literal">True</span>, padding_side=<span class="hljs-string">&quot;right&quot;</span>, add_special_tokens=<span class="hljs-literal">False</span><br>            )<br>            reward_inputs = <span class="hljs-built_in">super</span>()._prepare_inputs(reward_inputs)<br>            <span class="hljs-keyword">with</span> torch.inference_mode():<br>                rewards_per_func[:, i] = reward_func(**reward_inputs).logits[:, <span class="hljs-number">0</span>]  <span class="hljs-comment"># Shape (B*G,)</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># Repeat all input columns (but &quot;prompt&quot; and &quot;completion&quot;) to match the number of generations</span><br>            reward_kwargs = &#123;key: [] <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> inputs[<span class="hljs-number">0</span>].keys() <span class="hljs-keyword">if</span> key <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;prompt&quot;</span>, <span class="hljs-string">&quot;completion&quot;</span>]&#125;<br>            <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> reward_kwargs:<br>                <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> inputs:<br>                    <span class="hljs-comment"># Repeat each value in the column for `num_generations` times</span><br>                    reward_kwargs[key].extend([example[key]] * <span class="hljs-variable language_">self</span>.num_generations)<br>            output_reward_func = reward_func(prompts=prompts, completions=completions, **reward_kwargs)<br>            rewards_per_func[:, i] = torch.tensor(output_reward_func, dtype=torch.float32, device=device)<br><br>    <span class="hljs-comment"># Sum the rewards from all reward functions</span><br>    rewards = rewards_per_func.<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># Compute grouped-wise rewards</span><br>    mean_grouped_rewards = rewards.view(-<span class="hljs-number">1</span>, <span class="hljs-variable language_">self</span>.num_generations).mean(dim=<span class="hljs-number">1</span>)<br>    std_grouped_rewards = rewards.view(-<span class="hljs-number">1</span>, <span class="hljs-variable language_">self</span>.num_generations).std(dim=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># Normalize the rewards to compute the advantages</span><br>    mean_grouped_rewards = mean_grouped_rewards.repeat_interleave(<span class="hljs-variable language_">self</span>.num_generations, dim=<span class="hljs-number">0</span>)<br>    std_grouped_rewards = std_grouped_rewards.repeat_interleave(<span class="hljs-variable language_">self</span>.num_generations, dim=<span class="hljs-number">0</span>)<br>    advantages = (rewards - mean_grouped_rewards) / (std_grouped_rewards + <span class="hljs-number">1e-4</span>)<br><br>    <span class="hljs-comment"># Log the metrics</span><br>    reward_per_func = <span class="hljs-variable language_">self</span>.accelerator.gather_for_metrics(rewards_per_func).mean(<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">for</span> i, reward_func <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-variable language_">self</span>.reward_funcs):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(reward_func, nn.Module):  <span class="hljs-comment"># Module instead of PretrainedModel for compat with compiled models</span><br>            reward_func_name = reward_func.config._name_or_path.split(<span class="hljs-string">&quot;/&quot;</span>)[-<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">else</span>:<br>            reward_func_name = reward_func.__name__<br>        <span class="hljs-variable language_">self</span>._metrics[<span class="hljs-string">f&quot;rewards/<span class="hljs-subst">&#123;reward_func_name&#125;</span>&quot;</span>].append(reward_per_func[i].item())<br><br>    <span class="hljs-variable language_">self</span>._metrics[<span class="hljs-string">&quot;reward&quot;</span>].append(<span class="hljs-variable language_">self</span>.accelerator.gather_for_metrics(rewards).mean().item())<br>    <span class="hljs-variable language_">self</span>._metrics[<span class="hljs-string">&quot;reward_std&quot;</span>].append(<span class="hljs-variable language_">self</span>.accelerator.gather_for_metrics(std_grouped_rewards).mean().item())<br><br>    <span class="hljs-keyword">return</span> &#123;<br>        <span class="hljs-string">&quot;prompt_ids&quot;</span>: prompt_ids,<br>        <span class="hljs-string">&quot;prompt_mask&quot;</span>: prompt_mask,<br>        <span class="hljs-string">&quot;completion_ids&quot;</span>: completion_ids,<br>        <span class="hljs-string">&quot;completion_mask&quot;</span>: completion_mask,<br>        <span class="hljs-string">&quot;ref_per_token_logps&quot;</span>: ref_per_token_logps,<br>        <span class="hljs-string">&quot;advantages&quot;</span>: advantages,<br>    &#125;<br></code></pre></td></tr></table></figure>具体细节：<a href="https://blog.csdn.net/shizheng_Li/article/details/145794949">https://blog.csdn.net/shizheng_Li/article/details/145794949</a></li></ol><p><strong>compute_loss</strong><br>作用：根据 GRPO 公式，结合 KL 惩罚项和相对优势，计算最终损失并进行反向传播。<br>简要流程：</p><ol><li>在当前策略下计算完整序列的token级对数概率</li><li>根据actor model和ref model的token_log_prob,计算KL散度</li><li>利用KL散度和<code>_prepare_inputs</code>中得到的相对优势计算GRPO Loss,然后反向传播进行梯度更新<br>全部代码：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_loss</span>(<span class="hljs-params">self, model, inputs, return_outputs=<span class="hljs-literal">False</span>, num_items_in_batch=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-keyword">if</span> return_outputs:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;The GRPOTrainer does not support returning outputs&quot;</span>)<br>    <span class="hljs-comment"># Compute the per-token log probabilities for the model</span><br><br>    prompt_ids, prompt_mask = inputs[<span class="hljs-string">&quot;prompt_ids&quot;</span>], inputs[<span class="hljs-string">&quot;prompt_mask&quot;</span>]<br>    completion_ids, completion_mask = inputs[<span class="hljs-string">&quot;completion_ids&quot;</span>], inputs[<span class="hljs-string">&quot;completion_mask&quot;</span>]<br>    input_ids = torch.cat([prompt_ids, completion_ids], dim=<span class="hljs-number">1</span>)<br>    attention_mask = torch.cat([prompt_mask, completion_mask], dim=<span class="hljs-number">1</span>)<br>    logits_to_keep = completion_ids.size(<span class="hljs-number">1</span>)  <span class="hljs-comment"># we only need to compute the logits for the completion tokens</span><br><br>    per_token_logps = <span class="hljs-variable language_">self</span>._get_per_token_logps(model, input_ids, attention_mask, logits_to_keep)<br><br>    <span class="hljs-comment"># Compute the KL divergence between the model and the reference model</span><br>    ref_per_token_logps = inputs[<span class="hljs-string">&quot;ref_per_token_logps&quot;</span>]<br>    per_token_kl = torch.exp(ref_per_token_logps - per_token_logps) - (ref_per_token_logps - per_token_logps) - <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># x - x.detach() allows for preserving gradients from x</span><br>    advantages = inputs[<span class="hljs-string">&quot;advantages&quot;</span>]<br>    per_token_loss = torch.exp(per_token_logps - per_token_logps.detach()) * advantages.unsqueeze(<span class="hljs-number">1</span>)<br>    per_token_loss = -(per_token_loss - <span class="hljs-variable language_">self</span>.beta * per_token_kl)<br>    loss = ((per_token_loss * completion_mask).<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">1</span>) / completion_mask.<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">1</span>)).mean()<br><br>    <span class="hljs-comment"># Log the metrics</span><br>    completion_length = <span class="hljs-variable language_">self</span>.accelerator.gather_for_metrics(completion_mask.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>)).<span class="hljs-built_in">float</span>().mean().item()<br>    <span class="hljs-variable language_">self</span>._metrics[<span class="hljs-string">&quot;completion_length&quot;</span>].append(completion_length)<br><br>    mean_kl = ((per_token_kl * completion_mask).<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">1</span>) / completion_mask.<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">1</span>)).mean()<br>    <span class="hljs-variable language_">self</span>._metrics[<span class="hljs-string">&quot;kl&quot;</span>].append(<span class="hljs-variable language_">self</span>.accelerator.gather_for_metrics(mean_kl).mean().item())<br><br>    <span class="hljs-keyword">return</span> loss<br></code></pre></td></tr></table></figure>具体细节：<a href="https://blog.csdn.net/shizheng_Li/article/details/145793070">https://blog.csdn.net/shizheng_Li/article/details/145793070</a></li></ol><p><strong>prediction_step</strong><br>作用：训练 &#x2F; 验证阶段如何调用 _prepare_inputs 并获取 loss。<br>在评估或预测时，也需要执行 _prepare_inputs 来生成多条回答并算 loss，只不过不会再反向传播。这个函数就是在 eval 阶段或预测时，对应地拿到 loss，用于打印日志或 early stopping 等操作。</p><p><strong>log 与 create_model_card</strong><br>作用：日志与模型卡，可上传到 Hugging Face Hub 做模型管理。<br>create_model_card输入参数：</p><ul><li>model_name：模型的名称</li><li>dataset_name：用于训练的数据集的名称</li><li>tags：要与模型卡关联的标签</li></ul><h3 id="自定义奖励函数"><a href="#自定义奖励函数" class="headerlink" title="自定义奖励函数"></a>自定义奖励函数</h3><p>GRPOTrainer 支持使用自定义奖励函数来代替密集奖励模型。为了确保兼容性，您的奖励函数必须满足以下要求：</p><ol><li>输入参数<br>函数必须接受以下内容作为关键字参数：<ul><li>prompts（包含提示），</li><li>completions（包含生成的补全），</li><li>数据集可能包含的所有列名（但prompt除外）。例如，如果数据集包含名为ground_truth的列，则将使用ground_truth作为关键字参数调用该函数。满足此要求的最简单方法是在函数签名中使用**kwargs。</li></ul></li></ol><p>根据数据集格式，输入会有所不同：<br>    - 对于标准格式，prompts和completions将是字符串列表。<br>    - 对于对话格式，prompts和completions将是消息字典列表。</p><ol start="2"><li>返回值<br>函数必须返回一个浮点数列表。每个浮点数代表对应于单个补全的奖励。</li></ol><p>示例一: 奖励较长的补全</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">reward_func</span>(<span class="hljs-params">completions, **kwargs</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;奖励函数，对较长的补全给予更高的分数。&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> [<span class="hljs-built_in">float</span>(<span class="hljs-built_in">len</span>(completion)) <span class="hljs-keyword">for</span> completion <span class="hljs-keyword">in</span> completions]<br></code></pre></td></tr></table></figure><p>示例二：奖励具有特定格式的补全</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> re<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">format_reward_func</span>(<span class="hljs-params">completions, **kwargs</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;奖励函数，检查补全是否具有特定格式。&quot;&quot;&quot;</span><br>    pattern = <span class="hljs-string">r&quot;^&amp;lt;think&amp;gt;.*?&amp;lt;/think&amp;gt;&amp;lt;answer&amp;gt;.*?&amp;lt;/answer&amp;gt;$&quot;</span><br>    completion_contents = [completion[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;content&quot;</span>] <span class="hljs-keyword">for</span> completion <span class="hljs-keyword">in</span> completions]<br>    matches = [re.<span class="hljs-keyword">match</span>(pattern, content) <span class="hljs-keyword">for</span> content <span class="hljs-keyword">in</span> completion_contents]<br>    <span class="hljs-keyword">return</span> [<span class="hljs-number">1.0</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">match</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0.0</span> <span class="hljs-keyword">for</span> <span class="hljs-keyword">match</span> <span class="hljs-keyword">in</span> matches]<br></code></pre></td></tr></table></figure><p>写在最后： 详见<a href="https://huggingface.co/docs/trl/main/en/grpo_trainer">https://huggingface.co/docs/trl/main/en/grpo_trainer</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>RLHF</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RLHF(二)：偏好数据采集</title>
    <link href="/2025/04/18/RLHF(%E4%BA%8C)/"/>
    <url>/2025/04/18/RLHF(%E4%BA%8C)/</url>
    
    <content type="html"><![CDATA[<h3 id="ORM-和-PRM"><a href="#ORM-和-PRM" class="headerlink" title="ORM 和 PRM"></a>ORM 和 PRM</h3><p><strong>ORM</strong>：结果奖励模型，是不管推理有多少步，对完整的生成结果进行一次打分，是一个反馈更稀疏的奖励模型<br><strong>PRM</strong>：过程奖励模型，是在生成过程中，分步骤，对每一步进行打分，是更细粒度的奖励模型</p><p>使用PRM可以在post-training和inference两个阶段提升模型的推理性能：</p><ul><li>Post-Training阶段：在偏好对齐阶段，通过在RL过程中增加PRM，对采样的结果按步骤输出奖励值，为模型提供更精细的监督信号，来指导策略模型优化，提升模型按步推理的能力</li><li>Inference阶段：对于一个训练好的PRM，可以在inference阶段筛选优质生成结果。</li></ul><h3 id="MCTS-蒙特卡洛树搜索"><a href="#MCTS-蒙特卡洛树搜索" class="headerlink" title="MCTS 蒙特卡洛树搜索"></a>MCTS 蒙特卡洛树搜索</h3><p>MCTS是强化学习领域提出的方法，通过采样方式预估当前动作或状态的价值。具体操作步骤：使用已有的策略与环境做仿真交互，进行多次rollout采样，最终构成了一个从当前节点出发的一颗Tree（每个rollout表示<strong>从当前节点到最终结束状态的多次与环境仿真交互的过程</strong>）。这颗Tree的所有叶子节点都是结束状态，结束状态是可以通过定义规则进行量化收益的。当Tree的叶子结点有了奖励值，就可通过反向传播，计算每个中间节点的奖励值，最终计算出整个Tree所有节点的奖励值。MCTS一次rollout包括：sample，expand，simulate，backprop四个步骤。</p><ul><li><strong>Sample(采样)：</strong>选择一个未被探索的节点，在Reasoning Model中的节点表示一个带有特定标签的推理步骤（如：planning 节点，reflection节点等）。初始情况，Tree只有一个表示原始查询的节点</li><li><strong>Expand(扩展)：</strong>从未被选择的节点出发，展开所有可能的子节点，如下图中从$S_0$到$S_{1,1}, S_{1,2}, S_{1,3}, S_{1,4}$的过程。对于文本生成模型，不可能穷举所有子节点(next token)，因此需要设置一个最大生活次数，即最大子节点个数。</li><li><strong>Simulate(模拟)：</strong>从展开的子节点中，随机选择一个节点，再展开它的子节点，重复进行expand过程。直到达到叶子结点。该迭代过程需要控制搜索树的最大深度N</li><li><strong>Backprop(回传)：</strong>通过多次模拟我们得到了一个从根节点到叶子结点的Tree，如下图所示。通过计算<code>(从当前节点出发到正确答案的路径数)/(从当前节点出发的总路径数)</code>的比值作为节点的奖励值。</li></ul><p>使用MCTS也可以在post-training和inference两个节点提升模型的推理性能：</p><ul><li>Post-Training阶段: 对于每个problem 通过上述方法构造一个搜索Tree，然后进行Tree的游走遍历采样，再用采样的样本SFT或RL训练模型。</li><li>Inference阶段：在推理阶段，也是对一个problem探索多节点构造一棵搜索树，对于到达正确答案的路径，根据节点路径的置信度打分，贪心选取最优路径作为最终的推理结果。</li></ul><p><img src="/../article_img/RLHF/img2-1.png" alt="MCTS生成搜索树的过程"></p><h3 id="分而治之：OmegaPRM"><a href="#分而治之：OmegaPRM" class="headerlink" title="分而治之：OmegaPRM"></a>分而治之：OmegaPRM</h3><p>由于MCTS和PRM方法的规模化成本过高，为了更高效的收集高质量的过程监督数据，OmegaPRM算法通过二分搜索快速识别思维链CoT中的第一个错误，并平衡正反例，从而确保效率和质量。</p><p>OmegaPRM的搜索树如下图所示，树中的每个节点都表示部分思维链解决方案的状态，其中包含信息，如推出的准确性和其他统计数据。每条边都表示从上一个状态开始的一个动作，即推理步骤。黄色边是正确的步骤，蓝色边是错误的步骤。<br><img src="/../article_img/RLHF/img2-2.png" alt="OmegaPRM生成搜索树的过程"></p><p>搜索算法的具体实现如下：建立了一个<code>完成者策略</code>，该策略可以采用问题 𝑞 和一个由前 𝑡 步骤 $𝑥_{1:𝑡}$ 组成的前缀解决方案，并输出后续步骤的完成情况（在强化学习中通常称为<code>rollout</code>），直到得出最终答案。对于解决方案的任何步骤，<code>完成者策略</code>可用于从该步骤中随机抽取 𝑘 个 <code>rollout</code>。将这些 rollout 的最终答案与正确答案进行比较，提供与 𝑘 个 rollout 相对应的 𝑘 个答案正确性标签。随后，计算第 𝑡 步中正确 rollout 占总 rollout 的比率，公式1 展示了估计前缀步骤 $𝑥_{1:𝑡}$ “正确性水平”的方法。只要在逻辑推理场景中任何一个推出是正确的，𝑥1:𝑡 就应该被视为正确的。为了优化注释效率，OmegaPRM采用二分搜索的蒙特卡洛估计，如下图所示。<br>$c_t &#x3D; MontoCarlo(q,x_{1:t}) &#x3D; \frac{Num(\text{correct rollouts from t-th step})}{Num(\text{total rollouts from t-th step})}$<br><img src="/../article_img/RLHF/img2-3.png" alt="OmegaPRM二分搜索算法"></p>]]></content>
    
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>RLHF</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RLHF(一)：LLM post-training</title>
    <link href="/2025/04/17/RLHF(%E4%B8%80)/"/>
    <url>/2025/04/17/RLHF(%E4%B8%80)/</url>
    
    <content type="html"><![CDATA[<h3 id="1-PPO算法"><a href="#1-PPO算法" class="headerlink" title="1. PPO算法"></a>1. PPO算法</h3><p>$L_{PPO} &#x3D; \sum_{(s_t,a_t)}\frac{\pi_\theta(a_t|s_t)}{\pi_{ref}(a_t|s_t)}A(s_t,a_t) - \beta KL(\pi_\theta, \pi_{ref})$</p><p>PPO的训练步骤如下：<br>（1）收集人类反馈，人工标注数据 （2）训练奖励模型 （3）采用PPO强化学习，优化策略<br><img src="/../article_img/RLHF/img1-1.png" alt="PPO训练流程"></p><p>在LLM上使用PPO算法进行post-training时，主要涉及4个model:</p><ul><li><strong>Actor Model</strong>： 是我们要优化学习的策略模型，同时用于做数据采样，用SFT Model热启</li><li><strong>Reference Model</strong>： 是为了控制Actor模型学习的分布与原始模型的分布相差不会太远的参考模型，通过loss中增加KL项，来达到这个效果。训练过程中该模型不更新</li><li><strong>Critic Model</strong>：是对每个状态做打分的价值模型，衡量当前token到生成结束的整体价值打分，一般可用Reward Model热启</li><li><strong>Reward Model</strong>：对整个生成的结果打分，是事先训练好的Reward Model。训练过程中该模型不更新</li></ul><h3 id="2-DPO算法"><a href="#2-DPO算法" class="headerlink" title="2. DPO算法"></a>2. DPO算法</h3><p>$L_{DPO}(\pi_\theta; \pi_{ref}) &#x3D; -E_{(x,y_w,y_l)\sim D}[log \sigma(\beta log\frac{\pi_\theta(y_w|x)}{\pi_{ref}(y_w|x)} - \beta log\frac{\pi_\theta(y_l|x)}{\pi_{ref}(y_l|x)})]$<br>DPO相比于PPO算法，由于它直接定义偏好损失作为策略来优化LLM，省去了奖励模型的定义，因此在post-training的流程上更为简练(PPO: SFT-&gt;RM-&gt;PPO)</p><p>如何理解DPO loss:<br>开始训练时，Reference model和Policy model都是同一个模型，在训练过程中Reference model不更新权重。我们将loss公式中的log部分展开，然后设$\beta$为1，并且暂时不看前面的log_sigmoid。从而将优化函数简化为：$[logp(y_w) - logp_{ref}(y_w)]-[logp(y_l)-logp_{ref}(y_l)]$</p><p>训练的目标为将优化函数最大化。即我们希望公式的左半部分和右半部分的margin越大越好，左半部分的含义是good response相较于没训练之前的累计概率差值，右半部分代表bad response相较于没训练之前的累计概率差值</p><h3 id="3-KTO算法"><a href="#3-KTO算法" class="headerlink" title="3. KTO算法"></a>3. KTO算法</h3><p>DPO算法中依赖的训练数据为：问题——期望回答——拒绝回答。高质量的偏好数据收集较为困难。KTO则回避了这个问题，可以直接利用二元信号标记的数据来训练算法，对于负样本更加敏感</p><p><strong>前景价值函数</strong>：决策者根据实际收益或损失所产生的主观感受的价值。（决策时，相对于收益，决策者对损失更加敏感）</p><div align="center">$$v(z,z_{ref};\lambda,a) =\begin{cases} (z - z_{ref})^\alpha & \text{if } z > z_{ref} \\-\lambda(z_{ref} - z)^\alpha & \text{if } z < z_{ref}\end{cases}$$</div><p>KTO算法的loss如下：<br>$L_{KTO}(\pi_\theta; \pi_{ref}) &#x3D; E_{(x,y)\sim D}[\lambda_y - v(x,y)]$</p><div align="center">$$v(x,y)=\begin{cases} \lambda_D \sigma(\beta(r_\theta(x,y)-z_0)) & if y \sim y_{desirable}|x \\-\lambda_U \sigma(\beta(z_0 - r_\theta(x,y))) & if y \sim y_{undesirable}|x\end{cases}$$</div>其中，$z_0 = KL(\pi_\theta(y'|x)||\pi_{ref}(y'|x))$， $r_\theta(x,y)=log \frac{\pi_\theta(y|x)}{\pi_{ref}(y|x)}$<h3 id="4-GRPO算法"><a href="#4-GRPO算法" class="headerlink" title="4.GRPO算法"></a>4.GRPO算法</h3><p>在PPO算法中，每个时间步都有一个价值网络去估计优势函数，这使得训练资源消耗巨大。为了减少在post-training的过程中对价值网络的依赖，GRPO采用“分组输出相互比较”的方式来估计基线，从而省去Critic Model。<br><strong>关键点：分组采样与相对奖励</strong><br>对于一个问题q，Actor Model会产生多份输出$o_1,o_2,…,o_G$，然后将这组输出一起送入奖励模型，得到奖励集合$r_1,r_2,…,r_G$。然后对奖励集合进行归一化$\tilde{r_i}&#x3D;(r_i-mean(r))&#x2F;std(r)$，从而得到分组内的相对水平，即<strong>相对奖励</strong>。GRPO会将相对奖励赋给该输出对应的所有token的优势函数。即$\hat{A}_{i,t} &#x3D; \tilde{r_i}$，也就是说，<strong>输出$o_i$的所有token共享同一个分数</strong>，于是我们得到了一个无价值网络的优势函数。</p><p>综上所述，因为不再需要在每个token上拟合一个价值函数，GRPO可以大幅节省内存。</p><p>下面给出GRPO的loss function:<br>$L_{GRPO}&#x3D; E[\frac{1}{G}\sum_{i&#x3D;1}^G \frac{1}{||o_i||}\sum_{t&#x3D;1}^{||o_i||} min(\frac{\pi_\theta(o_{i,t}|q,o_{i,&lt;t})}{\pi_{ref}(o_{i,t}|q,o_{i,&lt;t})},clip(\frac{\pi_\theta(o_{i,t}|q,o_{i,&lt;t})}{\pi_{ref}(o_{i,t}|q,o_{i,&lt;t})},1-\epsilon,1+\epsilon)) \cdot \hat{A_{i,t}} -\beta KL(\pi_\theta, \pi_{ref})]$<br><img src="/../article_img/RLHF/img1-2.png" alt="GRPO vs PPO"></p><p>Ques: 如何使用GRPO进行过程监督</p>]]></content>
    
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>RLHF</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Syncthing安装</title>
    <link href="/2025/03/25/syncthing%E5%AE%89%E8%A3%85/"/>
    <url>/2025/03/25/syncthing%E5%AE%89%E8%A3%85/</url>
    
    <content type="html"><![CDATA[<h3 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 1、下载最新部署包</span><br>curl -s https://api.github.com/repos/syncthing/syncthing/releases/latest | grep browser_download_url | grep linux-amd64 | <span class="hljs-built_in">cut</span> -d <span class="hljs-string">&#x27;&quot;&#x27;</span> -f 4 | wget -qi -<br><span class="hljs-comment"># 2、解压并安装</span><br>tar -xvf syncthing-linux-amd64-v1.28.1.tar.gz<br><span class="hljs-built_in">mv</span> syncthing-linux-amd64-v1.28.1/syncthing /usr/bin/<br><span class="hljs-comment"># 3、启动并且测试</span><br>syncthing<br></code></pre></td></tr></table></figure><h3 id="开机自启"><a href="#开机自启" class="headerlink" title="开机自启"></a>开机自启</h3><p>如果要立刻启动<strong>syncthing</strong>，直接使用命令 <code>syncthing</code> 即可，但这样运行十分不优雅，因此可以使用systemd配置开机自启。<br>创建一个新的 systemd 服务文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> nano /etc/systemd/system/syncthing.service<br></code></pre></td></tr></table></figure><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs Ini"><span class="hljs-section">[Unit]</span><br><span class="hljs-attr">Description</span>=Syncthing - Open Source Continuous File Synchronization<br><span class="hljs-attr">After</span>=work.target<br><span class="hljs-section">[Service]</span><br><span class="hljs-attr">User</span>=&lt;your_user_name&gt;<br><span class="hljs-attr">ExecStart</span>=/usr/bin/syncthing -<span class="hljs-literal">no</span>-browser -<span class="hljs-literal">no</span>-restart -logflags=<span class="hljs-number">0</span><br><span class="hljs-attr">Restart</span>=<span class="hljs-literal">on</span>-failure<br><span class="hljs-attr">SuessExitStatus</span>=<span class="hljs-number">3</span> <span class="hljs-number">4</span><br><span class="hljs-attr">RestartForceExitStatus</span>=<span class="hljs-number">3</span> <span class="hljs-number">4</span><br><span class="hljs-section">[Install]</span><br><span class="hljs-attr">WantedBy</span>=multi-user.target<br></code></pre></td></tr></table></figure><p>在User处填上用户名，然后重启systemd</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> systemctl daemon-reload<br>systemctl --user restart syncthing<br>systemctl --user status syncthing<br></code></pre></td></tr></table></figure><p>查看当前syncthing进程判断是否正常运行： <code>ps aux | grep syncthing</code></p><h3 id="本地网络访问"><a href="#本地网络访问" class="headerlink" title="本地网络访问"></a>本地网络访问</h3><p>默认情况下，Syncthing 的 Web GUI 只监听 localhost:8384，所以如果在本地网络访问远程服务器的syncthing服务，需要修改监听地址</p><ol><li>编辑配置文件<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">nano ~/.config/syncthing/config.xml<br></code></pre></td></tr></table></figure>如果不知道syncthing的位置的话，可以在命令行输入<code>syncthing -paths</code>找到 <code>config.xml</code> 这项</li><li>找到<code>&lt;gui&gt;</code>节点，修改其中的 address 字段：<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">gui</span> <span class="hljs-attr">enabled</span>=<span class="hljs-string">&quot;true&quot;</span> <span class="hljs-attr">tls</span>=<span class="hljs-string">&quot;false&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">address</span>&gt;</span>0.0.0.0:8384<span class="hljs-tag">&lt;/<span class="hljs-name">address</span>&gt;</span>   <span class="hljs-comment">&lt;!-- ← 这里改成 0.0.0.0 表示监听所有地址 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">apikey</span>&gt;</span>你的apikey<span class="hljs-tag">&lt;/<span class="hljs-name">apikey</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">user</span>&gt;</span>用户名<span class="hljs-tag">&lt;/<span class="hljs-name">user</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">password</span>&gt;</span>密码（Base64编码）<span class="hljs-tag">&lt;/<span class="hljs-name">password</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">gui</span>&gt;</span><br></code></pre></td></tr></table></figure></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Tool</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>强化学习系列（五）：Policy Gradient</title>
    <link href="/2025/03/15/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%94%EF%BC%89/"/>
    <url>/2025/03/15/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%94%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p>写在前面：前面所提到的Q-value Based方法无法解决连续动作空间场景下的优化问题，因为Q-learning的策略是从多个离散动作中贪婪地选择最大Q值，在连续空间中，无法枚举所有动作。为此，本节讲述一种<strong>直接面向策略</strong>的优化方法：Policy Gradient</p><span id="more"></span><h3 id="1-Policy-Gradient"><a href="#1-Policy-Gradient" class="headerlink" title="1. Policy Gradient"></a>1. Policy Gradient</h3><p>训练目标：$\pi_\theta(s,a)&#x3D;P[a|s,\theta]$<br>Ques: 什么样的策略算是好的策略,如何进行梯度更新<br>Ans:<br><code>think</code> $\theta$会影响策略$\pi$,$\pi$会影响episode采样路径$\tau&#x3D;{s_1,a_1,r_1,s_2,a_2,r_2,…,s_T,a_T,r_T}$，根据$\tau$, 我们可以算出$R(\tau)&#x3D;\sum_{n&#x3D;1}^N r_n$，我们希望采样路径的$R(\tau)$尽可能的大<br><code>method</code><br>用采样路径的平均收益来评价一个$\theta$的好坏<br>$\bar R_\theta &#x3D; \sum_{\tau} R(\tau) \cdot P(\tau|\theta) \approx \frac{1}{N} \sum_{n&#x3D;1}^{N} R(\tau^n)$<br>推导$\bar R_\theta$的梯度:<br>$$\nabla \bar R_\theta&#x3D;\sum_\tau R(\tau) \nabla P(\tau|\theta)&#x3D;\sum_\tau R(\tau)P(\tau|\theta) \frac{\nabla P(\tau|\theta)}{P(\tau|\theta)}&#x3D;<br>\sum_\tau R(\tau)P(\tau|\theta)\nabla logP(\tau|\theta) \approx \frac{1}{N}\sum_{n&#x3D;1}^N R(\tau^n) \nabla log P(\tau^n|\theta)$$<br>其中，$P(\tau|\theta)&#x3D;p(s_1)p(a_1|s_1,\theta)p(r_1,s_2|s_1,a_1)p(a_2|s_2,\theta)…$<br>由此，我们有：$log P(\tau|\theta)&#x3D;logp(s_1)+\sum_{t&#x3D;1}^Tlogp(a_t|s_t,\theta)+logp(r_t,s_{t+1}|s_t,a_t)$<br>$\nabla logP(\tau|\theta)&#x3D;\sum_{t&#x3D;1}^T\nabla logp(a_t|s_t, \theta)$<br>由此，我们可以将policy gradient视为一个分类任务对$\nabla \bar R_\theta$进行更新<br><img src="/../article_img/Reinforcement/img5-2.png" alt="Gradient Descent"><br>类比分类任务：<br><img src="/../article_img/Reinforcement/img5-1.png" alt="Classification Task"></p><h3 id="2-Actor-Critic"><a href="#2-Actor-Critic" class="headerlink" title="2. Actor-Critic"></a>2. Actor-Critic</h3><p>在Policy Gradient方法中，我们在更新$\nabla \bar R_\theta$时，借助累计收益$R(\tau^n)$作为优势估计，然而在一些情况下，虽然$R(\tau^n)$是positive的，但是效益还比不过随机效益的话，其实也是不能接受的。因此，需要add a baseline去进一步评估positive or negtive，从而更好地指导$\nabla logP(\tau|\theta)$的更新</p><p>核心思想：<br>（1）Actor:学习策略$\pi_\theta(a|s)$，负责决策<br>（2）Critic:学习一个价值函数 $V_w(s)$，估计状态的“好坏”，指导 Actor 改进策略</p><p>梯度更新：<br>$$\nabla \bar R_\theta \approx \frac{1}{N}\sum_{n&#x3D;1}^{N}\sum_{t&#x3D;1}^{T_n}(R_\tau^n-baseline) \nabla log P_\theta(a_t^n|s_t^n)$$<br>其中$R_\tau^n$可以表示为$E[G_t^n]&#x3D;Q^{\pi_\theta}(s_t^n,a_t^n)$，baseline表示为$V^{\pi_\theta}(s_t^n)$</p><p>Ques: 需要estimate Q和V两个网络吗<br>Ans: 可以只estimate value network<br>利用$Q^{\pi_\theta}(s_t^n,a_t^n)&#x3D;E[r_t^n + V^{\pi_\theta}(s_{t+1}^n)] \approx r_t^n + V^{\pi_\theta}(s_{t+1}^n)$<br>我们可以得到<strong>Advantage Function</strong>：$Q^{\pi_\theta}(s_t^n,a_t^n)-V^{\pi_\theta}(s_t^n)&#x3D;r_t^n - (V^{\pi_\theta}(s_t^n)-V^{\pi_\theta}(s_{t+1}^n))$</p><h3 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h3><p><img src="/../article_img/Reinforcement/img5-5.png" alt="summary"></p>]]></content>
    
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Algorithm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>强化学习系列（四）：DQN算法</title>
    <link href="/2025/03/14/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E5%9B%9B%EF%BC%89/"/>
    <url>/2025/03/14/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E5%9B%9B%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p>写在前面：前面讲解了在On-Policy和Off-Policy环境下如何进行策略提升的几种常用方法，但是在实际应用场景中，state的数量可能是非常庞大的，为了存储每个state-action pair所需要的lookup-table所需要的空间会很庞大，无法通过遍历的方式去evaluate每个state-action pair。这就需要我们考虑如何对Q，V进行建模，通过函数逼近的方法估计连续空间下的state value</p><span id="more"></span><h3 id="1-Value-Approximation"><a href="#1-Value-Approximation" class="headerlink" title="1. Value Approximation"></a>1. Value Approximation</h3><p>Target: 寻找到合适的参数w使得mse loss尽可能的小  $J(w)&#x3D;E_\pi[(v_\pi(S)-\hat{v}(S,w))^2]$<br>通过梯度下降来更新w: $\Delta w&#x3D;-\frac{1}{2}\alpha \nabla_w J(w)&#x3D;\alpha(v_\pi(S)-\hat{v}(S,w))\nabla_w\hat{v}(S_t,w)$</p><p>使用特征向量表示state $x(S)&#x3D;(x_1(S)…x_n(S))$<br>$\hat{v}(S_t,w)$可以通过线性加权得到，即$\hat{v}(S,w)&#x3D;x(S)^Tw&#x3D;\sum_{j&#x3D;1}^n x_j(S)w_j$ </p><p>于是我们便有：$\Delta w&#x3D;\alpha(v_\pi(S)-\hat{v}(S_t,w))x(S)$</p><p>现在思考一个问题，我们如何得到$v_\pi(S)$的真实表示？依然是采用MC&#x2F;TD等方法进行泛化估计<br>MC: $\Delta w&#x3D;\alpha(G_t-\hat{v}(S,w))\nabla_w\hat{v}(S_t,w)$<br>TD(0): $\Delta w&#x3D;\alpha(R_{t+1}+\gamma\hat{v}(S_{t+1},w)-\hat{v}(S_t,w))\nabla_w\hat{v}(S_t,w)$</p><h3 id="2-Replay-Buffer"><a href="#2-Replay-Buffer" class="headerlink" title="2. Replay Buffer"></a>2. Replay Buffer</h3><p>replay buffer是一个 <strong>存储智能体交互经验</strong> 的数据结构（通常是一个队列或数组），用来保存智能体与环境交互的轨迹样本：$(S_t, A_t, S_{t+1}, A_{t+1}, <code>done</code>)$<br>✅ 打破时间相关性 (Break Correlation)<br>强化学习中的数据是按时间顺序生成的，彼此高度相关。Replay Buffer让我们从过去的经验中随机采样，打乱数据顺序，降低相关性，提升训练稳定性。</p><p>✅ 提高数据利用率 (Improve Data Efficiency)<br>每次交互生成的数据如果只用一次就丢掉，效率太低了。Replay Buffer让数据能被多次复用，大大提高训练效率。</p><p>✅ 平滑训练 (Smooth Training)<br>缓冲区里的经验包括成功和失败的多种场景，防止模型被最近的几次失败经验“误导”得太严重。</p><p>✅ 支持 Off-Policy 学习<br>DQN 是 Off-Policy 算法，目标策略是贪婪策略，行为策略是<strong>ϵ-greedy</strong>。Replay Buffer让我们从过去的经验中训练，不必跟当前行为策略严格匹配。</p><h3 id="3-DQN算法"><a href="#3-DQN算法" class="headerlink" title="3. DQN算法"></a>3. DQN算法</h3><p>DQN算法是结合了Q-Learning和深度神经网络的强化学习算法。它用深度神经网络替代传统的Q表格，近似的学习Q值函数：$Q(s,a;\theta) \approx Q*(s,a)$<br>下面对该算法进行介绍：<br>（1）经验回放（Experience Replay）<br>在传统Q-Learning中，每次训练都用最新的数据更新Q值，可能导致网络过拟合最近的经验，收敛不稳定。<br>DQN引入经验回放机制，将每次经历 (s, a, r, s’) 保存到回放缓冲池（Replay Buffer），每次训练时随机采样一批数据进行训练。<br>（2）目标网络（Target Network）<br>DQN使用<strong>在线网络</strong>和<strong>目标网络</strong>两个网络，前者用于实时更新，输出$Q(s,a;\theta)$;后者每隔一段时间赋值在线网络参数$\theta$到目标网络$\theta’$，输出$Q(s’,a’;\theta’)$<br>目标网络的Q值用作训练的目标： $Loss&#x3D;(r + \gamma max_{a’}Q(s’,a’;\theta’)-Q(s,a;\theta))^2$<br><img src="/../article_img/Reinforcement/img4-1.png" alt="DQN framework"><br>（3）使用Epsilon Greedy策略在探索与利用之间做权衡</p><p>下面给出DQN算法的伪代码：<br><img src="/../article_img/Reinforcement/img4-2.png" alt="DQN Algorithm"></p><p>Ques: DQN网络如何实现端到端的学习<br>Ans: 中间层是常规的卷积网络用来学习state表征，输出层通过映射到一个output空间，定义每个维度代表一个value</p><h3 id="4-DQN算法的延伸"><a href="#4-DQN算法的延伸" class="headerlink" title="4. DQN算法的延伸"></a>4. DQN算法的延伸</h3><h4 id="Double-DQN"><a href="#Double-DQN" class="headerlink" title="Double DQN"></a>Double DQN</h4><p>DQN算法存在的问题：使用同一个网络既选择动作又评估价值，可能会导致over estimate的问题<br>改进方案：$Q(s_t,a_t) \leftarrow r_t + Q’(s_{t+1}, argmax_a Q(s_{t+1}，a))$ 内层的Q用来选择action，外层的Q用来评估价值</p><h4 id="Dueling-DQN"><a href="#Dueling-DQN" class="headerlink" title="Dueling DQN"></a>Dueling DQN</h4><p>DQN算法存在的问题：在很多状态下，动作的价值差别不大。比如：游戏中站在原地等待 vs 随便走一步 这种情况下，DQN仍然必须给每个动作单独估计 Q 值，浪费了大量学习能力，导致训练效率下降。<br>Dueling DQN的核心思想：将Q值分成两部分，<strong>状态值函数 V(s)：</strong>描述当前状态本身的“好坏” <strong>优势函数 A(s, a)：</strong>描述某个具体动作比其他动作好多少<br>于是，我们便有：$Q(s,a)&#x3D;V(s)+A(s,a)$<br>优点：状态价值主导训练，不用每次都算所有动作；更高效地学习，尤其在动作多、动作差别小的场景；收敛更快，性能更好<br><img src="/../article_img/Reinforcement/img4-3.png" alt="Dueling DQN"></p><h4 id="Batch-Constraint-DQN-BCQ"><a href="#Batch-Constraint-DQN-BCQ" class="headerlink" title="Batch-Constraint DQN(BCQ)"></a>Batch-Constraint DQN(BCQ)</h4><p>DQN算法存在的外推误差（extrapolation error）问题：Q网络在没见过的state-action pair上会over estimate Q值<br>问题的根源在于：<strong>有限的数据集：</strong>训练数据无法覆盖所有可能的状态-动作对。<strong>目标网络延迟更新：</strong>目标 Q 值用的是旧网络（延迟更新），可能不准确。<strong>最大化操作带来的偏差：</strong>maxQ 倾向于选更高估的值。<br>核心思想：尽可能让agent action和batch中sample action产生的结果相近，即<strong>约束策略不要偏离已收集的数据分布，同时最大化回报</strong></p><p>下面给出BCQ算法的伪代码：<br><img src="/../article_img/Reinforcement/img4-4.png" alt="BCQ Algorithm"><br>可以看到，在行为选择时，除了考虑高Q值以外，我们还希望它能够接近数据分布的action，伪代码的第5行中我们通过设定阈值的方式筛选掉了一些发生概率较低的action</p><h4 id="Distributional-Q-function"><a href="#Distributional-Q-function" class="headerlink" title="Distributional Q-function"></a>Distributional Q-function</h4><p>DQN算法存在的问题：在DQN中，我们学的是Q值的期望，$Q(s,a)&#x3D;E[R(s,a)]$ 但问题是，期望值无法描述奖励的不确定性和波动。也就是说，DQN 只学到了平均回报，没学到“回报的分布情况”。<br>👉 举个例子：假设有两个动作$a_1$和$a_2$，它们的期望回报都是 10。$a_1$的回报是 [10, 10, 10]，非常稳定。$a_2$的回报是 [0, 10, 20]，波动很大。传统 DQN 认为它俩一样好，但显然$a_1$更可靠<br>核心观点：学习回报的“完整分布” $Q(s,a)&#x3D;E[Z(s,a)]$ 这里的Z(s,a)为一个概率分布<br>step：定义回报范围$[v_min,v_max]$,划分为n个小区间；学习每个bin的概率$p_i$,形成一个回报的离散分布；训练目标变成让网络预测整个分布，而不是单一Q值</p>]]></content>
    
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Algorithm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>强化学习系列（三）：Model-Free Control</title>
    <link href="/2025/03/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%89%EF%BC%89/"/>
    <url>/2025/03/12/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p>写在前面：系列二中提及的MC&#x2F;TD方法都是在已知策略$\pi$的前提下，估计每个状态的期望回报。前者是等到整个回合结束利用完整回报$G_t$来更新价值函数,后者利用一步预测和当前奖励动态更新价值函数。可以看到的是，这些方法知识学习了价值函数，并没有改变策略。在这一节，我们主要介绍一些常用的策略优化方法。</p><span id="more"></span><h3 id="1-Epsilon-Greedy"><a href="#1-Epsilon-Greedy" class="headerlink" title="1. Epsilon Greedy"></a>1. Epsilon Greedy</h3><p>在Model-based Control中，我们基于MDP Transition采用贪心策略进行policy improvement：$\pi’(s)&#x3D;argmax_{a \in A}R_s^a + P_{ss’}^aV(s’)$<br>在Model-free背景下，由于缺失MDP Transition，往往采用对行为价值函数Q(s,a)进行建模: $\pi’(s)&#x3D;argmax_{a \in A}Q(s,a)$<br>这里介绍一个常用的贪心策略Epsilon Greedy：</p><div align="center">$$\pi(a|s) =\begin{cases} \frac{\epsilon}{m} + 1 - \epsilon & \text{if } a = \arg\max\limits_{a \in A} Q(s,a) \\\frac{\epsilon}{m} & \text{otherwise}\end{cases}$$</div>why to search bad state: 避免局部最优解，通过增加对不良状态的探索，智能体能够全面地了解环境，发现可能被忽略的潜在机会，进而提升整体策略的质量。<p>&lt;定义&gt;Greedy in the limit with infinite exploration(GLIE)<br>随着时间的推进，策略最终收敛到纯贪婪策略；在训练过程中，每个状态和动作都要被探索无限次，确保获得充分的信息来评估所有可能的动作。<br>即GLIE要求策略$\pi_t$满足以下条件：<br>(1) $lim_{k-&gt;\infty}N_k(s,a)&#x3D;\infty$<br>(2) $lim_{k-&gt;\infty}\pi_k(a|s)&#x3D;1(a&#x3D;argmax_{a’ \in A}Q_k(s,a’))$</p><p>GLIE的意义：（1）保证收敛 （2）避免局部最优</p><p>Epsilon Greedy满足GLIE：在探索的过程中逐渐减少探索率$\epsilon$，例如$\epsilon_t&#x3D;1&#x2F;t$</p><p>下面介绍下$\epsilon$-Greedy与Monte-Carlo结合的Control方法：<br>(1) 使用当前策略$\pi$与环境进行第k次完整交互(kth episode)得到采样数据： ${S_1,A_1,R_2,…,,S_T} \sim \pi$<br>(2) 使用MC方法对进行Q值更新：$N(S_t,A_t) \leftarrow N(S_t,A_t) + 1$, $Q(S_t, A_t) \leftarrow Q(S_t,A_t) + \frac{1}{N(S_t,A_t)}(G_t - Q(S_t, A_t))$<br>(3) 基于\epsilon-Greedy进行策略提升：$\epsilon \leftarrow 1&#x2F;k$, $\pi \leftarrow \epsilon-greedy(Q)$</p><h3 id="2-SARSA"><a href="#2-SARSA" class="headerlink" title="2. SARSA"></a>2. SARSA</h3><p>将TD方法和GLIE结合的Control方法我们称其为SARSA。<br><img src="/../article_img/Reinforcement/img3-1.png" alt="SARSA"><br>下面是SARSA进行Q值更新和策略提升的伪代码:<br><img src="/../article_img/Reinforcement/img3-2.png" alt="SARSA Algorithm"></p><p>n-step SARSA:<br>$q_t^{(n)}&#x3D;R_{t+1} + \gamma R_{t+2} + … + \gamma^{n-1}R_{t+n} + \gamma^n Q(S_{t+n})$<br>$Q(S_t,A_t) \leftarrow Q(S_t,A_t) + \alpha (q_t^{(n)}-Q(S_t,A_t))$</p><h3 id="3-Off-Policy-Learning"><a href="#3-Off-Policy-Learning" class="headerlink" title="3. Off-Policy Learning"></a>3. Off-Policy Learning</h3><p>on policy learning:策略学习只能使用 <strong>当前策略</strong> 生成的数据<br>off policy learning: 策略学习可以使用 <strong>其他策略</strong> 生成的数据，包括历史数据和经验回放<br>​特点：训练策略和行为策略可以不同；可以使用 <strong>过去的数据（经验回放）</strong> 进行训练，提高数据利用率<br>对于off-policy learning，由于行为策略和训练策略并不相同，行为策略$\mu$产生的数据可能不符合目标策略$\pi$的分布，直接使用它来更新目标策略会产生偏差。为了修正分布偏差，可以采用Importance Sampling方法。<br>important sampling:  <strong>用于估计一个分布的期望值，而采样数据却来自另一个分布</strong> 的技术。它通过调整采样分布的影响，来修正采样偏差，使得估计值更准确。<br>$E_{X\sim P}[f(X)]&#x3D;\sum P(X)f(X)&#x3D;\sum Q(X)\frac{P(X)}{Q(X)}f(X)&#x3D;E_{X\sim Q}[\frac{P(X)}{Q(X)}f(X)]$</p><p>下面介绍Importance Sampling for Off-Policy Monte-Carlo:<br>Target: 通过model-free control学习一个目标策略$\pi$,但是采样数据来自于行为策略$\mu$<br>在这里，我们称$\mu$为行为策略，它负责生成训练数据；$\pi$为目标策略，即我们希望学习的策略<br>Step：假设一个完整的episode采样序列：$\tau &#x3D; {S_1, A_1, R_2,…,S_T}$<br>在目标策略$\pi$中的回报期望为 $G_t^{\pi&#x2F;\mu} &#x3D; \frac{\pi(A_t|S_t)}{\mu(A_t|S_t)}\frac{\pi(A_{t+1}|S_{t+1})}{\mu(A_{t+1}|S_{t+1})}…\frac{\pi(A_T|S_T)}{\mu(A_T|S_T)}G_t$<br>更新Q值函数：$Q(S_t,A_t) \leftarrow Q(S_t,A_t) + \alpha(G_t^{\pi&#x2F;\mu}-Q(S_t,A_t))$</p><p>Ques: 为什么$\pi(A_t|S_t)$已知却不能直接用$\pi来更新Q值$<br>Ans: 我们手头的数据是行为策略 μ 生成的，而不是目标策略 π 生成的。如果我们直接用目标策略 π 来更新Q值，实际上我们是在<strong>假设数据是按目标策略采样的，但数据实际是按行为策略采样的</strong>。这会导致估计产生偏差。</p><h3 id="4-Q-Learning"><a href="#4-Q-Learning" class="headerlink" title="4. Q-Learning"></a>4. Q-Learning</h3><p>Q-learning是一种Off-Policy Temporal Difference Learning的控制方法，它可以借助行为策略产生的数据而无需Importance Sampling<br>公式：$Q(S,a) \leftarrow Q(S,a) + \alpha [R+\gamma max_{a’}Q(s’,a’)-Q(s,a)]$<br><img src="/../article_img/Reinforcement/img3-4.png" alt="Q-Learning"></p><p>Ques: 为什么Q-learning不需要重要性采样<br>Ans:<br>（1）Q-learning 的目标策略始终是贪婪策略（$max_{a’}Q(s’,a’)$），但行为策略可以是探索性的（比如 ϵ-greedy）。因为它只用目标策略来选择下一个状态的最优动作，不需要纠正行为策略带来的偏差。<br>（2）它用的是单步TD更新，不是完整回报。TD更新只依赖当前经验(s,a,r,s’)，所以行为策略只需要提供足够多样的数据，不要求它和目标策略一致</p><p>Ans:无法与真实环境交互，如何训练目标策略<br>Ques: Simulator和Batch RL<br>Simulator: 强化学习中的一个环境，允许Agent在其中交互、收集数据并进行训练。<strong>适用于Online RL（在线强化学习）</strong>：算法可以随时与环境交互并收集数据（如 DQN、PPO）。<br>Batch RL：它仅使用一个固定的数据集来训练，而不会与环境交互。<strong>需要 Off-Policy 方法</strong>：由于数据可能来自多个不同的策略（而非当前策略），必须使用 <strong>Off-Policy RL</strong>（如 DQN、BCQ）</p><p>区分Q-learning和SARSA的Q值更新：<br>SARSA的Q值更新公式为：$Q(S_t,A_t) \leftarrow Q(S_t,A_t) + \alpha[R_{t+1}+\gamma Q(S_{t+1},A_{t+1})-Q(S_t,A_t)]$<br>Q-learning用的是下一状态的最优动作$max_{a’}Q(s’,a’)$来更新，属于Off-Policy。SARSA用的是实际选到的下一动作$A_{t+1}$来更新，属于On-Policy。</p><p>下面给出Q-Learning的伪代码：<br><img src="/../article_img/Reinforcement/img3-5.png" alt="Q-Learning Algorithm"></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p><img src="/../article_img/Reinforcement/img3-6.png" alt="Summary"></p>]]></content>
    
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Algorithm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Lora Adapter调试跟踪</title>
    <link href="/2025/03/11/Lora%20Adapter%E8%B0%83%E8%AF%95%E8%B7%9F%E8%B8%AA/"/>
    <url>/2025/03/11/Lora%20Adapter%E8%B0%83%E8%AF%95%E8%B7%9F%E8%B8%AA/</url>
    
    <content type="html"><![CDATA[<p>打算花点时间看看在peft库中lora是怎么注入base model的，这里简单总结下：</p><p>首先写个测试程序：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> LoraModel, LoraConfig<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer<br><br><br>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&#x27;meta-llama/Llama-2-7b-hf&#x27;</span>, torch_dtype=torch.float16, device_map=<span class="hljs-string">&quot;cuda&quot;</span>)<br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&#x27;meta-llama/Llama-2-7b-hf&#x27;</span>)<br>tokenizer.pad_token = tokenizer.eos_token<br>lora_config = LoraConfig(<br>    r=<span class="hljs-number">32</span>,<br>    lora_alpha=<span class="hljs-number">16</span>,<br>    target_modules=[<span class="hljs-string">&quot;gate_proj&quot;</span>,<span class="hljs-string">&quot;up_proj&quot;</span>,<span class="hljs-string">&quot;q_proj&quot;</span>,<span class="hljs-string">&quot;down_proj&quot;</span>,<span class="hljs-string">&quot;o_proj&quot;</span>,<span class="hljs-string">&quot;k_proj&quot;</span>,<span class="hljs-string">&quot;v_proj&quot;</span>],<br>    lora_dropout=<span class="hljs-number">0.05</span>,<br>    bias=<span class="hljs-string">&quot;none&quot;</span>,<br>    task_type=<span class="hljs-string">&quot;CAUSAL_LM&quot;</span>,<br>)<br><br>model = LoraModel(model, lora_config, <span class="hljs-string">&quot;default&quot;</span>) <span class="hljs-comment"># 在这里打个断点</span><br>model.print_trainable_parameters()<br><span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> model.named_parameters():<br>    <span class="hljs-built_in">print</span>(name, param)<br></code></pre></td></tr></table></figure><p>跟进去调试，LoraModel是基于BaseTuner类实现的子类，BaseTuner的init函数中有一个inject_adapter方法，该方法实现了如何将lora中的target module与base model中的module进行替换</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">elf.active_adapter: <span class="hljs-built_in">str</span> | <span class="hljs-built_in">list</span>[<span class="hljs-built_in">str</span>] = adapter_name<br><span class="hljs-variable language_">self</span>._pre_injection_hook(<span class="hljs-variable language_">self</span>.model, <span class="hljs-variable language_">self</span>.peft_config[adapter_name], adapter_name)<br><span class="hljs-keyword">if</span> peft_config != PeftType.XLORA <span class="hljs-keyword">or</span> peft_config[adapter_name] != PeftType.XLORA:<br>    <span class="hljs-variable language_">self</span>.inject_adapter(<span class="hljs-variable language_">self</span>.model, adapter_name, low_cpu_mem_usage=low_cpu_mem_usage)<br></code></pre></td></tr></table></figure><p>跟进inject_adapter,它首先会收集base model的所有named modules组成一个key list，然后进入循环，如果key在peft_config中定义的target_modules中，则调用_create_and_replace方法（@abstractmethod），该方法在子类中进行实现。下面重点介绍下该方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_create_and_replace</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        lora_config,</span><br><span class="hljs-params">        adapter_name,</span><br><span class="hljs-params">        target,</span><br><span class="hljs-params">        target_name,</span><br><span class="hljs-params">        parent,</span><br><span class="hljs-params">        current_key,</span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-keyword">if</span> current_key <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;Current Key shouldn&#x27;t be `None`&quot;</span>)<br><br>        <span class="hljs-comment"># Regexp matching - Find key which matches current target_name in patterns provided</span><br>        pattern_keys = <span class="hljs-built_in">list</span>(chain(lora_config.rank_pattern.keys(), lora_config.alpha_pattern.keys()))<br>        target_name_key = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> key: re.<span class="hljs-keyword">match</span>(<span class="hljs-string">rf&quot;.*\.<span class="hljs-subst">&#123;key&#125;</span>$&quot;</span>, current_key), pattern_keys), current_key)<br>        r = lora_config.rank_pattern.get(target_name_key, lora_config.r)<br>        alpha = lora_config.alpha_pattern.get(target_name_key, lora_config.lora_alpha)<br><br>        kwargs = &#123;<br>            <span class="hljs-string">&quot;r&quot;</span>: r,<br>            <span class="hljs-string">&quot;lora_alpha&quot;</span>: alpha,<br>            <span class="hljs-string">&quot;lora_dropout&quot;</span>: lora_config.lora_dropout,<br>            <span class="hljs-string">&quot;fan_in_fan_out&quot;</span>: lora_config.fan_in_fan_out,<br>            <span class="hljs-string">&quot;init_lora_weights&quot;</span>: lora_config.init_lora_weights,<br>            <span class="hljs-string">&quot;use_rslora&quot;</span>: lora_config.use_rslora,<br>            <span class="hljs-string">&quot;use_dora&quot;</span>: lora_config.use_dora,<br>            <span class="hljs-string">&quot;ephemeral_gpu_offload&quot;</span>: lora_config.runtime_config.ephemeral_gpu_offload,<br>            <span class="hljs-string">&quot;loaded_in_8bit&quot;</span>: <span class="hljs-built_in">getattr</span>(<span class="hljs-variable language_">self</span>.model, <span class="hljs-string">&quot;is_loaded_in_8bit&quot;</span>, <span class="hljs-literal">False</span>),<br>            <span class="hljs-string">&quot;loaded_in_4bit&quot;</span>: <span class="hljs-built_in">getattr</span>(<span class="hljs-variable language_">self</span>.model, <span class="hljs-string">&quot;is_loaded_in_4bit&quot;</span>, <span class="hljs-literal">False</span>),<br>        &#125;<br><br>        quant_methods = [<span class="hljs-string">&quot;gptq&quot;</span>, <span class="hljs-string">&quot;aqlm&quot;</span>, <span class="hljs-string">&quot;awq&quot;</span>]<br>        <span class="hljs-keyword">for</span> quant_method <span class="hljs-keyword">in</span> quant_methods:<br>            quantization_config = get_quantization_config(<span class="hljs-variable language_">self</span>.model, method=quant_method)<br>            <span class="hljs-keyword">if</span> quantization_config <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                kwargs[<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;quant_method&#125;</span>_quantization_config&quot;</span>] = quantization_config<br><br>        <span class="hljs-comment"># note: AdaLoraLayer is a subclass of LoraLayer, we need to exclude it</span><br>        <span class="hljs-keyword">from</span> peft.tuners.adalora <span class="hljs-keyword">import</span> AdaLoraLayer<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(target, LoraLayer) <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(target, AdaLoraLayer):<br>            target.update_layer(<br>                adapter_name,<br>                r,<br>                lora_alpha=alpha,<br>                lora_dropout=lora_config.lora_dropout,<br>                init_lora_weights=lora_config.init_lora_weights,<br>                use_rslora=lora_config.use_rslora,<br>                use_dora=lora_config.use_dora,<br>            )<br>        <span class="hljs-keyword">else</span>:<br>            new_module = <span class="hljs-variable language_">self</span>._create_new_module(lora_config, adapter_name, target, **kwargs)<br>            <span class="hljs-keyword">if</span> adapter_name <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.active_adapters:<br>                <span class="hljs-comment"># adding an additional adapter: it is not automatically trainable</span><br>                new_module.requires_grad_(<span class="hljs-literal">False</span>)<br>            <span class="hljs-variable language_">self</span>._replace_module(parent, target_name, new_module, target)<br></code></pre></td></tr></table></figure><p>kwargs为构造Lora层所必需的参数，此外这里还检查了base model是否已经被8 bit or 4 bit量化，以防止不兼容的操作。然后判断target是都已经是一个LoraLayer：<strong>如果 <code>target</code> 已经是一个 LoRA 层</strong>（<code>LoraLayer</code>），则 <strong>更新</strong> 其参数（如 <code>r</code>、<code>lora_alpha</code> 等）；<strong>如果 <code>target</code> 是 <code>AdaLoraLayer</code>，则跳过</strong>，因为 AdaLoRA 有自己的适配逻辑；否则，创建新的 LoRA 层并替换目标层。self._replace_module用于 将 <code>parent</code> 中的 <code>target_name</code> 层替换为 <code>new_module</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_replace_module</span>(<span class="hljs-params">self, parent, child_name, new_module, child</span>):<br>        <span class="hljs-built_in">setattr</span>(parent, child_name, new_module)<br>        <span class="hljs-comment"># It&#x27;s not necessary to set requires_grad here, as that is handled by</span><br>        <span class="hljs-comment"># _mark_only_adapters_as_trainable</span><br><br>        <span class="hljs-comment"># child layer wraps the original module, unpack it</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(child, <span class="hljs-string">&quot;base_layer&quot;</span>):<br>            child = child.base_layer<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">hasattr</span>(new_module, <span class="hljs-string">&quot;base_layer&quot;</span>):<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(new_module, <span class="hljs-string">&quot;W_q&quot;</span>):  <span class="hljs-comment"># HQQ</span><br>                new_module.W_q = child.W_q<br>            <span class="hljs-keyword">else</span>:<br>                new_module.weight = child.weight<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(child, <span class="hljs-string">&quot;bias&quot;</span>):<br>                new_module.bias = child.bias<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">getattr</span>(child, <span class="hljs-string">&quot;state&quot;</span>, <span class="hljs-literal">None</span>) <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(new_module, <span class="hljs-string">&quot;base_layer&quot;</span>):<br>                new_module.base_layer.state = child.state<br>            <span class="hljs-keyword">else</span>:<br>                new_module.state = child.state<br>            new_module.to(child.weight.device)<br><br>        meta = torch.device(<span class="hljs-string">&quot;meta&quot;</span>)<br>        <span class="hljs-comment"># dispatch to correct device</span><br>        <span class="hljs-keyword">for</span> name, module <span class="hljs-keyword">in</span> new_module.named_modules():<br>            <span class="hljs-keyword">if</span> (<span class="hljs-variable language_">self</span>.prefix <span class="hljs-keyword">in</span> name) <span class="hljs-keyword">or</span> (<span class="hljs-string">&quot;ranknum&quot;</span> <span class="hljs-keyword">in</span> name):<br>                weight = (<br>                    child.qweight<br>                    <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(child, <span class="hljs-string">&quot;qweight&quot;</span>)<br>                    <span class="hljs-keyword">else</span> child.W_q<br>                    <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(child, <span class="hljs-string">&quot;W_q&quot;</span>)<br>                    <span class="hljs-keyword">else</span> child.weight<br>                    <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(child, <span class="hljs-string">&quot;weight&quot;</span>)<br>                    <span class="hljs-keyword">else</span> <span class="hljs-built_in">next</span>(child.parameters())<br>                )<br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">any</span>(p.device == meta <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> module.parameters()):<br>                    module.to(weight.device)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Code</tag>
      
      <tag>debug</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>强化学习系列（二）：Model-free Prediction</title>
    <link href="/2025/03/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <url>/2025/03/08/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p>写在前面: Prediction任务是用来在给定策略$\pi$的前提下，基于价值函数和奖励函数来评估该策略的好坏。Control任务用来对策略进行提升和改进。根据是否已知状态转移矩阵(MDP transition)分为Model-Based Prediction和Model-free Prediction</p><span id="more"></span><h3 id="Model-Based-Prediction-Control"><a href="#Model-Based-Prediction-Control" class="headerlink" title="Model-Based Prediction&amp;Control"></a>Model-Based Prediction&amp;Control</h3><h4 id="1-Policy-Iteration"><a href="#1-Policy-Iteration" class="headerlink" title="1. Policy Iteration"></a>1. Policy Iteration</h4><p>策略迭代（Policy Iteration）是一种用于求解马尔可夫决策过程（MDP）的动态规划算法。它主要用于寻找最优策略，即在给定MDP的情况下，使得累计奖励最大的策略。<br>step: （1）<strong>策略评估（Policy Evaluation）</strong> Prediction Phase<br>在当前策略$\pi$下，计算所有状态s的状态函数$V^{\pi}(s)$, $V^{\pi}(s)&#x3D;\sum_{a}\pi(a|s)[R_s^a +\gamma \sum_{s’}P_{ss’}^a V^\pi(s’)]$<br>(2) <strong>策略改进（Policy Improvement）</strong> Control Phase<br>利用贪心策略来改进当前策略：$\pi’&#x3D;greedy(\pi)$<br>具体来说，对于每个状态s，找到使得价值函数最大的动作a，从而得到最优策略$\pi*$<br>$\pi*(s)&#x3D;argmax_a\sum_{s’}P_{ss’}^a[R_s^a + \gamma V^\pi(s’)]$</p><h4 id="2-Value-Iteration"><a href="#2-Value-Iteration" class="headerlink" title="2. Value Iteration"></a>2. Value Iteration</h4><p>价值迭代（Value Iteration）在更新状态时并不涉及策略$\pi$，它将根据最大的动作奖励与转移后的状态价值之和所对应的那个动作作为新的策略。即$V_{k+1}(s)&#x3D;max_{a \in A}(R_s^a + \gamma \sum_{s’ \in S}P_{ss’}^a V_k(s’))$<br>下面给出Policy Iteration和Value Iteration的对比：</p><table><thead><tr><th><strong>特点</strong></th><th><strong>Value Iteration (值迭代)</strong></th><th><strong>Policy Iteration (策略迭代)</strong></th></tr></thead><tbody><tr><td><strong>思路</strong></td><td>直接迭代更新值函数直到收敛，再提取最优策略</td><td>交替执行策略评估和策略改进，不断迭代优化策略</td></tr><tr><td><strong>主要步骤</strong></td><td>1. 更新值函数 → 2. 提取策略</td><td>1. 策略评估 → 2. 策略改进 → 3. 重复直到策略收敛</td></tr><tr><td><strong>收敛条件</strong></td><td>值函数变化足够小 (</td><td>V_{k+1} - V_k</td></tr><tr><td><strong>策略提取时机</strong></td><td>最后一步提取最优策略</td><td>每轮策略改进都会更新策略</td></tr><tr><td><strong>计算量</strong></td><td>更新每个状态时都考虑所有动作（计算量大但收敛快）</td><td>每次完整评估策略再改进策略，可能需要多次评估，但改进次数较少</td></tr><tr><td><strong>策略更新</strong></td><td>从值函数提取策略（离线策略）</td><td>每次改进立即生成新策略（在线策略）</td></tr></tbody></table><h3 id="Model-Free-Prediction"><a href="#Model-Free-Prediction" class="headerlink" title="Model-Free Prediction"></a>Model-Free Prediction</h3><h4 id="1-Monte-Carlo-Reinforcement-Learning"><a href="#1-Monte-Carlo-Reinforcement-Learning" class="headerlink" title="1. Monte-Carlo Reinforcement Learning"></a>1. Monte-Carlo Reinforcement Learning</h4><p>特点：no bootstrapping(bootstrapping是指用现有的估计值来更新当前的估计值)，即不依赖未来状态的估计值，每次只用真实的经验回报来更新策略。<br>bootstrapping（Q-learning、SARSA）: 更新值依赖于未来状态的估计值<br>$Q(s,a) \leftarrow Q(s,a) + \alpha(r + \gamma Q(s’,a’) -Q(s,a))$   这里的Q(s’,a’)就是对未来的估计值<br>no bootstrapping(Monte Carlo): 完全基于真实的完整回报𝐺更新，不依赖未来状态的估计<br>$Q(s,a) \leftarrow Q(s,a) + \alpha(G-Q(s,a))$ 其中$G&#x3D;\sum_{t’&#x3D;t}^T \gamma^{t’-t}r_{t’}$</p><table><thead><tr><th><strong>特性</strong></th><th><strong>No Bootstrapping</strong></th><th><strong>Bootstrapping</strong></th></tr></thead><tbody><tr><td><strong>代表算法</strong></td><td>Monte Carlo, REINFORCE</td><td>Q-learning, SARSA, TD(0)</td></tr><tr><td><strong>更新依赖</strong></td><td>完整回报</td><td>未来状态的估计值</td></tr><tr><td><strong>误差来源</strong></td><td>高方差</td><td>有偏差（因依赖估计值）</td></tr><tr><td><strong>收敛速度</strong></td><td>慢（方差大、数据需求多）</td><td>快（但可能收敛到次优解）</td></tr><tr><td><strong>实时性</strong></td><td>必须等完整轨迹结束才更新</td><td>可以在线更新，每一步都能调整</td></tr></tbody></table><p>step: 为了估计状态s，每一次采样路径经过状态s时，$N(s) \leftarrow N(s)+1$,同时增加累积回报 $S(s) \leftarrow S(s) + G_t$。最终，采用平均估计的方式得到状态价值V(s)&#x3D;S(s)&#x2F;N(s)。接下来更新策略$V(s) \leftarrow V_{\pi}(s)$，直到$N(s) \leftarrow \infty$</p><p>根据$\mu_k &#x3D; \frac{1}{k}\sum_{j&#x3D;1}^k x_j&#x3D;\mu_{k-1}+\frac{1}{k}(x_k-\mu_{k-1})$<br>$V(S_t) \leftarrow V(S_t) + \frac{1}{N(S_t)}(G_t -V(S_t))$<br>通常情况下，我们将这里的$\frac{1}{N(S_t)}$替换为折损因子\alpha，即$V(S_t) \leftarrow V(S_t) + \alpha(G_t -V(S_t))$</p><h4 id="2-Temporal-Difference-Learning"><a href="#2-Temporal-Difference-Learning" class="headerlink" title="2. Temporal Difference Learning"></a>2. Temporal Difference Learning</h4><p>利用Bellman方程的方式来泛化估计$G_t$，即$V(S_t) \leftarrow V(S_t) + \alpha(R_{t+1} + \gamma V(S_{t+1})-V(S_t))$<br>其中$R_{t+1} + \gamma V(S_{t+1})$为TD Target, $\delta_t&#x3D;R_{t+1} + \gamma V(S_{t+1}) - V(S_t)$为TD Error</p><table><thead><tr><th><strong>特性</strong></th><th><strong>TD Learning</strong></th><th><strong>Monte Carlo (MC)</strong></th></tr></thead><tbody><tr><td><strong>更新时机</strong></td><td>每一步更新（在线学习）</td><td>完整轨迹结束后再更新</td></tr><tr><td><strong>回报估计</strong></td><td>依赖当前经验 + 未来估计值（bootstrapping）</td><td>依赖完整回报（no bootstrapping）</td></tr><tr><td><strong>偏差 vs. 方差</strong></td><td>有偏但方差小（因为估计依赖未来状态的值）</td><td>无偏但方差大（因为回报波动大）</td></tr><tr><td><strong>收敛速度</strong></td><td>快，能更快调整值函数</td><td>慢，因为要等待完整回报</td></tr><tr><td><strong>适用场景</strong></td><td>适用于连续或在线任务</td><td>适用于回合式任务（如游戏）</td></tr></tbody></table><h4 id="3-N-Step-Prediction-TD-Learning的变体"><a href="#3-N-Step-Prediction-TD-Learning的变体" class="headerlink" title="3. N-Step Prediction(TD Learning的变体)"></a>3. N-Step Prediction(TD Learning的变体)</h4><p>将TD target设定为未来n步的奖励和转移状态期望，相当于TD和MC的折中,迭代n步再更新<br>Consider the following n-step returns for n&#x3D;1,2…,\infty<br>n&#x3D;1 (TD) $G_t^{(1)}&#x3D;R_{t+1}+\gamma V(S_{t+1})$<br>n&#x3D;2 (2-Step) $G_t^{(2)}&#x3D;R_{t+1}+\gamma R_{t+2} + \gamma^2 V(S_{t+2})$<br>… … …<br>n&#x3D;\infty (MC) $G_t^\infty&#x3D;R_{t+1}+\gamma R_{t+2} + … + \gamma^{T-1}R_T$<br>因此，对于n-step temporal-difference learning: $V(S_t) \leftarrow V(S_t) + \alpha(G_t^{(n)}-V(S_t))$</p><h4 id="4-Lamda-Return-N-Step-Prediction的变体"><a href="#4-Lamda-Return-N-Step-Prediction的变体" class="headerlink" title="4. Lamda Return(N-Step Prediction的变体)"></a>4. Lamda Return(N-Step Prediction的变体)</h4><p>考虑了短步回报和长步回报的不同收益： $G_t^\lambda&#x3D; (1-\lambda)\sum_{n&#x3D;1}^\infty \lambda^{n-1}G_t^{(n)}$<br>$V(S_t) \leftarrow V(S_t) + \alpha (G_t^\lambda- V(S_t))$<br>λ 越小，更依赖当前的 TD 估计，快速调整但可能抖动大; λ 越大，更依赖长时间的回报，稳定但更新慢</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>Monte Carlo Backup<br><img src="/../article_img/Reinforcement/img2-1.png" alt="Monte Carlo Backup"><br>Temporal-Difference Backup<br><img src="/../article_img/Reinforcement/img2-2.png" alt="Temporal-Difference Backup"><br>Dynamic Programming Backup(Policy&#x2F;Value Iteration)<br><img src="/../article_img/Reinforcement/img2-3.png" alt="Dynamic Programming Backup"></p>]]></content>
    
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Algorithm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>强化学习系列（一）:基础概念</title>
    <link href="/2025/03/05/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <url>/2025/03/05/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h2 id="三要素："><a href="#三要素：" class="headerlink" title="三要素："></a>三要素：</h2><p><strong>rewards, actions, states</strong><br><img src="/article_img/Reinforcement/img1-1.png" alt="RL framework"></p><h2 id="马尔可夫奖励过程："><a href="#马尔可夫奖励过程：" class="headerlink" title="马尔可夫奖励过程："></a>马尔可夫奖励过程：</h2><p>马尔可夫奖励过程可以表示为 $&lt;S,P,R,\gamma&gt;$，其中：</p><ul><li>$S$ 为状态集合；</li><li>$P$ 为状态转移矩阵，$P_{ss’}&#x3D;P[S_{t+1}&#x3D;s’|S_t&#x3D;s]$；</li><li>$R$ 为奖励函数，$R_s&#x3D;E[R_{t+1}|S_t&#x3D;s]$；</li><li>$\gamma$ 为折扣因子，$\gamma \in [0,1]$。</li></ul><h3 id="总折扣奖励："><a href="#总折扣奖励：" class="headerlink" title="总折扣奖励："></a>总折扣奖励：</h3><p>回报（Return）$G_t$ 表示从时刻 $t$ 开始的总折扣奖励：<br>$$<br>G_t&#x3D;R_{t+1}+\gamma R_{t+2}+…&#x3D;\sum_{k&#x3D;0}^\infty \gamma^k R_{t+k+1}<br>$$</p><ul><li><strong>状态价值函数</strong>：$v(s)&#x3D;E[G_t|S_t&#x3D;s]$  </li><li><strong>行为价值函数</strong>：$q(s,a)&#x3D;E[G_t|S_t&#x3D;s,A_t&#x3D;a]$</li></ul><h2 id="Bellman-方程："><a href="#Bellman-方程：" class="headerlink" title="Bellman 方程："></a>Bellman 方程：</h2><p>Bellman 方程表示状态价值函数的递归形式：<br>$$<br>v(s)&#x3D;E[G_t|S_t&#x3D;s]&#x3D;E[R_{t+1}+\gamma R_{t+2}+…|S_t&#x3D;s]&#x3D;E[R_{t+1}+\gamma G_{t+1}|S_t&#x3D;s]&#x3D;E[R_{t+1}+\gamma v(S_{t+1})|S_t&#x3D;s]<br>$$</p><p>根据下方的<strong>状态价值迭代示意图</strong>，我们可以得到：<br>$$<br>v(s)&#x3D;R_s + \gamma \sum_{s’ \in S}P_{ss’}v(s’)<br>$$<br><img src="/article_img/Reinforcement/img1-2.png" alt="状态价值迭代示意图"></p><p>根据<strong>行为价值迭代示意图</strong>，可以得到：<br>$$<br>q(s,a)&#x3D;R_s^a + \gamma \sum_{s’ \in S}P_{ss’}^a v(s’)<br>$$<br><img src="/article_img/Reinforcement/img1-3.png" alt="行为价值迭代示意图"></p><h2 id="马尔可夫决策过程："><a href="#马尔可夫决策过程：" class="headerlink" title="马尔可夫决策过程："></a>马尔可夫决策过程：</h2><p>马尔可夫决策过程（MDP）表示为 $&lt;S,A,P,R,\gamma&gt;$，其中：</p><ul><li>$S$ 是状态集合；</li><li>$A$ 为动作集合；</li><li>$P$ 为状态转移矩阵，$P_{ss’}^a&#x3D;P[S_{t+1}&#x3D;s’|S_t&#x3D;s, A_t&#x3D;a]$；</li><li>$R$ 为奖励函数，$R_s^a&#x3D;E[R_{t+1}|S_t&#x3D;s, A_t&#x3D;a]$。</li></ul><p>状态的转移基于决策策略（policy）$\pi$ 所产生的动作，$\pi$ 用来基于当前状态给出下一步行动的规划：<br>$$<br>\pi(a|s)&#x3D;P[A_t&#x3D;a|S_t&#x3D;s]<br>$$</p><h3 id="价值函数："><a href="#价值函数：" class="headerlink" title="价值函数："></a>价值函数：</h3><p>由此，我们可以定义策略 $\pi$ 下的状态价值函数和行为价值函数：<br>$$<br>v_{\pi}(s)&#x3D;E_{\pi}[G_t|S_t&#x3D;s]<br>$$<br>$$<br>q_{\pi}(s,a)&#x3D;E_{\pi}[G_t|S_t&#x3D;s, A_t&#x3D;a]<br>$$</p><p>使用即时奖励的形式，可以转换为：<br>$$<br>v_{\pi}(s)&#x3D;E_{\pi}[R_{t+1}+\gamma v_{\pi}(S_{t+1})|S_t&#x3D;s]<br>$$<br>$$<br>q_{\pi}(s,a)&#x3D;E_{\pi}[R_{t+1}+\gamma q_{\pi}(S_{t+1},A_{t+1})|S_t&#x3D;s, A_t&#x3D;a]<br>$$</p><h3 id="最优价值函数："><a href="#最优价值函数：" class="headerlink" title="最优价值函数："></a>最优价值函数：</h3><p>$$<br>v_*(s)&#x3D;\max_{\pi}v_{\pi}(s)<br>$$<br>$$<br>q_*(s,a)&#x3D;\max_{\pi}q_{\pi}(s,a)<br>$$</p><p><strong>定理</strong>：如果对于任意的状态 $s$，都有 $v_{\pi}(s) \geq v_{\pi’}(s)$，则策略 $\pi$ 优于策略 $\pi’$。</p><h2 id="Q-A："><a href="#Q-A：" class="headerlink" title="Q&amp;A："></a>Q&amp;A：</h2><p><strong>Ques：</strong> 奖励是由状态变化产生的还是由行动产生的？<br><strong>Ans：</strong> 奖励（Reward）通常是由 <strong>行动（Action）</strong> 产生的，而不是由状态变化直接产生的。在强化学习（RL）中，奖励的定义是智能体（Agent）在环境（Environment）中执行某个 <strong>动作</strong> 后得到的反馈，它表示智能体在采取该动作后获得的即时回报。状态变化是行为导致的结果。</p>]]></content>
    
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Algorithm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Solidity智能合约</title>
    <link href="/2025/03/01/FundMe/"/>
    <url>/2025/03/01/FundMe/</url>
    
    <content type="html"><![CDATA[<h3 id="安装Remix-ide"><a href="#安装Remix-ide" class="headerlink" title="安装Remix-ide"></a>安装Remix-ide</h3><p>先排个雷，目前官方提供的remix-ide desktop版能安装，但是跑不起来，我在github release列表下了latest version,启动后就是漫长的白屏，网上给的解释是需要修改代理ping通github，但是我这边是能ping通的，多次尝试无果后我选择使用Remix-Ethereum IDE + 本地 remixd。remixd是Remix IDE提供的一个辅助工具，主要用于 Solidity 智能合约开发时，让本地文件系统和 Remix Web IDE 之间建立连接。<br>安装方式：npm install -g @remix-project&#x2F;remixd<br>启动命令：remixd -s .&#x2F; –remix-ide <a href="https://remix.ethereum.org/">https://remix.ethereum.org</a></p><h3 id="vscode-solc"><a href="#vscode-solc" class="headerlink" title="vscode + solc"></a>vscode + solc</h3><p>需要在vscode中安装solidity插件，另外也可安装remix-light插件用于轻量化编译、部署。使用solidity插件对sol编译的方式是右键选择Solidity：Compile Contract。如果编译器版本不匹配的话，solidity插件支持三种不同的更换版本方式：<br>（1）远程下载: 使用远程版本进行编译，需要更改solidity setting中的solidity.compileUsingRemoteVersion，设置为相应的版本号<br>（2）使用本地文件：更改solidity setting中的solidity.compileUsingLocalVersion，设置为solc文件本地路径<br>（3）Npm&#x2F;节点安装：可以在solidity项目文件夹中本地安装solc（npm install solc）<br>优先顺序：首先使用npm&#x2F;节点安装，然后使用本地文件，最后使用远程</p><p>Ques: 简述Solidity的编译和部署都干了什么事儿<br>Ans：Solidity的编译是将人类可读的智能合约代码转化成EVM（以太坊虚拟机）能理解的字节码；Solidity部署是将合约代码正式发布到区块链上，从而拥有独立的地址（合约地址），用来管理资产，支持收款与支付</p><h3 id="区块链交易明细"><a href="#区块链交易明细" class="headerlink" title="区块链交易明细"></a>区块链交易明细</h3><ul><li>交易哈希（Transaction Hash）：这个是在这个区块链上这笔交易的唯一ID，这个交易哈希标识了发送了0.25个以太币到我们的地址的操作。</li><li>状态（Status）：我们可以看到交易状态是成功的，它没有因某种情况而失败。</li><li>区块（Block）：我们可以看到这个交易所在的区块高度。</li><li>时间戳（Timestamp）：这里是时间戳，代表这个交易是何时发生的。</li><li>发送者（From）：我们可以看到这个交易是由谁发送的，当然我们可以在新的标签页打开它，你就能看到发送交易的账户信息。</li><li>接受者（To）：接受了交易的用户，这里就是我们自己。</li><li>价值（Value）：交易的资产价值是0.25个以太币。</li><li>交易手续费（Transaction Fee）：交易的手续费，付给矿工处理这笔交易的费用。</li><li>Gas价格（Gas Price）：Gas的价格，Gas价格是交易中每个执行单元的花费（用ether和gwei做单位），Gas价格越高，被写到区块中的机会越大。</li></ul><h3 id="区分ETH代币和Link代币"><a href="#区分ETH代币和Link代币" class="headerlink" title="区分ETH代币和Link代币"></a>区分ETH代币和Link代币</h3><p>Link代币的功能：</p><ul><li>支付数据服务费：用 LINK 代币支付获取链下数据的费用，比如价格、天气等</li><li>节点质押担保：节点需要质押 LINK 作为担保，作恶会被罚掉</li><li>节点奖励激励：节点提供高质量数据，获得 LINK 奖励</li><li>跨链数据传输费：用于支付跨链数据通信的成本，比如在不同链之间同步信息</li><li>DeFi 抵押品：在一些 DeFi 协议中可以作为抵押品，借贷稳定币等<br>下面是Eth的代币和Link代币的对比总结：<table><thead><tr><th><strong>特点</strong></th><th><strong>ETH（以太坊）</strong></th><th><strong>LINK（Chainlink）</strong></th></tr></thead><tbody><tr><td><strong>项目类型</strong></td><td>智能合约平台</td><td>去中心化预言机网络</td></tr><tr><td><strong>代币功能</strong></td><td>支付交易费、质押、DApp</td><td>支付节点费用、质押、奖励</td></tr><tr><td><strong>技术层级</strong></td><td>Layer 1 主链</td><td>ERC-20 代币（基于以太坊）</td></tr><tr><td><strong>市场定位</strong></td><td>“区块链燃料”、平台代币</td><td>“数据桥梁”、预言机领域龙头</td></tr><tr><td><strong>代表场景</strong></td><td>DeFi、NFT、DAO、Staking</td><td>数据喂价、跨链数据传输</td></tr></tbody></table></li></ul><h3 id="编写FundMe代码在链上筹款"><a href="#编写FundMe代码在链上筹款" class="headerlink" title="编写FundMe代码在链上筹款"></a>编写FundMe代码在链上筹款</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs solidity">// Get funds from users<br>// Withdraw funds<br>// Set a minimum funding value in ETH<br><br>// SPDX-License-Identifier: MIT<br>pragma solidity ^0.8.22;<br><br>contract FundMe &#123;<br><br>    uint256 public minimumETH = 0.01 * 1e18; // 1 * 10 ** 18<br><br>    address[] public funders;<br>    mapping(address =&gt; uint256) public addressToAmountFunded;<br>    <br>    function fund() public payable &#123;<br>        // Want to be able to set a minimum fund amount in currency<br>        // 1. How do we send ETH to this contract?<br>        require(msg.value &gt;= minimumETH, &quot;Didn&#x27;t send enough!&quot;);<br>        funders.push(msg.sender);<br>        addressToAmountFunded[msg.sender] = msg.value;<br>    &#125;<br><br>    function withdraw() public &#123;<br>        /* starting index, ending index, step amount */<br>        for (uint256 funderIndex = 0; funderIndex &lt; funders.length; funderIndex++) &#123;<br>            // code<br>            address funder = funders[funderIndex];<br>            addressToAmountFunded[funder] = 0;<br>        &#125;<br>        // resret the array<br>        funders = new address[](0);<br>        (bool callSuccess, ) =  payable(msg.sender).call&#123;value: address(this).balance&#125;(&quot;&quot;);<br>        require(callSuccess, &quot;Call failed&quot;);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Web3</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>区块链入门指南</title>
    <link href="/2025/03/01/Web3/"/>
    <url>/2025/03/01/Web3/</url>
    
    <content type="html"><![CDATA[<h1 id="区块链与加密货币入门指南"><a href="#区块链与加密货币入门指南" class="headerlink" title="区块链与加密货币入门指南"></a>区块链与加密货币入门指南</h1><h2 id="基础篇：区块链与加密货币基础"><a href="#基础篇：区块链与加密货币基础" class="headerlink" title="基础篇：区块链与加密货币基础"></a>基础篇：区块链与加密货币基础</h2><h3 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h3><ul><li>理解区块链基本原理</li><li>掌握加密货币基础知识</li><li>了解DeFi生态系统</li><li>尝试链上交互</li></ul><h3 id="核心学习资源"><a href="#核心学习资源" class="headerlink" title="核心学习资源"></a>核心学习资源</h3><h3 id="1-入门"><a href="#1-入门" class="headerlink" title="1. 入门"></a>1. 入门</h3><ul><li><strong>视频教程</strong>: <a href="https://www.youtube.com/watch?v=bBC-nXj3Ng4">3Blue1Brown的”比特币和区块链是如何工作的”</a> - 通过可视化方式解释区块链的基本原理</li><li><strong>在线课程</strong>: <a href="https://www.coursera.org/learn/blockchain-basics">Coursera - 区块链基础知识</a> &amp; <a href="https://space.bilibili.com/586660955/lists/894352">PKU学生区块链中心WEB3新人公开课</a></li><li><strong>书籍</strong>: 《精通比特币》(Mastering Bitcoin) - Andreas Antonopoulos著</li><li><strong>指南</strong>: <a href="https://yeasy.gitbook.io/blockchain_guide/">区块链技术指南</a> - 完整的中文区块链入门资料</li><li><a href="https://www.youtube.com/watch?v=HNDkNXD0m20">DeFi 工具扫盲</a></li></ul><h3 id="2-白皮书"><a href="#2-白皮书" class="headerlink" title="2. 白皮书"></a>2. 白皮书</h3><ul><li><strong>官方文档</strong>: <a href="https://bitcoin.org/bitcoin.pdf">比特币白皮书</a> - 了解比特币的设计理念</li><li><strong>视频：</strong><a href="https://www.youtube.com/c/WhiteboardCrypto">Whiteboard Crypto</a> - 简化的加密货币教学</li></ul><h3 id="4-实践项目"><a href="#4-实践项目" class="headerlink" title="4. 实践项目"></a>4. 实践项目</h3><ol><li><strong>创建和管理加密钱包</strong><ul><li>OKX 钱包  &#x2F; Metamask &#x2F; …</li><li>学习私钥管理和安全</li><li>在测试网络获取测试代币</li></ul></li><li><strong>体验基本的区块链交互</strong><ul><li>在测试网络上发送交易</li><li>使用区块浏览器如<a href="https://etherscan.io/">Etherscan</a>查看交易</li><li>参与简单的代币交换(使用Uniswap测试网)</li></ul></li></ol><h2 id="进阶篇：智能合约与DeFi"><a href="#进阶篇：智能合约与DeFi" class="headerlink" title="进阶篇：智能合约与DeFi"></a>进阶篇：智能合约与DeFi</h2><h3 id="核心学习资源-1"><a href="#核心学习资源-1" class="headerlink" title="核心学习资源"></a>核心学习资源</h3><h3 id="1-智能合约开发"><a href="#1-智能合约开发" class="headerlink" title="1. 智能合约开发"></a>1. 智能合约开发</h3><h4 id="ETH"><a href="#ETH" class="headerlink" title="ETH"></a>ETH</h4><ul><li><a href="https://docs.soliditylang.org/">Solidity文档</a> - 智能合约的编程语言</li><li><strong>实践指南</strong>: <a href="https://cryptozombies.io/">CryptoZombies</a> - Solidity 互动式智能合约开发课程</li></ul><h4 id="Solana"><a href="#Solana" class="headerlink" title="Solana"></a>Solana</h4><ul><li>Solana 官方文档</li></ul><h3 id="2-DeFi协议解析"><a href="#2-DeFi协议解析" class="headerlink" title="2. DeFi协议解析"></a>2. DeFi协议解析</h3><ul><li><strong>Uniswap</strong>: <a href="https://docs.uniswap.org/">Uniswap文档</a> - 学习AMM原理</li><li><strong>Aave</strong>: <a href="https://docs.aave.com/developers/">Aave开发者文档</a> - 了解借贷协议</li><li><a href="https://www.youtube.com/c/Finematics">Finematics</a> - 专注DeFi教学的YouTube频道</li><li><a href="https://www.youtube.com/watch?v=HNDkNXD0m20">3D的频道中的各个协议</a></li></ul><h3 id="3-区块链数据分析"><a href="#3-区块链数据分析" class="headerlink" title="3. 区块链数据分析"></a>3. 区块链数据分析</h3><ul><li><strong>学习资源</strong>: <a href="https://github.com/SixdegreeLab/MasteringChainAnalytics">精通链上数据分析</a> - 从入门到高级的链上数据分析教程</li><li><strong>分析平台</strong>: <a href="https://dune.com/">Dune Analytics</a> - 区块链数据可视化平台</li></ul><h2 id="从零到无穷大"><a href="#从零到无穷大" class="headerlink" title="从零到无穷大"></a>从零到无穷大</h2><h3 id="核心学习资源-2"><a href="#核心学习资源-2" class="headerlink" title="核心学习资源"></a>核心学习资源</h3><h3 id="1-MEV"><a href="#1-MEV" class="headerlink" title="1. MEV"></a>1. MEV</h3><ul><li><a href="https://github.com/33357/smartcontract-apps">智能合约应用指南</a> 包含了常见的套利思路</li><li><a href="https://docs.flashbots.net/">Flashbots</a> - ETH 民主化 MEV</li></ul><h3 id="2-开源实现参考"><a href="#2-开源实现参考" class="headerlink" title="2. 开源实现参考"></a>2. 开源实现参考</h3><ul><li><a href="https://github.com/duckdegen/apebot">ApeBot</a> 已失效的 new listing snipper</li><li><a href="https://hummingbot.io/">Hummingbot</a></li></ul><h3 id="3-实践项目"><a href="#3-实践项目" class="headerlink" title="3. 实践项目"></a>3. 实践项目</h3><ol><li><strong>信息搜集</strong><ul><li>新闻爬取，新闻交易</li><li>社区情绪分析</li><li>市场热点收集与分析</li></ul></li><li><strong>链上数据</strong><ul><li>使用Dune Analytics创建DeFi数据看板</li><li>跟踪协议TVL、交易量等关键指标</li><li>实现简单的链上行为分析。老鼠仓（内幕交易），巨鲸检测。bot盈利、策略分析</li><li>套利机会检测、风险监控</li></ul></li><li><strong>链上套利</strong><ul><li><a href="https://github.com/33357/smartcontract-apps">智能合约应用指南</a> 涵盖了常见的套利思路，比较简略</li><li><a href="https://github.com/antaintan/uniswap-arbitrage-analysis">Uniswap套利分析</a> 经典实战案例分析</li></ul></li><li><strong>DeFi协议分析</strong><ul><li>分析Uniswap的智能合约代码</li><li>理解借贷协议的风险模型</li><li>研究流动性挖矿机制</li></ul></li><li><strong>MEV研究</strong><ul><li>检测和监控 MEV 行为</li></ul></li><li><strong>工具与资源</strong>:<ul><li><a href="https://www.tradingview.com/">TradingView</a></li><li>dune</li><li><a href="https://defillama.com/">DeFi Llama</a> - DeFi协议跟踪与分析</li><li><a href="https://messari.io/">Messari</a> - 同上</li><li>geckoterminal - DEX 数据查看器</li><li>solscan, etherscan …</li></ul></li></ol><h2 id="持续学习资源"><a href="#持续学习资源" class="headerlink" title="持续学习资源"></a>持续学习资源</h2><h3 id="新闻"><a href="#新闻" class="headerlink" title="新闻"></a>新闻</h3><ul><li><a href="https://www.theblock.co/">The Block</a> - 区块链新闻</li><li>推特<ul><li>AggrNews</li><li>BWENews (方程式新闻)</li><li>…</li></ul></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Web3</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>命名实体识别&amp;关系抽取 小结</title>
    <link href="/2025/02/21/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB&amp;%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%20%E5%B0%8F%E7%BB%93/"/>
    <url>/2025/02/21/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB&amp;%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%20%E5%B0%8F%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h4 id="BIO标记法"><a href="#BIO标记法" class="headerlink" title="BIO标记法"></a>BIO标记法</h4><p><strong>B-（Begin）</strong>：表示一个实体的<strong>开始</strong>（首个 token）。</p><p><strong>I-（Inside）</strong>：表示实体的<strong>内部</strong>（除首个 token 以外的部分）。</p><p><strong>O-（Outside）</strong>：表示<strong>非实体</strong>的 token。</p><p>例如：**”Apple Inc. is based in California.”</p><p>BIO 标注：</p><table><thead><tr><th>Token</th><th>BIO 标签</th></tr></thead><tbody><tr><td>Apple</td><td><strong>B-ORG</strong></td></tr><tr><td>Inc.</td><td><strong>I-ORG</strong></td></tr><tr><td>is</td><td><strong>O</strong></td></tr><tr><td>based</td><td><strong>O</strong></td></tr><tr><td>in</td><td><strong>O</strong></td></tr><tr><td>California</td><td><strong>B-LOC</strong></td></tr><tr><td>.</td><td><strong>O</strong></td></tr></tbody></table><p><strong>常见的实体类别</strong></p><table><thead><tr><th>实体类别</th><th>含义</th></tr></thead><tbody><tr><td><strong>PER</strong> (Person)</td><td>人名（例如：Elon Musk, Bill Gates）</td></tr><tr><td><strong>ORG</strong> (Organization)</td><td>组织名（例如：Apple, Google, NASA）</td></tr><tr><td><strong>LOC</strong> (Location)</td><td>地名（例如：California, Beijing, Paris）</td></tr><tr><td><strong>MISC</strong> (Miscellaneous)</td><td>其他（例如：品牌名、事件名等）</td></tr></tbody></table><p>在 <strong>NER 任务</strong> 中，BIO 标签常作为<strong>序列标注模型</strong>（如 BiLSTM-CRF、Transformer）训练的目标</p><p><strong>训练模型</strong></p><ul><li><strong>输入</strong>：Word Embeddings（如 BERT, GloVe）</li><li><strong>模型</strong>：BiLSTM + CRF &#x2F; Transformer</li><li><strong>输出</strong>：BIO 标注序列</li></ul><p><strong>预测新文本</strong></p><p>输入新文本后，模型预测对应的 BIO 标签，从而<strong>提取实体</strong>。</p><h4 id="RE-Relation-Extraction-训练集"><a href="#RE-Relation-Extraction-训练集" class="headerlink" title="RE(Relation Extraction)训练集"></a>RE(Relation Extraction)训练集</h4><p><strong>spo:</strong> subject-predicate-object 头实体-关系-尾实体</p><p><strong>训练集中的Predicate列表</strong></p><p>​{<br>      “O”: 0,<br>      “I”: 1,<br>      “注册资本”: 2,<br>      “作者”: 3,<br>      “所属专辑”: 4,<br>      “歌手”: 5,<br>      …<br>      “上映时间_@value”: 8,<br>      “上映时间_@area”: 9,<br>      …<br>​}</p><p>对于同一个S-P，句子中是可能存在多个不同的合法O的，那我们就需要使用两个或多个不同的S-P来对应这些不同的O。一种最常见的方法就是对P再进行细分。如上面示例中的“上映时间_@value”和”上映时间_@area“</p><p><strong>训练集中的spo列表</strong></p><p>​{<br>      “predicate”: [“empty”, “empty”, “注册资本”, “作者”, “所属专辑”, …],<br>      “subject_type”: [“empty”, “empty”, “企业”, “图书作品”, “歌曲”, …],<br>      “object_type”: [“empty”, “empty”, “Number”, “人物”, “音乐专辑”, …]<br>​}</p><p>前两个empty是为了O和I标签留的,因为之前定义的predicate列表中的前2个标签分别为O、I，这两个标签不会起到连接首尾实体的作用，因此需要置为empty。</p><h4 id="NER模型的训练原理"><a href="#NER模型的训练原理" class="headerlink" title="NER模型的训练原理"></a>NER模型的训练原理</h4><p>将实体抽取问题转化为Token Classfication问题。</p><p>Ques：如何实现关系抽取？ </p><p>Ans：在字符类别中添加入「关系标签」，即该字符是否能和这句话当中的其他字符产生关联关系。</p><p><img src="/article_img/NER/NER.png" alt="NER model"></p><p>对每个token，label一共有（2N + 2）维，其中 N 为 Predicate 的类别个数</p><p>损失函数一般使用BCE Loss</p>]]></content>
    
    
    
    <tags>
      
      <tag>NER</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Path-Level GNN-Based Retrievers</title>
    <link href="/2025/02/20/GraphRAG/"/>
    <url>/2025/02/20/GraphRAG/</url>
    
    <content type="html"><![CDATA[<p>1.<a href="https://arxiv.org/abs/2405.20139">GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning</a></p><p>开源代码：<a href="https://github.com/cmavro/GNN-RAG">https://github.com/cmavro/GNN-RAG</a></p><p>Motivation: 将GNN的推理能力和LLM的语言理解能力相结合用于知识图谱问答</p><p>Methodology：首先，GNN 对密集的 KG 子图进行推理，以检索给定问题的答案候选者。其次，提取 KG 中连接问题实体和答案候选项的最短路径以表示 KG 推理路径。提取的路径被文本化并作为使用 RAG 进行 LLM 推理的输入。在GNN-RAG 框架中，GNN 充当密集的子图推理器来提取有用的图信息，而 LLM 则利用其自然语言处理能力进行最终的 KGQA（知识图谱问答）</p><p><img src="/../article_img/PathGNN/GNN-RAG.png" alt="GNN-RAG"></p><p><strong>GNN的训练过程：</strong>将知识图谱问答KGQA任务视为节点分类，使用question-answer pairs训练集，将KG entities被分为answers和non-answers，</p><p>$h_v^{(l)}&#x3D;\psi(h_v^{(l-1)}, \sum_{v’\in N_v}\omega(q,r)\cdot m_{vv’}^{(l)})$    Equ.1</p><p>其中函数$\omega(\cdot)$用来计算三元组(v,r,v’)中关系r和用户查询q之间的相关性。经过多跳传播后，所有节点根据最终表示被分为answer和non-answer两类。</p><p>此外，考虑到不同的GNN会产生不同的推理路径，如公式Equ.1所示，GNN的推理依赖于question-relation匹配函数$\omega(q,r)$，比较常用的设计方式为$\phi(q^{(k)}\odot r)$，其中$q^{(k)}$和$r$使用预训练语言模型来进行编码，$q^{(k)}&#x3D;\gamma_k(LM(q)), r&#x3D;\gamma_c(LM(r))$。</p><p><strong>GNN的推理过程：</strong>具有最高概率分数的节点（例如，高于概率阈值）将作为候选答案返回，以及将问题实体与候选答案连接起来的最短路径（推理路径）。检索到的推理路径用作基于 LLM 的 RAG 的输入。</p><p>为了确保推理路径的多样性，这里作者并没有采用不同的GNN架构，而是使用了不同的LM通过更改$\omega$函数来引导单一的GNN获取不同的节点表示</p><p><strong>LLM</strong>：没什么好说的，prompt-tuning </p><p>prompt: “Based on the reasoning paths, please answer the given question.\n Reasoning Paths: {Reasoning Paths} \n Question: {Question}”. </p><p>Reasoning paths 用语言描述为 “{question entity} → {relation} → {entity} → · · · → {relation} → {answer entity} \n”</p><p>2.<a href="https://arxiv.org/abs/2310.01061">Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning</a></p><p>开源代码：<a href="https://github.com/RManLuo/reasoning-on-graphs">https://github.com/RManLuo/reasoning-on-graphs</a></p><p>Motivation: 现有的基于 KG 的 LLM 推理方法仅将 KG 视为事实知识库，而忽视了其结构信息对推理的重要性。作者提出了一种称为图推理（TOG）的方法，并设计了一种规划检索推理框架，以实现忠实和可解释的推理</p><p><img src="/../article_img/PathGNN/RoG.png" alt="RoG"></p><p>Methodology：RoG包含两个组件：（1）<strong>规划模块：</strong>基于用户查询生成关系路径作为KG的检索规划（2) <strong>检索推理模块：</strong>根据规划模块的关系路径从KG中检索有效的推理路径。RoG通过两项任务进行优化：（1）<strong>规划优化</strong>，由于LLM对KG中包含的关系一无所知，该模块的训练目标是让LLM生成的关系路径尽可能近似于KG的有效路径。作者使用关系路径Q（z）的后验分布最小化KL发散来实现，该后验分布可以通过KGs中的有效关系路径来近似（2）<strong>检索-推理优化</strong>，给定问题q和作为规划z的关系路径，检索模块旨在从KG图G检索这个推理路径$W_z$。检索过程包括在G中查找路径，其从问题实体$e_q$开始并遵循关系路径z。采用一个约束的广度优先搜索（BFS）来检索来自KGs的推理路径$W_z$。实验中，所有检索的路径都用于推理。</p><p><img src="/../article_img/PathGNN/Algorithm.png" alt="Optimization Algorithm"></p><p>总结：LLM用来生成关系路径，在训练的过程中尽可能的去拟合KG中的真实路径。推理时首先让LLM根据用户查询生成路径规划，然后再KG查询对应的有效路径，作为检索结果，与用户查询一起作为LLM输入用户生成回复。</p>]]></content>
    
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>RAG</tag>
      
      <tag>Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GraphRAG综述</title>
    <link href="/2025/02/20/GraphRAG%E7%BB%BC%E8%BF%B0/"/>
    <url>/2025/02/20/GraphRAG%E7%BB%BC%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<h4 id="Sec-1-传统RAG系统面临的挑战"><a href="#Sec-1-传统RAG系统面临的挑战" class="headerlink" title="Sec.1 传统RAG系统面临的挑战"></a>Sec.1 传统RAG系统面临的挑战</h4><p><strong>复杂的查询理解：</strong>传统的 RAG 方法依赖于简单的关键字匹配和向量相似性技术，不足以捕捉准确和全面所需的深层语义细微差别和多步骤推理过程。例如，当询问概念 A 和概念 D 之间的联系时，这些系统通常只检索直接相关的信息，而错过了像 B 和 C 这样可以弥合关系的关键中间概念。这种狭窄的检索范围限制了 RAG 的能力，使其无法进行广泛的上下文理解和复杂的推理</p><p><strong>集成来自分布式源的领域知识：</strong>检索到的知识通常是扁平的、广泛的和错综复杂的，而领域概念通常分散在多个文档中，不同概念之间没有明确的层次结构关系。尽管 RAG 系统试图通过将文档划分为较小的块以实现有效和高效的索引来管理这种复杂性，但这种方法无意中牺牲了关键的上下文信息，严重损害了检索准确性和上下文理解。这种限制阻碍了在相关知识点之间建立强大联系的能力，导致理解碎片化，并降低利用特定领域专业知识的效率。</p><p><strong>LLM的固有约束：</strong>受到其固定上下文窗口的限制，LLM无法完全捕获复杂文档中的长距离依赖关系。在专业领域中，在广泛的知识背景下保持连贯性的挑战变得越来越棘手，因为关键信息可能会在上下文窗口截断期间丢失。</p><p><strong>系统效率和可拓展性：</strong>RAG 系统在计算上可能既昂贵又耗时 ，尤其是在处理大规模知识源时，因为模型需要搜索大量非结构化文本以查找相关信息。此外，实时检索和跨文档推理可能会带来相当大的延迟，从而对用户体验产生负面影响。此外，实时检索和跨文档推理可能会带来相当大的延迟，从而对用户体验产生负面影响，从而限制了它在广泛和动态的专业环境中的实际部署</p><h4 id="Sec-2-现有的GraphRAG分类"><a href="#Sec-2-现有的GraphRAG分类" class="headerlink" title="Sec.2 现有的GraphRAG分类"></a>Sec.2 现有的GraphRAG分类</h4><p><strong>基于知识的GraphRAG:</strong> 它使用图作为知识载体，专注于将非结构化文本文档转换为显式和结构化的 KG，其中node代表领域概念，edge捕获它们之间的语义关系，从而更好地表示分层关系和复杂的知识依赖关系</p><p><strong>基于索引的GraphRAG:</strong> 使用图作为索引工具从语料库中检索相关的原始文本，它保留了原始文本形式，同时主要将图形结构用作索引机制来有效地组织和检索相关文本块。通过将图形结构合并到文本索引中，基于索引的 GraphRAG 方法在文本块之间建立语义连接，以实现高效的查找作和检索</p><p><strong>基于知识的 GraphRAG 旨在通过基于图的推理能力创建结构化的知识表示，以便更好地理解复杂的关系；而基于索引的 GraphRAG 则侧重于通过基于图的索引策略优化相关文本信息的检索和可访问性</strong></p><h4 id="Sec-3-Overview-the-Framework-of-RAG"><a href="#Sec-3-Overview-the-Framework-of-RAG" class="headerlink" title="Sec.3 Overview the Framework of RAG"></a>Sec.3 Overview the Framework of RAG</h4><p>RAG框架主要由三个部分组成，Knowledge Organization,Knowledge Retrieval,Knowledge Integration。下图展示了传统RAG、基于知识的GraphRAG和基于索引的GraphRAG在这三部分的各自实现方式。</p><p><img src="/../article_img/20250220/img1.png" alt="传统 RAG 和两个典型 GraphRAG 工作流程的全面概述。传统 RAG 将语料库组织成块，按相似性对它们进行排名，并检索最相关的文本以生成响应。基于知识的 GraphRAG 使用实体识别和关系提取从语料库中提取详细的知识图谱，提供精细的、特定于领域的信息。基于索引的 GraphRAG 将语料库总结为高级主题节点，这些节点链接以形成索引图，而事实链接将主题映射到文本。这种两层结构将高效的主题检索与详细的文本知识相结合，与基于知识的 GraphRAG 相比，提供了可扩展性和性能"></p><p><strong>Knowledge Organization:  该部分关注外部知识库的构建</strong></p><p><strong>传统RAG</strong>：传统RAG主要采用将大规模文本语料库拆分为可管理块的策略，然后使用嵌入模型将这些块转换为嵌入，其中嵌入用作向量数据库中原始文本块的键。此设置通过在语义空间中基于距离的搜索实现高效的查找作和检索相关内容。常见的优化方法：<strong>粒度优化</strong>和<strong>索引优化</strong>。</p><p><strong>GraphRAG:</strong> 基于图的方法构建外部信息，通过显式知识表示（作为知识载体的图）或索引机制（用于知识索引的图）。这些方法可实现高效的上下文感知信息检索。</p><p><strong>Knowledge Retrieval: 该部分关注如何更精准高效的进行检索</strong></p><p><strong>传统RAG</strong>: 常涉及的检索方法：KNN、TF-IDF、BM25。为了提高检索的准确性和效率，一方面可以在检索前通过优化表示或重排序等技术来提高检索模型的准确性，例如<a href="https://arxiv.org/pdf/2009.08553">GAR</a>、<a href="https://arxiv.org/pdf/2305.17080">EAR</a>等；另一方面，对检索模型进行训练，例如<a href="https://arxiv.org/pdf/2301.12652">Replug</a>，<a href="https://www.jmlr.org/papers/volume24/23-0037/23-0037.pdf">Atlas</a>，<a href="https://arxiv.org/pdf/2305.06983">Flare</a>等。</p><p><strong>GraphRAG:</strong> GraphRAG 模型使用基于图的规划器（可学习的规划器或基于图算法的规划器）根据输入查询检索相关信息。这些检索技术不仅考虑了查询和每个文本块之间的语义相似性，还考虑了查询类型和检索到的子图之间的逻辑连贯性</p><p><strong>Knowledge Integration:  该部分关注如何将检索结果和用户查询高质量整合</strong></p><p><strong>传统RAG</strong>:提高检索到的内容的质量：强化学习方法<a href="https://www.sciencedirect.com/science/article/pii/S294971912400013X">LeanContext</a> LLM自评估方法<a href="https://arxiv.org/pdf/2310.11511">Self-RAG</a>  <a href="https://arxiv.org/pdf/2307.03027">评估检索内容重要性</a>。此外，考虑到对大量检索到的段落进行编码是资源密集型的，这会导致大量的计算和内存开销，相关优化方法：<a href="https://arxiv.org/pdf/2404.12457">RAGCache</a> <a href="https://arxiv.org/pdf/2310.15556">TCRA-LLM</a></p><p><strong>GraphRAG:</strong> 一旦检索到相关知识，GraphRAG 模型就会将其与用户查询整合起来作为LLM input。集成过程的目标是将检索到的知识无缝合并到生成的文本中，从而提高其质量和信息量。一个关键的设计考虑因素是，如何在最终的基于文本的提示中保留检索到的子图信息的丰富性，而不会引入冗余或错误地强调文本描述中不太关键的方面</p><h4 id="Sec-4-Knowledge-Organization-in-GraphRAG"><a href="#Sec-4-Knowledge-Organization-in-GraphRAG" class="headerlink" title="Sec.4 Knowledge Organization in GraphRAG"></a>Sec.4 Knowledge Organization in GraphRAG</h4><p>首先构建一个图结构来组织知识，然后检索和集成与查询相关的信息。下面对Sec.2 提到的范式展开具体介绍。</p><p><strong>Graphs for Knowledge Indexing</strong></p><p>​基于索引的 GraphRAG 方法利用图结构来索引和检索相关的原始文本块，然后将其馈送到 LLM 中以进行知识注入和上下文理解。这些索引图应用语义相似性或特定于域的关系等原则来有效地桥接单独文本段落之间的连接。与仅将图用作知识载体相比，这种技术通过直接总结与查询相关的原始文本块中的信息来提供更丰富的答案。</p><p>​面临的挑战：（1） <strong>简洁性和相关性</strong>：确保构建的图仅捕获相关关系，而不会因不必要的连接而过载，这是一项重大挑战，从而有助于有效调用相关文本块而不会产生冗余 （2）<strong>一致性和冲突解决：</strong>不同的数据块可能会引入冲突的信息。解决这些冲突并确保图保持一致、可靠和结构良好至关重要。</p><p><strong>Graphs for Knowledge Carriers</strong></p><p>​优势：1）高效检索与查询相关的知识 2）长跨度的连贯多步推理  </p><p>​局限性：（1） <strong>缺乏高质量的 KG：</strong>对于直接使用KG作为外部知识库，这一研究方向受到高质量KG可用性的限制。构建KG是资源密集型的，但大多数公开可用的KG仍然远非全面（2） <strong>效率和有效性之间的权衡：</strong>当从文本语料库构建 KG 时，提取知识的粒度在平衡效率和有效性方面起着至关重要的作用。保留细粒度信息会导致更大、更详细的 KG，这可能会阻碍计算效率。相反，紧凑的 KG 可能会牺牲重要的细节，从而导致潜在的信息丢失。</p><h4 id="Sec-5-Knowledge-Retrieval-Process"><a href="#Sec-5-Knowledge-Retrieval-Process" class="headerlink" title="Sec.5 Knowledge Retrieval Process"></a>Sec.5 Knowledge Retrieval Process</h4><p>​基于图的知识检索一般分为Preprocess&#x2F;Matching&#x2F;Pruning三个步骤，如下图所示：</p><p><img src="/../article_img/20250220/img2.png" alt="Retrieval Process"></p><p><strong>Query&#x2F;Graph Preprocess</strong> 预处理阶段同时对查询数据库和图形数据库运行，以便为高效检索做好准备。对于查询预处理，系统通过矢量化或关键术语提取将输入问题转换为结构化表示。这些表示形式用作后续检索作的搜索索引。在图方面，图数据库经过更全面的处理，其中预训练的语言模型将图元素（实体、关系和三元组）转换为密集的向量表示，作为检索锚点 。此外，一些高级检索模型在图数据库上应用图神经网络 （GNN） 来提取高级结构特征，而一些方法甚至采用规则挖掘算法生成规则库，作为图知识的丰富、可搜索的索引</p><p><strong>Matching</strong> 匹配阶段在预处理的查询和索引图数据库之间建立连接。此过程将查询表示形式与图索引进行比较，以识别相关的知识片段。匹配算法同时考虑图中的<strong>语义相似性和结构关系</strong>。根据匹配分数，系统检索与查询高度相关的连通组件和子图，从而创建一组初始的候选知识。</p><p><strong>Knowledge Pruning</strong> 修剪阶段会优化最初检索的知识，以提高其质量和相关性。此优化过程解决了检索过多或不相关信息的常见挑战，尤其是在处理复杂查询或大型图数据库时。剪枝算法应用一系列细化作来整合和总结检索到的知识。具体来说，系统首先删除明显不相关或嘈杂的信息。然后，它整合了相关的知识片段，并生成了复杂图知识的简明摘要。通过提供精炼和重点突出的摘要，LLM 能够更好地理解信息的上下文和细微差别，从而做出更准确和有意义的回答。</p><h4 id="Sec-6-Knowledge-Retrieval-Techniques"><a href="#Sec-6-Knowledge-Retrieval-Techniques" class="headerlink" title="Sec.6 Knowledge Retrieval Techniques"></a>Sec.6 Knowledge Retrieval Techniques</h4><p><strong>基于语义相似性的检索器</strong> 通过测量离散语言空间或连续向量空间中的查询与知识库之间的相似性来进行适当的答案检索 （1）离散空间建模。离散空间建模方法主要利用语言离散统计知识直接对文本字符串进行建模。例如子字符串匹配、正则表达式和精确短语匹配等算法  （2）嵌入空间建模。利用预训练语言模型和词嵌入等方法，例如 TF-IDF、Word2Vec 和 GloVe</p><p><strong>基于逻辑推理的检索器</strong> 采用符号推理从图知识库中推断和提取相关信息。此方法包括创建逻辑规则和约束，以阐明知识库固有的关系和层次结构，例如 规则挖掘 、归纳逻辑编程 和 约束满足 等技术</p><p><strong>基于 GNN 的 Retriever</strong> 主要利用图神经网络对构建的图库中的节点进行编码。检索主要依赖于同时包含情感意义和结构关系理解的节点表征的编码相似性。基于 GNN 的检索器需要训练 GNN 编码器。此外，由于缺乏明确标注的数据，<strong>训练的重点是设计一个合适的损失函数，使 GNN 能够学习通过表示编码准确定位目标知识</strong></p><p><strong>基于 LLM 的检索器</strong> 关于构建的图库，基于 LLM 的知识检索器主要侧重于利用 LLM 来理解图并识别关键子图。</p><p><strong>基于强化学习的检索器</strong> 强化学习 为 GraphRAG 系统中的检索提供了一种自适应和动态策略。通过将检索过程构建为顺序决策挑战，基于 RL 的方法使代理能够在环境反馈的指导下学习和遍历图库，以寻找最相关的信息。</p><p>这种方法赋予系统通过主动交互和积累经验不断提高其检索性能的能力。这个过程可以描述如下：相关的推理背景在于一个特定于问题的子图 $G_{sub}$，其中包含所有源实体 $Q_s$、目标实体 $Q_t$ 及其邻居。理想的子图 $G_{sub}$ 应具有以下属性：（i） $G_{sub}$ 包含尽可能多的源实体和目标实体;（ii） $G_{sub}$ 中的实体和关系与问题上下文具有很强的相关性;（iii） $G_{sub}$ 简洁明了，几乎没有冗余信息，因此可以输入到长度有限的 LLM 中。相关方法：<a href="https://arxiv.org/pdf/2405.16420">Deep QNetworks</a>, <a href="https://arxiv.org/pdf/2401.06800">Policy Gradients</a>, and <a href="https://arxiv.org/pdf/2410.10584">Actor-Critic</a></p><h4 id="Sec-7-Knowledge-Integration"><a href="#Sec-7-Knowledge-Integration" class="headerlink" title="Sec.7 Knowledge Integration"></a>Sec.7 Knowledge Integration</h4><p><strong>微调技术：</strong>利用各种图形信息的微调过程可以根据输入目标的粒度分为三个不同的类别：（i） 节点级知识：关注图形中的各个节点。（ii） 路径级知识：专注于节点之间的连接和序列。（iii） 子图级知识：考虑由多个节点组成的较大结构及其互连。我们将详细探讨这些方面中的每一个。 </p><p>使用 Node 级知识进行微调。在许多基于图的 RAG 系统中，每个节点都链接到一个文档，例如引文网络中的摘要。由于特定领域的数据很少出现在预训练语料库中，因此一些研究在进行下游任务微调之前采用指令调优来加强对特定领域的知识理解。一种简单的微调方法包括将节点和相邻文本作为上下文信息馈送到 LLM 中，以帮助预测 <a href="https://openreview.net/forum?id=x5FfUvsLIE">1</a>、<a href="https://arxiv.org/pdf/2406.10393">2</a>、<a href="https://arxiv.org/pdf/2402.07483">3</a>。鉴于检索到的文档可能很广泛，研究人员可以利用 LLM 将这些文本提炼成单个嵌入 <a href="https://proceedings.neurips.cc/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf">4</a>。尽管缺乏词汇外标记的预训练数据，但 LLM 能够在实践中识别这些嵌入中的信息。</p><p>使用 Path-level Knowledge 进行微调。语言任务通常涉及复杂的推理，需要对事实关系有清晰的理解。利用知识图谱路径，LLM 通过关系和实体的引导增强自身推理能力。这些路径可以是从问题实体到答案实体的最直接路线，也可以使用 图检索模型 或 启发式方法 进行挖掘。它们可以用作输入和输出，但是当两个节点之间存在多条路径时，过滤掉嘈杂的路径同时保留知识图谱中的关系至关重要。为了保持实体表示的完整性及其沿路径的关系，一些方法侧重于将这些路径作为训练目标，预测两个节点之间路径上的节点和关系<a href="https://arxiv.org/pdf/2303.03922">5</a>，甚至跨多个路径<a href="https://arxiv.org/pdf/2310.01061">6</a>。这使 LLM 能够进行Path级推理并产生可靠的输出。</p><p>使用 Subgraph 级知识进行微调。与路径数据的线性拓扑不同，子图数据表现出更复杂、更不规则的拓扑。一种简单的方法是使用图编码器将子图级信息压缩到读出嵌入中。或者，将图数据转换为序列。然而，这些方法往往忽略了子图中丰富的文本内容，无法使 LLM 认识到底层的图结构。为了解决这个问题，一些工作专注于调整 transformer 架构以更好地处理结构化数据，例如<a href="https://arxiv.org/pdf/2212.01588">7</a>、<a href="https://arxiv.org/pdf/2402.11709">8</a>，而另一些则将节点和边的描述直接合并到提示中，例如<a href="https://aclanthology.org/2024.findings-eacl.132.pdf">9</a>、<a href="https://arxiv.org/pdf/2402.08170">10</a>。然而，现有方法仍然存在挑战。前者可能会因架构更改而丢失在预训练期间获得的知识，而后者可能难以处理具有大量节点和边的密集图。</p><h4 id="相关工作总结"><a href="#相关工作总结" class="headerlink" title="相关工作总结"></a>相关工作总结</h4><p>参考文献：<a href="https://arxiv.org/pdf/2501.13958">https://arxiv.org/pdf/2501.13958</a></p><p><img src="/../article_img/20250220/img3.png" alt="参考文献"></p>]]></content>
    
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>RAG</tag>
      
      <tag>Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Graph + RAG</title>
    <link href="/2025/02/18/20250218/"/>
    <url>/2025/02/18/20250218/</url>
    
    <content type="html"><![CDATA[<h1 id="Graph-RAG"><a href="#Graph-RAG" class="headerlink" title="Graph + RAG"></a>Graph + RAG</h1><p>图RAG相比于传统RAG的优势：</p><ol><li>多跳推理能力 2. 关系建模能力 3. 高效的知识更新与管理 4. 减少检索的噪声和生成的幻觉</li></ol><p>最近看了几篇图RAG的论文：</p><h3 id="G-Retriever-Retrieval-Augmented-Generation-for-Textual-Graph-Understanding-and-Question-Answering（https-arxiv-org-pdf-2402-07630）"><a href="#G-Retriever-Retrieval-Augmented-Generation-for-Textual-Graph-Understanding-and-Question-Answering（https-arxiv-org-pdf-2402-07630）" class="headerlink" title="G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering（https://arxiv.org/pdf/2402.07630）"></a>G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering（<a href="https://arxiv.org/pdf/2402.07630%EF%BC%89">https://arxiv.org/pdf/2402.07630）</a></h3><p>Motivation: 引入文本图进行检索增强</p><p>开源代码：<a href="https://github.com/XiaoxinHe/G-Retriever">https://github.com/XiaoxinHe/G-Retriever</a></p><p>首先根据已有的外部知识构建知识图谱，并对每个节点和关系，利用其固有的文本属性进行特征编码。针对用户的query，进行相似度检索，得到节点和边的topk子集。然后设计了一种强化学习策略基于检索得到的子集构建subgraph。在生成阶段，LLM的参数被冻结，除了用户的query以外，还有检索子图的文本属性所构成的hard prompt和基于可训练graph encoder得到的soft prompt <img src="/article_img/20250218/20250218_01.png" alt="G-Retriever"></p><h3 id="Knowledge-Graph-Retrieval-Augmented-Generation-For-LLM-Based-Recommendation-https-arxiv-org-pdf-2501-02226"><a href="#Knowledge-Graph-Retrieval-Augmented-Generation-For-LLM-Based-Recommendation-https-arxiv-org-pdf-2501-02226" class="headerlink" title="Knowledge Graph Retrieval-Augmented Generation For LLM-Based Recommendation(https://arxiv.org/pdf/2501.02226)"></a>Knowledge Graph Retrieval-Augmented Generation For LLM-Based Recommendation(<a href="https://arxiv.org/pdf/2501.02226">https://arxiv.org/pdf/2501.02226</a>)</h3><p>Motivation: 传统的RAG方法忽视了知识的结构关系，借助外部知识构建KG，对推荐进行检索增强；</p><p>检索阶段，首先训练一个GNN网络用来对item-entity知识图谱的每个节点和关系进行编码，并以每个节点作为中心节点生成的多跳特征表示收集起来，构建向量数据库。对于待预测的用户节点，根据其交互历史中的每个节点，利用其文本特征从KG VecDB中检索相关子图，并对检索得到的所有子图进行重排序用于构建soft prompt，从而增强LLM的推荐能力。<img src="/article_img/20250218/20250218_02.png" alt="K-RagRec"></p><h3 id="KG-Retriever-Efficient-Knowledge-Indexing-for-Retrieval-Augmented-Large-Language-Models（https-arxiv-org-pdf-2412-05547）"><a href="#KG-Retriever-Efficient-Knowledge-Indexing-for-Retrieval-Augmented-Large-Language-Models（https-arxiv-org-pdf-2412-05547）" class="headerlink" title="KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models（https://arxiv.org/pdf/2412.05547）"></a>KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models（<a href="https://arxiv.org/pdf/2412.05547%EF%BC%89">https://arxiv.org/pdf/2412.05547）</a></h3><p>Motivation: 对结构信息分层检索，从根本上缓解信息碎片化的问题</p><p>设计了Doc层(Document-level Graph)和KG层(Entity-level Graph)分别用于建立文档内和文档间的连接，Doc Graph的构建是对每个文档进行文本编码，并基于语义相似性获得每个节点的K近邻居；KG Graph的构建是对每个文档进行信息抽取，从而获得对应的知识图谱。检索策略上，作者考虑了两级检索：文档级检索和实体级检索，前者除了考虑用户查询和每个文档的语义相似性以外，还根据Doc Graph获取这些topN文档的one-hop邻居；后者则针对上一阶段检索的所有文档所对应的kg图检索语义相关的实体集，和query一起作为最终LLM的输入<br><img src="/article_img/20250218/20250218_03.png" alt="KG-Retriever"></p>]]></content>
    
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>RAG</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于模型padding左对齐和右对齐的问题</title>
    <link href="/2025/02/17/LLM%20padding/"/>
    <url>/2025/02/17/LLM%20padding/</url>
    
    <content type="html"><![CDATA[<p>最近微调模型进行原因预测任务训练的时候，在eval阶段进行推理生成时遇到了一个警告：“A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set <code>padding_side=&#39;left&#39;</code> when initializing the tokenizer.”，我将tokenizer初始化的定义设置为左填充依然出现该警告，问了下身边对大模型比较了解的同学，发现是token序列结尾加了eos符号导致出现的warning，下面是transformers库中该警告出现的条件：</p><p><img src="/article_img/LLM%20padding/warning.png" alt="warning"></p><p>为什么模型训练选择右填充，推理时选择左填充；为什么训练时需要在结尾添加<eos>标记符，而推理时则不需要，下面给出解释说明：</p><p>训练：Q+A[EOS]  </p><p>模型训练时，对于输入的token序列，我们知道其真实标签（Ques部分可直接用-100作为 <strong>mask</strong> 填充或无效标签，以确保这些位置不会影响损失计算），采用右填充是为了让每个batch内的样本长度对齐。在结尾添加eos标记符是为了告诉模型输入序列的结束位置，如果没有 EOS token，模型可能会将序列当作是没有结束的，进而可能会试图无限制地生成下一个 token，导致训练不稳定或生成行为不正确</p><p>推理：Q</p><p>自回归模型在推理时，从bos标记符开始从左到右依次预测下一个词来生成内容，如下面的图所示：</p><p><img src="/article_img/LLM%20padding/padding.png" alt="padding"></p><p>如果采用右填充，<pad>将被放置在In-Context的右端，从而改变了In-Context内容，这将导致生成时模型的上下文理解出现偏差，结果可能会影响到生成的质量或连贯性。此外，如果在In-Context的结尾处加入eos标记符，这将导致模型停止生成。</p><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/4581421783">模型训练选择right填充，推理选择left填充，为什么？ - 知乎</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Bug</tag>
      
      <tag>Code</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>大模型显存占用计算</title>
    <link href="/2025/02/17/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97/"/>
    <url>/2025/02/17/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97/</url>
    
    <content type="html"><![CDATA[<h2 id="1-显存单位换算"><a href="#1-显存单位换算" class="headerlink" title="1. 显存单位换算"></a>1. 显存单位换算</h2><p>在讨论显存占用时，首先要明白“B”和“G”的含义。通常，“B”指的是十亿（1B &#x3D; 10^9），而“G”则表示千兆字节（1G &#x3D; 10^9字节）。例如，1B参数意味着有10亿个参数。显存的单位通常以字节计算，而1个字节等于8位。<br>🎈如果使用全精度训练（fp32），每个参数需要占用32位（即4个字节），因此1B的参数需要占用4GB的显存。<br>🎈如果使用半精度（fp16或bf16），则每个参数占用2字节，1B的参数只需占用2GB的显存。</p><h2 id="2-显存开销的其他组成部分"><a href="#2-显存开销的其他组成部分" class="headerlink" title="2. 显存开销的其他组成部分"></a>2. 显存开销的其他组成部分</h2><p>除了模型参数本身外，训练过程中还会消耗一定的显存，主要包括以下几部分：<br>🎈梯度：每个参数对应一个梯度，因此梯度的显存占用与参数量相同。<br>🎈优化器状态：优化器，如Adam，通常会为每个参数保存一阶动量和二阶动量，因此优化器的显存开销为参数量的2倍（对于Adam）。对于其他优化器（如SGD），则取决于优化器的具体实现，若是带动量的SGD，则为参数量的1倍。</p><h2 id="3-显存总占用计算"><a href="#3-显存总占用计算" class="headerlink" title="3. 显存总占用计算"></a>3. 显存总占用计算</h2><p>假设我们训练一个参数量为1B的模型，采用全精度（fp32）并使用Adam优化器，显存的占用计算如下：<br>🎈参数：1B × 4GB &#x3D; 4GB<br>🎈梯度：1B × 4GB &#x3D; 4GB<br>🎈优化器状态：1B × 8GB &#x3D; 8GB<br>因此，总显存占用为16GB。如果使用半精度（bf16），则显存占用减半，为8GB。混合精度训练则会根据各部分精度调整计算结果。</p>]]></content>
    
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>Code</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Recsys大牛实验室官网链接</title>
    <link href="/2025/02/01/lab/"/>
    <url>/2025/02/01/lab/</url>
    
    <content type="html"><![CDATA[<p>Xiangnan He：<a href="https://hexiangnan.github.io/">https://hexiangnan.github.io/</a><br>Yuan Fang@SMU: <a href="https://www.yfang.site/">https://www.yfang.site/</a><br>Huang Chao: <a href="https://sites.google.com/view/chaoh">https://sites.google.com/view/chaoh</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Study</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>人工智能竞赛汇总</title>
    <link href="/2025/02/01/competition/"/>
    <url>/2025/02/01/competition/</url>
    
    <content type="html"><![CDATA[<h2 id="1-人工智能竞赛平台-Biendata：Data-Competition-Community-Biendata"><a href="#1-人工智能竞赛平台-Biendata：Data-Competition-Community-Biendata" class="headerlink" title="1.人工智能竞赛平台 Biendata：Data Competition Community - Biendata"></a><strong>1.人工智能竞赛平台 Biendata：</strong><a href="https://link.zhihu.com/?target=https://www.biendata.xyz/">Data Competition Community - Biendata</a></h2><p><strong>介绍：</strong></p><blockquote><p>2018 年 5 月，人工智能和大数据的竞赛平台 Biendata 完成天使轮融资，由DeepTech深科技投资，旨在打造中国人工智能赛事顶级 IP，赛事相关媒体运营。Biendata 的比赛客户既包括<strong>今日头条、知乎、摩拜、搜狐等企业，也包括了 IEEE、ACM、中国计算机学会、中国人工智能学会</strong>等国内外顶尖学术组织。</p></blockquote><p>总体上来说就是一个各自AI比赛汇总的平台（除了一些大厂有自己的大规模AI赛事比如阿里云天池、华为云、百度、腾讯），类似的办赛平台IP还有</p><ul><li><strong>datafountain：</strong><a href="https://www.datafountain.cn/competitions">数据科学竞赛&#x2F;大数据 竞赛 - DataFountain</a></li><li><strong>Kaggle(国外)：</strong><a href="https://www.kaggle.com/competitions">Kaggle Competitions</a></li></ul><p><strong>时间：</strong>基本上是什么时间都有，需要持续关注官网，同一个企业基本每年举办的timeline不变</p><h2 id="2-阿里云天池：算法大赛-天池大数据竞赛-天池大赛-阿里云天池"><a href="#2-阿里云天池：算法大赛-天池大数据竞赛-天池大赛-阿里云天池" class="headerlink" title="2.阿里云天池：算法大赛-天池大数据竞赛-天池大赛-阿里云天池"></a><strong>2.阿里云天池：</strong><a href="https://tianchi.aliyun.com/competition/gameList/algorithmList">算法大赛-天池大数据竞赛-天池大赛-阿里云天池</a></h2><p><strong>介绍：</strong>老牌，2014年启办，面向全世界科研人员和高校师生，业务场景丰富（2B2C都有cover），奖金池也丰富。</p><p><strong>时间：</strong>基本上是5月份开始报名——夏天初赛\复赛——10月决赛答辩</p><h2 id="3-华为云-：华为云大赛平台"><a href="#3-华为云-：华为云大赛平台" class="headerlink" title="3.华为云 ：华为云大赛平台"></a><strong>3.华为云 ：</strong><a href="https://competition.huaweicloud.com/competitions">华为云大赛平台</a></h2><p><strong>介绍：</strong>众所周知华为对研发投入比例很大，也十分重视创新大赛的举办，会联合各种高校、产品线、学术机构\组织办赛，每年任何时间节点都可能会有比赛。相关领域的同学需要持续关注。</p><p><strong>时间：</strong>一年中任意时刻</p><h2 id="4-百度飞桨AI-Studio大赛：飞桨AI-Studio-人工智能学习与实训社区"><a href="#4-百度飞桨AI-Studio大赛：飞桨AI-Studio-人工智能学习与实训社区" class="headerlink" title="4. 百度飞桨AI Studio大赛：飞桨AI Studio - 人工智能学习与实训社区"></a><strong>4. 百度飞桨AI Studio大赛：</strong><a href="https://aistudio.baidu.com/aistudio/competition/1/1">飞桨AI Studio - 人工智能学习与实训社区</a></h2><p><strong>介绍：</strong>AI Studio是基于百度深度学习平台飞桨的人工智能学习与实训社区，整体跟华为云的形式差异不大，但赛程周期会紧凑一些，内容也和百度的业务内容强相关（如<strong>NLP</strong>\图像检测\导航路径）。个人感觉场景会更专精于NLP，比如事件抽取\机器翻译\QA\阅读理解\情感分析。</p><p><strong>时间：</strong>每年3-5月</p><h2 id="5-腾讯：-2021腾讯广告算法大赛"><a href="#5-腾讯：-2021腾讯广告算法大赛" class="headerlink" title="5.腾讯： 2021腾讯广告算法大赛"></a><strong>5.腾讯：</strong> <a href="https://algo.qq.com/index.html%3Flang%3Dcn">2021腾讯广告算法大赛</a></h2><p><strong>介绍：</strong>腾讯AI赛事做的不是特别好，除了广告算法大赛还比较成规模（基本每年有延续），其他的都很分散，没有统一的平台。</p><blockquote><p>AI Lab偶尔有些算法挑战赛，AI温室种番茄什么的: <a href="https://ai.tencent.com/ailab/zh/index">腾讯 AI Lab - 腾讯人工智能实验室官网</a></p></blockquote><p><strong>时间：</strong>三月开始报名——夏季初赛\复赛——八月决赛答辩</p><h2 id="6-AIOps-Challenge智能运维挑战赛：竞赛列表"><a href="#6-AIOps-Challenge智能运维挑战赛：竞赛列表" class="headerlink" title="6.AIOps Challenge智能运维挑战赛：竞赛列表"></a><strong>6.AIOps Challenge智能运维挑战赛</strong>：<a href="https://iops.ai/competition_list/">竞赛列表</a></h2><p><strong>介绍：</strong>规模较小，每年承办方会有变化，但是主题围绕着AIOps不变</p><p><strong>时间：</strong>基本上是1月年初开始报名——春季初赛\复赛——五月决赛答辩</p><h2 id="7-KDD-CUP：KDD-2021-Singapore"><a href="#7-KDD-CUP：KDD-2021-Singapore" class="headerlink" title="7.KDD CUP：KDD 2021 | Singapore"></a><strong>7.KDD CUP：</strong><a href="https://www.kdd.org/kdd2021/%23">KDD 2021 | Singapore</a></h2><p><strong>介绍:</strong> 国外赛事，商业性质较弱所以奖金池较小，主题是多源数据时序异常检测\OGB-LSC\城市大脑挑战，延续性比较好。</p><p><strong>时间：</strong>每年五月-八月</p>]]></content>
    
    
    
    <tags>
      
      <tag>Study</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>搭建代理服务器访问外网</title>
    <link href="/2025/02/01/buildvpn/"/>
    <url>/2025/02/01/buildvpn/</url>
    
    <content type="html"><![CDATA[<h2 id="理论部分"><a href="#理论部分" class="headerlink" title="理论部分"></a>理论部分</h2><p>这里简单介绍下常用的代理工具，并区分下Shadowsocks和ShadowsocksR的区别</p><h3 id="代理工具科学上网的原理"><a href="#代理工具科学上网的原理" class="headerlink" title="代理工具科学上网的原理"></a>代理工具科学上网的原理</h3><p>step:</p><ol><li><p><code>本地客户端</code> 与 <code>远程代理服务器</code> 建立加密隧道。</p></li><li><p>本地流量通过隧道发送到代理服务器。</p></li><li><p>代理服务器解密请求，访问目标网站（如 Google）。</p></li><li><p>返回的数据再次加密传回本地客户端。</p></li></ol><p>下面是关于代理工具常见的实现方式：</p><ol><li>HTTP&#x2F;HTTPS 代理<br>用于网页浏览器等支持 HTTP&#x2F;S 的客户端。</li></ol><p>代理服务器处理 HTTP 请求，并转发给目标网站。</p><p>缺点：不能代理非 HTTP 协议的流量（如游戏、软件更新等）。</p><ol start="2"><li>SOCKS5 代理<br>更通用的代理协议，支持任何协议（TCP、UDP）。</li></ol><p>应用层更透明，可以代理 Telegram、游戏、FTP、P2P 等流量。</p><p>常见工具：Shadowsocks、V2Ray 的 SOCKS5 模式。</p><ol start="3"><li>VPN（虚拟专用网络）<br>创建一个本地设备与远端服务器之间的加密通道。</li></ol><p>所有流量都通过该通道传输，相当于把你“搬到”另一个国家上网。</p><p>协议示例：OpenVPN、WireGuard、L2TP、IPSec。</p><ol start="4"><li>隧道转发工具（Tunneling）<br>例如：Shadowsocks、V2Ray、Trojan、Clash、Brook 等。</li></ol><p>这些工具结合 SOCKS5、HTTP 和自定义协议，提供加密代理服务，并通过 TLS 等方式隐藏特征。</p><h3 id="Shadowsocks与V2ray"><a href="#Shadowsocks与V2ray" class="headerlink" title="Shadowsocks与V2ray"></a>Shadowsocks与V2ray</h3><ol><li>Shadowsocks（SS）<br>特点</li></ol><ul><li><p>轻量级：专注于简单的 SOCKS5 代理，核心代码仅几千行。</p></li><li><p>设计目标：绕过网络封锁，不追求隐匿性（流量特征较明显）。</p></li><li><p>加密方式：支持 AES、ChaCha20 等对称加密。</p></li><li><p>协议：自定义协议（基于 SOCKS5），无完整握手过程，速度快。</p></li></ul><p>适用场景：适合个人翻墙、低延迟需求（如浏览网页、视频）。</p><p>优点: 1. 配置简单，资源占用低。 2. 客户端广泛（Windows&#x2F;macOS&#x2F;Android&#x2F;iOS 均有成熟客户端）。</p><p>缺点: 1. 流量特征易被识别（如 DPI 深度包检测可能封锁 SS 端口）。 2. 功能单一（仅代理 TCP&#x2F;UDP，无负载均衡等高级功能）。</p><ol start="2"><li>V2Ray（Project V）<br>特点</li></ol><ul><li><p>模块化设计：支持多种协议（VMess、VLESS、Shadowsocks、Trojan 等）。</p></li><li><p>隐匿性强：流量可伪装成 HTTPS（与正常网页流量混合），抗封锁能力更强。</p></li><li><p>功能丰富：支持多入口&#x2F;多出口（路由分流、负载均衡）。内置 DNS 代理、动态端口、mKCP（基于 UDP 的加速协议）。</p></li><li><p>加密与传输：默认使用 VMess 协议（基于 TLS + 动态 ID）。支持 WebSocket + TLS（伪装成 HTTPS 流量）。</p></li></ul><p>优点：1. 抗封锁能力强（适合严格审查环境，如中国 GFW）。 2. 灵活配置（可组合多种协议和传输方式）。 3. 支持多平台，生态完善（如 Clash、Qv2ray 等客户端）。</p><p>缺点：1. 配置复杂（需手动编写 JSON 配置文件）。 2. 资源占用略高（功能多导致性能开销稍大）。</p><h3 id="Shadowsocks与ShadowsocksR"><a href="#Shadowsocks与ShadowsocksR" class="headerlink" title="Shadowsocks与ShadowsocksR"></a>Shadowsocks与ShadowsocksR</h3><p>（1）协议与混淆<br>Shadowsocks：仅使用简单的 SOCKS5 代理协议，流量特征较明显；无内置混淆，易被防火墙通过流量分析识别（如 GFW 的主动探测）。</p><p>ShadowsocksR：支持 协议插件（如 auth_chain_a、auth_sha1_v4），混淆流量特征；可伪装成 HTTP&#x2F;TLS 流量，降低被封锁概率。</p><p>（2）加密方式<br>SS：固定加密（如 aes-256-cfb、chacha20-ietf）</p><p>SSR：支持更多加密组合（如 aes-256-gcm + tls1.2_ticket_auth）</p><h2 id="实操部分"><a href="#实操部分" class="headerlink" title="实操部分"></a>实操部分</h2><p>准备工作：有支付宝账户，有一个可用邮箱，有10美元。（根据我下面的链接注册，会赠送300美元的体验金，可以试一下没成本，如果长期用可以再去充值）</p><p>前言：首先我们选择Vultr供应商来购买海外VPS服务器，具有12个地区可以选择，当然也可以选择其他的供应商，但是Vultr的优点在于，所有服务器创建成功后开始计费，并且是按照小时来计费的，如果你删除掉服务器将不再计费。众所周知，目前国内的VPN打击特别严厉，很多VPN已经被封掉了，我们购买的海外服务器也有可能是被墙掉IP或者用一段时间被墙的。所以Vultr可以随时创建一个新的服务器（会分配一个新的ip），删除掉原有的。</p><h3 id="创建账户及购买VPS服务器"><a href="#创建账户及购买VPS服务器" class="headerlink" title="创建账户及购买VPS服务器"></a>创建账户及购买VPS服务器</h3><p>第一步：登录vultr官网注册一个账户，只需要一个邮箱和密码即可。然后到你注册的邮箱中去验证你的账户。</p><p>官网推广链接(<a href="https://www.vultr.com/?ref=9695214-9J">https://www.vultr.com/?ref=9695214-9J</a>) 这个链接是官网一个推荐链接，有300刀体验金</p><p>官网链接(<a href="https://www.vultr.com/?ref=7348872">https://www.vultr.com/?ref=7348872</a>) 这个链接就是普通的推荐链接</p><p><img src="/article_img/buildvpn/20180307101419422.jpg" alt="第一步"></p><p>第二步：登录你的账户，然后在如图所示地方进行充值。这里我们可以使用微信或支付宝扫码支付，充值成功后，可以再右上角看到你的账户余额。</p><p><img src="/article_img/buildvpn/20180307101506198.jpg" alt="第二步"></p><p>第三步：购买VPS服务器。在Servers标签中看到，我们目前还没有服务器，这时选择右上角的加号新添加一个服务器。</p><p><img src="/article_img/buildvpn/20180307101543991.jpg" alt="第三步"></p><p>我们首先选择服务器所在地区，这里我们选择NewYork纽约，一般来说选择日本、纽约、洛杉矶、硅谷都还可以（全看人品）。</p><p><img src="/article_img/buildvpn/20180307101558312.jpg" alt="第四步"></p><p>其次我们选择服务器的系统版本。这里注意选择CentOS6 ，默认是7由于防火墙等原因可能会影响接下来的操作。</p><p><img src="/article_img/buildvpn/20180307101612917.jpg" alt="第五步"></p><p>最后，我们选择每个月2.5刀，500G带宽的就可以了。</p><p><img src="/article_img/buildvpn/20180307101629749.jpg" alt="第六步"></p><p>其他的不需要选择，如果需要使用IPv6就在第四部选择。这里我们不选择，默认使用IPv4，最下面我们选择Depliy Now 新建服务器。</p><p><img src="/article_img/buildvpn/20180307101643841.jpg" alt="第七步"></p><p>到目前为止我们就已经成功的创建了一个海外服务器。但是这个服务器是否可用，有没有被墙掉呢？当服务器安装完成之后，我们来测试一下。</p><p><img src="/article_img/buildvpn/20180307101656506.jpg" alt="第八步"></p><p>我们可以看到已经在运行的服务器ip为  45.63.7.251 ，接下来就测试一下是否能够连接。<br>Win： win + R快捷键或者在开始菜单-附件-运行，调出运行窗口，输入cmd，然后输入ping  45.63.7.251 可以看到是否被墙。（多ping几次）<br>Mac + Linux：直接在命令行窗口输入ping  45.63.7.251 （按ctrl + c 退出）<br>或者通过网站ping检测，如果全是超时代表被墙了。<a href="http://ping.chinaz.com/">http://ping.chinaz.com/</a></p><p><img src="/article_img/buildvpn/20180307101706991.jpg" alt="第九步"></p><p>这里可以看到刚刚新建的服务器是被墙掉的。无法访问，这时就再新建一个服务器，然后在ping。如果同一个地区多次无法ping通，就换一个地区试试，这里推荐日本。（每次新建服务器，按小时首付0.01刀，删除后不计费，十次也才不到一块钱）</p><p>如图，我再次新建了一个服务器，这回可以ping通，说明没有被墙。就是延时高一点，延时与你的网络和当前的时间段，使用的人数有关。</p><p><img src="/article_img/buildvpn/20180307101717865.jpg" alt="第九步"></p><p><img src="/article_img/buildvpn/20180307101733164.jpg" alt="第十步"></p><p>这时我们把之前被墙掉的服务器删除就可以了。新建可用的服务器已经全部完成了。</p><p><img src="/article_img/buildvpn/20180307101748789.jpg" alt="第十一步"></p><p>点击详情可以看到服务器的用户名和密码</p><p><img src="/article_img/buildvpn/20180307101802763.jpg" alt="第十二步"></p><p><img src="/article_img/buildvpn/20180307101812373.jpg" alt="第十三步"></p><p>接下来我们就可以搭建VPN了。距离成功已经很近了。</p><p>首先如果我们是Windows系统需要下载一个软件（Mac 或 Linux不需要），Xshell或者SecureCRT。这里我用的是SecureCRT。<br>填写你的IP地址，用户名为root，点击链接，点击接受保存，输入你的密码，成功连接。</p><p><img src="/article_img/buildvpn/20180307101823784.jpg" alt="第十四步"><br><img src="/article_img/buildvpn/20180307101836775.jpg" alt="第十五步"></p><p>其次要设置编码格式，不然一会的中文会显示乱码。菜单栏 选项-会话选项-外观-字符编码-UTF8-确认。<br>关闭软件，重新连接（直接双击IP就可以了）。</p><p><img src="/article_img/buildvpn/20180307101848327.jpg" alt="第十六步"></p><p>然后复制下面的一键部署管理脚本，粘贴到窗口中（鼠标右键一下即可粘贴）</p><p>CentOS6&#x2F;Debian6&#x2F;Ubuntu14 ShadowsocksR一键部署管理脚本(可以把下面命令按行拆开分步执行)：</p><p>wget –no-check-certificate <a href="https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.sh">https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.sh</a></p><p>chmod +x shadowsocksR.sh</p><p>.&#x2F;shadowsocksR.sh 2&gt;&amp;1 | tee shadowsocksR.log</p><h3 id="主脚本安装SSR"><a href="#主脚本安装SSR" class="headerlink" title="主脚本安装SSR"></a>主脚本安装SSR</h3><p>第一步：设定密码，default 为默认密码</p><p><img src="/article_img/buildvpn/new2.png" alt="第十六-1步"></p><p>第二步：设定端口，default 为随机生成默认端口<br><img src="/article_img/buildvpn/new3.png" alt="第十六-2步"></p><p>第三步：设定加密方式，default 为默认加密方式<br><img src="/article_img/buildvpn/new4.png" alt="第十六-3步"></p><p>第四步：设协议，default 为默认协议<br><img src="/article_img/buildvpn/new1.png" alt="第十六-4步"></p><p>第五步：设定混淆方式，default 为默认混淆<br><img src="/article_img/buildvpn/new5.png" alt="第十六-5步"></p><p>第六步：安任意键，回车开始进行安装，安装完成后自动启动<br><img src="/article_img/buildvpn/new7.png" alt="第十六-6步"></p><p>当安装出现问题时，有可能是centOS中缺少相应c编译器，可以分别执行以下指令安装编译器后再安装SSR：</p><p>yum -y install gcc automake autoconf libtool make</p><p>yum -y install gcc-c++</p><p>最终：安装完成，展示你所设置的内容，可以按照链接信息进行连接(最近较严有可能被墙或者端口被封)<br><img src="/article_img/buildvpn/new6.png" alt="第十六-7步"></p><p>安装过后如果想要修改，运行如下相关命令</p><p>启动：&#x2F;etc&#x2F;init.d&#x2F;shadowsocks start</p><p>停止：&#x2F;etc&#x2F;init.d&#x2F;shadowsocks stop</p><p>重启：&#x2F;etc&#x2F;init.d&#x2F;shadowsocks restart</p><p>状态：&#x2F;etc&#x2F;init.d&#x2F;shadowsocks status</p><p>配置文件路径：&#x2F;etc&#x2F;shadowsocks.json  修改文件用vi 或者 vim命令，使用方法百度</p><p>日志文件路径：&#x2F;var&#x2F;log&#x2F;shadowsocks.log </p><p>安装路径：&#x2F;usr&#x2F;local&#x2F;shadowsocks&#x2F;shadowsoks</p><p>卸载.&#x2F;shadowsocksR.sh uninstall</p><h3 id="备用脚本安装SSR"><a href="#备用脚本安装SSR" class="headerlink" title="备用脚本安装SSR"></a>备用脚本安装SSR</h3><p>如果此时链接断了，重连后输入.&#x2F;ssr.sh 就可以进入下面安装操作，以后修改时也输入<code>./ssr.sh</code> 备用脚本（上面的脚步不可用再输入这个）：</p><p>wget -N –no-check-certificate <a href="https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssr.sh">https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssr.sh</a> &amp;&amp; chmod +x ssr.sh &amp;&amp; bash ssr.sh</p><p>如果在输入命令式提示wget:command not found，则表示没有wget工具，先输入下面指令进行安装，然后再部署管理脚本<br>yum -y install wget</p><p>第一步：选择1 </p><p><img src="/article_img/buildvpn/20180307101902154.jpg" alt="第十七步"></p><p>第二步：直接默认即可。（理论上说是可以随便的，1 - 65535）</p><p><img src="/article_img/buildvpn/20180307101913385.jpg" alt="第十八步"></p><p>第三步：设置密码</p><p><img src="/article_img/buildvpn/20180307101927773.jpg" alt="第十九步"></p><p>第四步：加密方式，选择aes-128-cfb就可以</p><p><img src="/article_img/buildvpn/20180307101937845.jpg" alt="第二十步"></p><p>第五步：协议插件，为了使SS也能够使用，这里选择origin</p><p><img src="/article_img/buildvpn/20180307101948387.jpg" alt="第二十一步"></p><p>第六步：选择混淆plain</p><p><img src="/article_img/buildvpn/20180307101957836.jpg" alt="第二十二步"></p><p>第七步：设置连接数量，默认回车即可。然后开始进行安装。</p><p><img src="/article_img/buildvpn/20180307102008416.jpg" alt="第二十三步"></p><p>如果遇到输入项，问y还是n时，输入y 回车确认。</p><p><img src="/article_img/buildvpn/20180307102018140.jpg" alt="第二十四步"></p><p><strong>到此安装就完成了。可以通过客户端进行链接翻墙上网了。</strong></p><p><img src="/article_img/buildvpn/2018030710205260.jpg" alt="第二十五步"></p><p>如果SSR成功安装，但是不能正常启动，在centOS中主要原因是缺少python环境，利用以下指令进行安装</p><p>yum -y install python36</p><p>cd &#x2F;usr&#x2F;bin</p><p>ln -s python3 python</p><p>为了能够提高上网速度，YouTube从480 体验为1080。我们接下来进行安装加速软件（速锐、BBR两者选其一，不可共存）。</p><h3 id="备用脚本安装SS"><a href="#备用脚本安装SS" class="headerlink" title="备用脚本安装SS"></a>备用脚本安装SS</h3><p>wget –no-check-certificate -O shadowsocks-all.sh <a href="https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh">https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh</a></p><p>第一项选1 python安装，其他选择与主脚本描述一样</p><h3 id="BBR加速"><a href="#BBR加速" class="headerlink" title="BBR加速"></a>BBR加速</h3><p>（如果需要速锐，跳过此段）</p><p>BBR加速特别简单，复制下面脚本代码即可。<br>谷歌BBR加速脚本：</p><p>第一个指令：wget –no-check-certificate <a href="https://github.com/teddysun/across/raw/master/bbr.sh">https://github.com/teddysun/across/raw/master/bbr.sh</a></p><p>第二个指令：chmod +x bbr.sh</p><p>第三个指令：.&#x2F;bbr.sh</p><p>1、遇到停顿按回车即可。然后继续安装。（多等一会）</p><p><img src="/article_img/buildvpn/20180307102104748.jpg" alt="第二十六步"></p><p>2、安装完成后问你是否重启，这里输入y，回车。</p><p><img src="/article_img/buildvpn/20180307102114503.jpg" alt="第二十七步"></p><p>3、重新连接后，输入 lsmod | grep bbr 查看BBR是否启动，可以看到已经启动了。</p><p><img src="/article_img/buildvpn/20180307102126665.jpg" alt="第二十八步"></p><h3 id="速锐加速"><a href="#速锐加速" class="headerlink" title="速锐加速"></a>速锐加速</h3><p>1、首先输入<br>uname -a 查看内核为</p><p>2、然后输入<br>cat &#x2F;etc&#x2F;redhat-release  查看系统版本</p><p>3、下载CentOS 6.6版本的内核（速锐支持6.6版本的）<br>wget <a href="http://ftp.scientificlinux.org/linux/scientific/6.6/x86_64/updates/security/kernel-2.6.32-504.3.3.el6.x86_64.rpm">http://ftp.scientificlinux.org/linux/scientific/6.6/x86_64/updates/security/kernel-2.6.32-504.3.3.el6.x86_64.rpm</a></p><p>4、安装内核<br>rpm -ivh kernel-2.6.32-504.3.3.el6.x86_64.rpm –force</p><p>5、重启服务器<br>reboot</p><p>6、安装速锐<br>wget -N –no-check-certificate <a href="https://raw.githubusercontent.com/91yun/serverspeeder/master/serverspeeder-all.sh">https://raw.githubusercontent.com/91yun/serverspeeder/master/serverspeeder-all.sh</a> &amp;&amp; bash serverspeeder-all.sh</p><p>这时正常情况速锐就已经安装完成并且启动了。</p><p><img src="/article_img/buildvpn/20180307102140531.jpg" alt="第二十九步"></p><p>service serverSpeeder status     查看速锐的状态<br>service serverSpeeder start | stop | restart  停止暂停重启锐速</p><p>到此为止，通过BBR或速锐加速的VPN服务器已经全部搭建完成了。接下来使用SSR或者SS客户端连接即可</p><h3 id="SSR-SS客户端链连接"><a href="#SSR-SS客户端链连接" class="headerlink" title="SSR&#x2F;SS客户端链连接"></a>SSR&#x2F;SS客户端链连接</h3><p>MAC：<a href="https://github.com/shadowsocksr-backup/ShadowsocksX-NG/releases">https://github.com/shadowsocksr-backup/ShadowsocksX-NG/releases</a><br>WIN：<a href="https://github.com/shadowsocksr-backup/shadowsocksr-csharp/releases">https://github.com/shadowsocksr-backup/shadowsocksr-csharp/releases</a><br>IPHONE：FirstWingy、potatso lite  （商店里有，实在找不到可以弄个美国APPLEID，什么都能下）</p><p>以iphone为例：首先右上角加号，添加服务器配置信息。</p><p><img src="/article_img/buildvpn/20180307102153178.jpg" alt="第三十步"></p><p>然后：填写一开始安装时的信息,保存。如果忘了记得 .&#x2F;ssr.sh  选择5 查看连接信息</p><p><img src="/article_img/buildvpn/20180307102204995.jpg" alt="第三十一步"></p><p>这时你可以愉快的翻墙上网了。</p><p><img src="/article_img/buildvpn/20180307102258394.jpg" alt="第三十二步"></p><p><strong>如果使用SSR无法连接网络，则可能是centOS未开放相关端口，接下来查询并开启端口</strong></p><p>.&#x2F;ssr.sh 选择5 查看配置信息中的端口号</p><p>假如我们使用的是2333端口</p><p>用以下指令可以查看是否开启对应端口</p><p>firewall-cmd –list-ports</p><p><img src="/article_img/buildvpn/port.png" alt="第三十三步"></p><p>如果没有出现2333&#x2F;tcp的字样，那么该端口还没有开放。使用以下命令开放相应端口并重启：</p><p>firewall-cmd –zone&#x3D;public –add-port&#x3D;2333&#x2F;tcp –permanent</p><p>reboot</p><p>等待1分钟左右，端口已开放，SSR可以连接</p>]]></content>
    
    
    
    <tags>
      
      <tag>Web</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>日语词汇积累</title>
    <link href="/2025/01/01/%E6%97%A5%E8%AF%AD%E8%AF%8D%E6%B1%87%E7%A7%AF%E7%B4%AF/"/>
    <url>/2025/01/01/%E6%97%A5%E8%AF%AD%E8%AF%8D%E6%B1%87%E7%A7%AF%E7%B4%AF/</url>
    
    <content type="html"><![CDATA[<p>2025.03.17<br> 愛(あい) <code>爱</code>  池(いけ) <code>鱼塘</code>  おはよう <code>早上好</code>  おねがい <code>拜托了</code>  はい <code>是的</code>  煩い(うるさい) <code>烦人的</code>  いいえ <code>不，不是</code>  可愛(かわいい) <code>可爱的</code>  かっこいい <code>帅的</code>  傘(かさ) <code>伞</code>  御手洗い(おてあらい) <code>厕所</code><br>2025.03.19<br> 海(うみ) <code>海</code>  嘘(うそ) <code>假话</code>  世界(せかい) <code>世界</code>  寿司(すし) <code>寿司</code>  美味(おいしい) <code>好吃</code>  お菓子(おかし) <code>点心</code>  菊(きく) <code>菊花</code>  君(きみ) <code>你</code>  声(こえ) <code>声音</code>  柿(かき) <code>柿子</code><br>2025.03.21<br> 最高(さいこう) <code>最高，最好</code>  顔(かお) <code>面孔，脸</code>  猫(ねこ) <code>猫</code> たこやき <code>章鱼烧</code>  机(つくえ) <code>桌子</code>  何(なに) <code>什么</code>  年(とし) <code>年龄</code>　 夏(なつ) <code>夏天</code>  梨(なし) <code>梨</code><br>2025.03.23<br> 招き猫(まねきねこ) <code>招财猫</code>  あほ <code>白痴</code>  兄(あに) <code>哥哥</code>  西(にし) <code>西</code>  下手(へた) <code>不擅长</code>  地下鉄(ちかてつ) <code>地铁</code>  うまい <code>好吃</code>  耳(みみ) <code>耳朵</code>  味增汁(みそしる)  <code>味增汤</code>  雨(あめ) <code>雨</code><br>2025.03.25<br> 山(やま) <code>山</code>  彼(かれ) <code>他</code>  無理(むり) <code>无理</code>  娘(むすめ) <code>女儿</code>  もしもし <code>喂（电话用语）</code> 鳥(とり) <code>鸟</code>  雲り(くもり) <code>阴天</code>  奈良(なら) <code>奈良县</code>  桜(さくら) <code>樱花</code>  花嫁(はなよめ) <code>新娘</code></p><p>日常用语整理：</p><ol><li>指示代词<br>第一人称：わたし　わたくし　あたし(女士专用)　ぼく&#x2F;おれ(男士专用)<br>第二人称：あなた　きみ　おまえ<br>第三人称：かれ 他　かのじょ 她；女朋友　かれし 他；男朋友<br>不定人称：だれ　どなた<br>复数人称：わたしたち 我们</li><li>自我介绍<br>初めまして(はじめまして) 初次见面<br>名前(なまえ) 名字<br>今年(ことし) 今年<br>大学(だいがく) 大学<br>一年生(いちねんせい) 大一学生<br>学校(がっこう) 学校 　<br>専門(せんもん) 专业　<br>出身(しゅっしん) 出身，家乡<br>家族(かぞく) 家族<br>これから 今后<br>はは 母亲 ちち 父亲 　<br>一緒に(いっしょに) 一起<br>どうぞ 请<br>よろしく 多多关照<br>思(おも)います 想要<br>人類(じんるい)  人类<br>以前(いぜん)<br>明日(あした)　昨日(きのう)　今日(きょう)  明後日(あさって)</li><li>问候语<br>おはよう 早上好 こんにちは 你好，下午好 こんぱんは 晚上好 おやすみなさい 晚安 いってきます 我出门了 いってらっしやい 路上小心 なだいま 我回来了 おかえりなさい 欢迎回来 ありがとう 谢谢 ごめんなさい 对不起 すみません 对不起 いただきます 我开动了 ごちそうさまでした 多谢款待 はじめまして 初次见面 さようなら 再见 ぱいぱい 拜拜 じゃね 拜拜</li><li>数字<br>0 ぜろ&#x2F;れい 1 いち 2 に 3 さん　4 よん&#x2F;し　5 ご　6 ろく 7 なな&#x2F;しち 8 はち 9 きゅう&#x2F;く 10 じゅう　<br>百 ひゃく　三百　さんびゃく 六百　ろっぴゃく 八百　はっぴゃく<br>から 从…开始   まで 到…结束</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Language</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
