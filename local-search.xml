<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Reinforencement Learning</title>
    <link href="/2025/02/25/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    <url>/2025/02/25/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p>model-free: 不依赖于转移矩阵 </p><p>Model-free Prediction ：迭代更新价值函数，用于预测评估每个状态的价值 Monte Carlo Learning ,Temporal-Difference Learning </p><p>model-based Prediction: Policy Iteration, Value Iteration</p><p>Model-free Control: 改变基于环境的action</p><p>on policy learning:策略学习只能使用 <strong>当前策略</strong> 生成的数据</p><p>off policy learning: 策略学习可以使用 <strong>其他策略</strong> 生成的数据，包括历史数据和经验回放</p><p>​特点：训练策略和行为策略可以不同；可以使用 <strong>过去的数据（经验回放）</strong> 进行训练，提高数据利用率</p><p>important sampling:  <strong>用于估计一个分布的期望值，而采样数据却来自另一个分布</strong> 的技术。它通过调整采样分布的影响，来修正采样偏差，使得估计值更准确。</p><p>在强化学习中，重要性采样用于 <strong>off-policy 评估</strong>，如 Actor-Critic，而 Q-learning <strong>不需要</strong> 重要性采样，因为它直接使用最大 Q 值进行更新。(1.<strong>它不计算策略的期望回报</strong>，而是优化状态-动作值函数 Q(s,a)，所以不需要修正采样分布 2.<strong>它不使用策略梯度</strong>，因此不需要通过重要性采样调整梯度估计)</p><p>Simulator和Batch RL</p><p>Simulator: 强化学习中的一个环境，允许Agent在其中交互、收集数据并进行训练。<strong>适用于Online RL（在线强化学习）</strong>：算法可以随时与环境交互并收集数据（如 DQN、PPO）。</p><p>Batch RL：它仅使用一个固定的数据集来训练，而不会与环境交互。<strong>需要 Off-Policy 方法</strong>：由于数据可能来自多个不同的策略（而非当前策略），必须使用 <strong>Off-Policy RL</strong>（如 DQN、BCQ）。</p><p>Value Approximation：真实场景中，state的数量可能是非常庞大的，为了存储每个state-action pair所需要的lookup-table所需要的空间会很庞大，因此可以考虑使用函数逼近的方法去估计value function，通常可以是Linear combinations of features, Neural network, Decision Tree…</p><p>Goal: $J(w)&#x3D;E_\phi[(v_\phi(S)-\hat v (S, w))^2]$</p><p>w梯度更新: $\bigtriangleup w&#x3D;-1&#x2F;2 \alpha \bigtriangledown_w J(w) &#x3D; \alpha(v_\phi(S)-\hat v (S,w))\bigtriangledown_w \hat v (S,w) $</p>]]></content>
    
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>Algorithm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>命名实体识别&amp;关系抽取 小结</title>
    <link href="/2025/02/21/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB&amp;%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%20%E5%B0%8F%E7%BB%93/"/>
    <url>/2025/02/21/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB&amp;%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%20%E5%B0%8F%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h4 id="BIO标记法"><a href="#BIO标记法" class="headerlink" title="BIO标记法"></a>BIO标记法</h4><p><strong>B-（Begin）</strong>：表示一个实体的<strong>开始</strong>（首个 token）。</p><p><strong>I-（Inside）</strong>：表示实体的<strong>内部</strong>（除首个 token 以外的部分）。</p><p><strong>O-（Outside）</strong>：表示<strong>非实体</strong>的 token。</p><p>例如：**”Apple Inc. is based in California.”</p><p>BIO 标注：</p><table><thead><tr><th>Token</th><th>BIO 标签</th></tr></thead><tbody><tr><td>Apple</td><td><strong>B-ORG</strong></td></tr><tr><td>Inc.</td><td><strong>I-ORG</strong></td></tr><tr><td>is</td><td><strong>O</strong></td></tr><tr><td>based</td><td><strong>O</strong></td></tr><tr><td>in</td><td><strong>O</strong></td></tr><tr><td>California</td><td><strong>B-LOC</strong></td></tr><tr><td>.</td><td><strong>O</strong></td></tr></tbody></table><p><strong>常见的实体类别</strong></p><table><thead><tr><th>实体类别</th><th>含义</th></tr></thead><tbody><tr><td><strong>PER</strong> (Person)</td><td>人名（例如：Elon Musk, Bill Gates）</td></tr><tr><td><strong>ORG</strong> (Organization)</td><td>组织名（例如：Apple, Google, NASA）</td></tr><tr><td><strong>LOC</strong> (Location)</td><td>地名（例如：California, Beijing, Paris）</td></tr><tr><td><strong>MISC</strong> (Miscellaneous)</td><td>其他（例如：品牌名、事件名等）</td></tr></tbody></table><p>在 <strong>NER 任务</strong> 中，BIO 标签常作为<strong>序列标注模型</strong>（如 BiLSTM-CRF、Transformer）训练的目标</p><p><strong>训练模型</strong></p><ul><li><strong>输入</strong>：Word Embeddings（如 BERT, GloVe）</li><li><strong>模型</strong>：BiLSTM + CRF &#x2F; Transformer</li><li><strong>输出</strong>：BIO 标注序列</li></ul><p><strong>预测新文本</strong></p><p>输入新文本后，模型预测对应的 BIO 标签，从而<strong>提取实体</strong>。</p><h4 id="RE-Relation-Extraction-训练集"><a href="#RE-Relation-Extraction-训练集" class="headerlink" title="RE(Relation Extraction)训练集"></a>RE(Relation Extraction)训练集</h4><p><strong>spo:</strong> subject-predicate-object 头实体-关系-尾实体</p><p><strong>训练集中的Predicate列表</strong></p><p>​{<br>      “O”: 0,<br>      “I”: 1,<br>      “注册资本”: 2,<br>      “作者”: 3,<br>      “所属专辑”: 4,<br>      “歌手”: 5,<br>      …<br>      “上映时间_@value”: 8,<br>      “上映时间_@area”: 9,<br>      …<br>​}</p><p>对于同一个S-P，句子中是可能存在多个不同的合法O的，那我们就需要使用两个或多个不同的S-P来对应这些不同的O。一种最常见的方法就是对P再进行细分。如上面示例中的“上映时间_@value”和”上映时间_@area“</p><p><strong>训练集中的spo列表</strong></p><p>​{<br>      “predicate”: [“empty”, “empty”, “注册资本”, “作者”, “所属专辑”, …],<br>      “subject_type”: [“empty”, “empty”, “企业”, “图书作品”, “歌曲”, …],<br>      “object_type”: [“empty”, “empty”, “Number”, “人物”, “音乐专辑”, …]<br>​}</p><p>前两个empty是为了O和I标签留的,因为之前定义的predicate列表中的前2个标签分别为O、I，这两个标签不会起到连接首尾实体的作用，因此需要置为empty。</p><h4 id="NER模型的训练原理"><a href="#NER模型的训练原理" class="headerlink" title="NER模型的训练原理"></a>NER模型的训练原理</h4><p>将实体抽取问题转化为Token Classfication问题。</p><p>Ques：如何实现关系抽取？ </p><p>Ans：在字符类别中添加入「关系标签」，即该字符是否能和这句话当中的其他字符产生关联关系。</p><p><img src="/article_img/NER/NER.png" alt="NER model"></p><p>对每个token，label一共有（2N + 2）维，其中 N 为 Predicate 的类别个数</p><p>损失函数一般使用BCE Loss</p>]]></content>
    
    
    
    <tags>
      
      <tag>NER</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Path-Level GNN-Based Retrievers</title>
    <link href="/2025/02/20/GraphRAG/"/>
    <url>/2025/02/20/GraphRAG/</url>
    
    <content type="html"><![CDATA[<p>1.<a href="https://arxiv.org/abs/2405.20139">GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning</a></p><p>开源代码：<a href="https://github.com/cmavro/GNN-RAG">https://github.com/cmavro/GNN-RAG</a></p><p>Motivation: 将GNN的推理能力和LLM的语言理解能力相结合用于知识图谱问答</p><p>Methodology：首先，GNN 对密集的 KG 子图进行推理，以检索给定问题的答案候选者。其次，提取 KG 中连接问题实体和答案候选项的最短路径以表示 KG 推理路径。提取的路径被文本化并作为使用 RAG 进行 LLM 推理的输入。在GNN-RAG 框架中，GNN 充当密集的子图推理器来提取有用的图信息，而 LLM 则利用其自然语言处理能力进行最终的 KGQA（知识图谱问答）</p><p><img src="/../article_img/PathGNN/GNN-RAG.png" alt="GNN-RAG"></p><p><strong>GNN的训练过程：</strong>将知识图谱问答KGQA任务视为节点分类，使用question-answer pairs训练集，将KG entities被分为answers和non-answers，</p><p>$h_v^{(l)}&#x3D;\psi(h_v^{(l-1)}, \sum_{v’\in N_v}\omega(q,r)\cdot m_{vv’}^{(l)})$    Equ.1</p><p>其中函数$\omega(\cdot)$用来计算三元组(v,r,v’)中关系r和用户查询q之间的相关性。经过多跳传播后，所有节点根据最终表示被分为answer和non-answer两类。</p><p>此外，考虑到不同的GNN会产生不同的推理路径，如公式Equ.1所示，GNN的推理依赖于question-relation匹配函数$\omega(q,r)$，比较常用的设计方式为$\phi(q^{(k)}\odot r)$，其中$q^{(k)}$和$r$使用预训练语言模型来进行编码，$q^{(k)}&#x3D;\gamma_k(LM(q)), r&#x3D;\gamma_c(LM(r))$。</p><p><strong>GNN的推理过程：</strong>具有最高概率分数的节点（例如，高于概率阈值）将作为候选答案返回，以及将问题实体与候选答案连接起来的最短路径（推理路径）。检索到的推理路径用作基于 LLM 的 RAG 的输入。</p><p>为了确保推理路径的多样性，这里作者并没有采用不同的GNN架构，而是使用了不同的LM通过更改$\omega$函数来引导单一的GNN获取不同的节点表示</p><p><strong>LLM</strong>：没什么好说的，prompt-tuning </p><p>prompt: “Based on the reasoning paths, please answer the given question.\n Reasoning Paths: {Reasoning Paths} \n Question: {Question}”. </p><p>Reasoning paths 用语言描述为 “{question entity} → {relation} → {entity} → · · · → {relation} → {answer entity} \n”</p><p>2.<a href="https://arxiv.org/abs/2310.01061">Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning</a></p><p>开源代码：<a href="https://github.com/RManLuo/reasoning-on-graphs">https://github.com/RManLuo/reasoning-on-graphs</a></p><p>Motivation: 现有的基于 KG 的 LLM 推理方法仅将 KG 视为事实知识库，而忽视了其结构信息对推理的重要性。作者提出了一种称为图推理（TOG）的方法，并设计了一种规划检索推理框架，以实现忠实和可解释的推理</p><p><img src="/../article_img/PathGNN/RoG.png" alt="RoG"></p><p>Methodology：RoG包含两个组件：（1）<strong>规划模块：</strong>基于用户查询生成关系路径作为KG的检索规划（2) <strong>检索推理模块：</strong>根据规划模块的关系路径从KG中检索有效的推理路径。RoG通过两项任务进行优化：（1）<strong>规划优化</strong>，由于LLM对KG中包含的关系一无所知，该模块的训练目标是让LLM生成的关系路径尽可能近似于KG的有效路径。作者使用关系路径Q（z）的后验分布最小化KL发散来实现，该后验分布可以通过KGs中的有效关系路径来近似（2）<strong>检索-推理优化</strong>，给定问题q和作为规划z的关系路径，检索模块旨在从KG图G检索这个推理路径$W_z$。检索过程包括在G中查找路径，其从问题实体$e_q$开始并遵循关系路径z。采用一个约束的广度优先搜索（BFS）来检索来自KGs的推理路径$W_z$。实验中，所有检索的路径都用于推理。</p><p><img src="/../article_img/PathGNN/Algorithm.png" alt="Optimization Algorithm"></p><p>总结：LLM用来生成关系路径，在训练的过程中尽可能的去拟合KG中的真实路径。推理时首先让LLM根据用户查询生成路径规划，然后再KG查询对应的有效路径，作为检索结果，与用户查询一起作为LLM输入用户生成回复。</p>]]></content>
    
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>Graph</tag>
      
      <tag>RAG</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GraphRAG综述</title>
    <link href="/2025/02/20/GraphRAG%E7%BB%BC%E8%BF%B0/"/>
    <url>/2025/02/20/GraphRAG%E7%BB%BC%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<h4 id="Sec-1-传统RAG系统面临的挑战"><a href="#Sec-1-传统RAG系统面临的挑战" class="headerlink" title="Sec.1 传统RAG系统面临的挑战"></a>Sec.1 传统RAG系统面临的挑战</h4><p><strong>复杂的查询理解：</strong>传统的 RAG 方法依赖于简单的关键字匹配和向量相似性技术，不足以捕捉准确和全面所需的深层语义细微差别和多步骤推理过程。例如，当询问概念 A 和概念 D 之间的联系时，这些系统通常只检索直接相关的信息，而错过了像 B 和 C 这样可以弥合关系的关键中间概念。这种狭窄的检索范围限制了 RAG 的能力，使其无法进行广泛的上下文理解和复杂的推理</p><p><strong>集成来自分布式源的领域知识：</strong>检索到的知识通常是扁平的、广泛的和错综复杂的，而领域概念通常分散在多个文档中，不同概念之间没有明确的层次结构关系。尽管 RAG 系统试图通过将文档划分为较小的块以实现有效和高效的索引来管理这种复杂性，但这种方法无意中牺牲了关键的上下文信息，严重损害了检索准确性和上下文理解。这种限制阻碍了在相关知识点之间建立强大联系的能力，导致理解碎片化，并降低利用特定领域专业知识的效率。</p><p><strong>LLM的固有约束：</strong>受到其固定上下文窗口的限制，LLM无法完全捕获复杂文档中的长距离依赖关系。在专业领域中，在广泛的知识背景下保持连贯性的挑战变得越来越棘手，因为关键信息可能会在上下文窗口截断期间丢失。</p><p><strong>系统效率和可拓展性：</strong>RAG 系统在计算上可能既昂贵又耗时 ，尤其是在处理大规模知识源时，因为模型需要搜索大量非结构化文本以查找相关信息。此外，实时检索和跨文档推理可能会带来相当大的延迟，从而对用户体验产生负面影响。此外，实时检索和跨文档推理可能会带来相当大的延迟，从而对用户体验产生负面影响，从而限制了它在广泛和动态的专业环境中的实际部署</p><h4 id="Sec-2-现有的GraphRAG分类"><a href="#Sec-2-现有的GraphRAG分类" class="headerlink" title="Sec.2 现有的GraphRAG分类"></a>Sec.2 现有的GraphRAG分类</h4><p><strong>基于知识的GraphRAG:</strong> 它使用图作为知识载体，专注于将非结构化文本文档转换为显式和结构化的 KG，其中node代表领域概念，edge捕获它们之间的语义关系，从而更好地表示分层关系和复杂的知识依赖关系</p><p><strong>基于索引的GraphRAG:</strong> 使用图作为索引工具从语料库中检索相关的原始文本，它保留了原始文本形式，同时主要将图形结构用作索引机制来有效地组织和检索相关文本块。通过将图形结构合并到文本索引中，基于索引的 GraphRAG 方法在文本块之间建立语义连接，以实现高效的查找作和检索</p><p><strong>基于知识的 GraphRAG 旨在通过基于图的推理能力创建结构化的知识表示，以便更好地理解复杂的关系；而基于索引的 GraphRAG 则侧重于通过基于图的索引策略优化相关文本信息的检索和可访问性</strong></p><h4 id="Sec-3-Overview-the-Framework-of-RAG"><a href="#Sec-3-Overview-the-Framework-of-RAG" class="headerlink" title="Sec.3 Overview the Framework of RAG"></a>Sec.3 Overview the Framework of RAG</h4><p>RAG框架主要由三个部分组成，Knowledge Organization,Knowledge Retrieval,Knowledge Integration。下图展示了传统RAG、基于知识的GraphRAG和基于索引的GraphRAG在这三部分的各自实现方式。</p><p><img src="/../article_img/20250220/img1.png" alt="传统 RAG 和两个典型 GraphRAG 工作流程的全面概述。传统 RAG 将语料库组织成块，按相似性对它们进行排名，并检索最相关的文本以生成响应。基于知识的 GraphRAG 使用实体识别和关系提取从语料库中提取详细的知识图谱，提供精细的、特定于领域的信息。基于索引的 GraphRAG 将语料库总结为高级主题节点，这些节点链接以形成索引图，而事实链接将主题映射到文本。这种两层结构将高效的主题检索与详细的文本知识相结合，与基于知识的 GraphRAG 相比，提供了可扩展性和性能"></p><p><strong>Knowledge Organization:  该部分关注外部知识库的构建</strong></p><p><strong>传统RAG</strong>：传统RAG主要采用将大规模文本语料库拆分为可管理块的策略，然后使用嵌入模型将这些块转换为嵌入，其中嵌入用作向量数据库中原始文本块的键。此设置通过在语义空间中基于距离的搜索实现高效的查找作和检索相关内容。常见的优化方法：<strong>粒度优化</strong>和<strong>索引优化</strong>。</p><p><strong>GraphRAG:</strong> 基于图的方法构建外部信息，通过显式知识表示（作为知识载体的图）或索引机制（用于知识索引的图）。这些方法可实现高效的上下文感知信息检索。</p><p><strong>Knowledge Retrieval: 该部分关注如何更精准高效的进行检索</strong></p><p><strong>传统RAG</strong>: 常涉及的检索方法：KNN、TF-IDF、BM25。为了提高检索的准确性和效率，一方面可以在检索前通过优化表示或重排序等技术来提高检索模型的准确性，例如<a href="https://arxiv.org/pdf/2009.08553">GAR</a>、<a href="https://arxiv.org/pdf/2305.17080">EAR</a>等；另一方面，对检索模型进行训练，例如<a href="https://arxiv.org/pdf/2301.12652">Replug</a>，<a href="https://www.jmlr.org/papers/volume24/23-0037/23-0037.pdf">Atlas</a>，<a href="https://arxiv.org/pdf/2305.06983">Flare</a>等。</p><p><strong>GraphRAG:</strong> GraphRAG 模型使用基于图的规划器（可学习的规划器或基于图算法的规划器）根据输入查询检索相关信息。这些检索技术不仅考虑了查询和每个文本块之间的语义相似性，还考虑了查询类型和检索到的子图之间的逻辑连贯性</p><p><strong>Knowledge Integration:  该部分关注如何将检索结果和用户查询高质量整合</strong></p><p><strong>传统RAG</strong>:提高检索到的内容的质量：强化学习方法<a href="https://www.sciencedirect.com/science/article/pii/S294971912400013X">LeanContext</a> LLM自评估方法<a href="https://arxiv.org/pdf/2310.11511">Self-RAG</a>  <a href="https://arxiv.org/pdf/2307.03027">评估检索内容重要性</a>。此外，考虑到对大量检索到的段落进行编码是资源密集型的，这会导致大量的计算和内存开销，相关优化方法：<a href="https://arxiv.org/pdf/2404.12457">RAGCache</a> <a href="https://arxiv.org/pdf/2310.15556">TCRA-LLM</a></p><p><strong>GraphRAG:</strong> 一旦检索到相关知识，GraphRAG 模型就会将其与用户查询整合起来作为LLM input。集成过程的目标是将检索到的知识无缝合并到生成的文本中，从而提高其质量和信息量。一个关键的设计考虑因素是，如何在最终的基于文本的提示中保留检索到的子图信息的丰富性，而不会引入冗余或错误地强调文本描述中不太关键的方面</p><h4 id="Sec-4-Knowledge-Organization-in-GraphRAG"><a href="#Sec-4-Knowledge-Organization-in-GraphRAG" class="headerlink" title="Sec.4 Knowledge Organization in GraphRAG"></a>Sec.4 Knowledge Organization in GraphRAG</h4><p>首先构建一个图结构来组织知识，然后检索和集成与查询相关的信息。下面对Sec.2 提到的范式展开具体介绍。</p><p><strong>Graphs for Knowledge Indexing</strong></p><p>​基于索引的 GraphRAG 方法利用图结构来索引和检索相关的原始文本块，然后将其馈送到 LLM 中以进行知识注入和上下文理解。这些索引图应用语义相似性或特定于域的关系等原则来有效地桥接单独文本段落之间的连接。与仅将图用作知识载体相比，这种技术通过直接总结与查询相关的原始文本块中的信息来提供更丰富的答案。</p><p>​面临的挑战：（1） <strong>简洁性和相关性</strong>：确保构建的图仅捕获相关关系，而不会因不必要的连接而过载，这是一项重大挑战，从而有助于有效调用相关文本块而不会产生冗余 （2）<strong>一致性和冲突解决：</strong>不同的数据块可能会引入冲突的信息。解决这些冲突并确保图保持一致、可靠和结构良好至关重要。</p><p><strong>Graphs for Knowledge Carriers</strong></p><p>​优势：1）高效检索与查询相关的知识 2）长跨度的连贯多步推理  </p><p>​局限性：（1） <strong>缺乏高质量的 KG：</strong>对于直接使用KG作为外部知识库，这一研究方向受到高质量KG可用性的限制。构建KG是资源密集型的，但大多数公开可用的KG仍然远非全面（2） <strong>效率和有效性之间的权衡：</strong>当从文本语料库构建 KG 时，提取知识的粒度在平衡效率和有效性方面起着至关重要的作用。保留细粒度信息会导致更大、更详细的 KG，这可能会阻碍计算效率。相反，紧凑的 KG 可能会牺牲重要的细节，从而导致潜在的信息丢失。</p><h4 id="Sec-5-Knowledge-Retrieval-Process"><a href="#Sec-5-Knowledge-Retrieval-Process" class="headerlink" title="Sec.5 Knowledge Retrieval Process"></a>Sec.5 Knowledge Retrieval Process</h4><p>​基于图的知识检索一般分为Preprocess&#x2F;Matching&#x2F;Pruning三个步骤，如下图所示：</p><p><img src="/../article_img/20250220/img2.png" alt="Retrieval Process"></p><p><strong>Query&#x2F;Graph Preprocess</strong> 预处理阶段同时对查询数据库和图形数据库运行，以便为高效检索做好准备。对于查询预处理，系统通过矢量化或关键术语提取将输入问题转换为结构化表示。这些表示形式用作后续检索作的搜索索引。在图方面，图数据库经过更全面的处理，其中预训练的语言模型将图元素（实体、关系和三元组）转换为密集的向量表示，作为检索锚点 。此外，一些高级检索模型在图数据库上应用图神经网络 （GNN） 来提取高级结构特征，而一些方法甚至采用规则挖掘算法生成规则库，作为图知识的丰富、可搜索的索引</p><p><strong>Matching</strong> 匹配阶段在预处理的查询和索引图数据库之间建立连接。此过程将查询表示形式与图索引进行比较，以识别相关的知识片段。匹配算法同时考虑图中的<strong>语义相似性和结构关系</strong>。根据匹配分数，系统检索与查询高度相关的连通组件和子图，从而创建一组初始的候选知识。</p><p><strong>Knowledge Pruning</strong> 修剪阶段会优化最初检索的知识，以提高其质量和相关性。此优化过程解决了检索过多或不相关信息的常见挑战，尤其是在处理复杂查询或大型图数据库时。剪枝算法应用一系列细化作来整合和总结检索到的知识。具体来说，系统首先删除明显不相关或嘈杂的信息。然后，它整合了相关的知识片段，并生成了复杂图知识的简明摘要。通过提供精炼和重点突出的摘要，LLM 能够更好地理解信息的上下文和细微差别，从而做出更准确和有意义的回答。</p><h4 id="Sec-6-Knowledge-Retrieval-Techniques"><a href="#Sec-6-Knowledge-Retrieval-Techniques" class="headerlink" title="Sec.6 Knowledge Retrieval Techniques"></a>Sec.6 Knowledge Retrieval Techniques</h4><p><strong>基于语义相似性的检索器</strong> 通过测量离散语言空间或连续向量空间中的查询与知识库之间的相似性来进行适当的答案检索 （1）离散空间建模。离散空间建模方法主要利用语言离散统计知识直接对文本字符串进行建模。例如子字符串匹配、正则表达式和精确短语匹配等算法  （2）嵌入空间建模。利用预训练语言模型和词嵌入等方法，例如 TF-IDF、Word2Vec 和 GloVe</p><p><strong>基于逻辑推理的检索器</strong> 采用符号推理从图知识库中推断和提取相关信息。此方法包括创建逻辑规则和约束，以阐明知识库固有的关系和层次结构，例如 规则挖掘 、归纳逻辑编程 和 约束满足 等技术</p><p><strong>基于 GNN 的 Retriever</strong> 主要利用图神经网络对构建的图库中的节点进行编码。检索主要依赖于同时包含情感意义和结构关系理解的节点表征的编码相似性。基于 GNN 的检索器需要训练 GNN 编码器。此外，由于缺乏明确标注的数据，<strong>训练的重点是设计一个合适的损失函数，使 GNN 能够学习通过表示编码准确定位目标知识</strong></p><p><strong>基于 LLM 的检索器</strong> 关于构建的图库，基于 LLM 的知识检索器主要侧重于利用 LLM 来理解图并识别关键子图。</p><p><strong>基于强化学习的检索器</strong> 强化学习 为 GraphRAG 系统中的检索提供了一种自适应和动态策略。通过将检索过程构建为顺序决策挑战，基于 RL 的方法使代理能够在环境反馈的指导下学习和遍历图库，以寻找最相关的信息。</p><p>这种方法赋予系统通过主动交互和积累经验不断提高其检索性能的能力。这个过程可以描述如下：相关的推理背景在于一个特定于问题的子图 $G_{sub}$，其中包含所有源实体 $Q_s$、目标实体 $Q_t$ 及其邻居。理想的子图 $G_{sub}$ 应具有以下属性：（i） $G_{sub}$ 包含尽可能多的源实体和目标实体;（ii） $G_{sub}$ 中的实体和关系与问题上下文具有很强的相关性;（iii） $G_{sub}$ 简洁明了，几乎没有冗余信息，因此可以输入到长度有限的 LLM 中。相关方法：<a href="https://arxiv.org/pdf/2405.16420">Deep QNetworks</a>, <a href="https://arxiv.org/pdf/2401.06800">Policy Gradients</a>, and <a href="https://arxiv.org/pdf/2410.10584">Actor-Critic</a></p><h4 id="Sec-7-Knowledge-Integration"><a href="#Sec-7-Knowledge-Integration" class="headerlink" title="Sec.7 Knowledge Integration"></a>Sec.7 Knowledge Integration</h4><p><strong>微调技术：</strong>利用各种图形信息的微调过程可以根据输入目标的粒度分为三个不同的类别：（i） 节点级知识：关注图形中的各个节点。（ii） 路径级知识：专注于节点之间的连接和序列。（iii） 子图级知识：考虑由多个节点组成的较大结构及其互连。我们将详细探讨这些方面中的每一个。 </p><p>使用 Node 级知识进行微调。在许多基于图的 RAG 系统中，每个节点都链接到一个文档，例如引文网络中的摘要。由于特定领域的数据很少出现在预训练语料库中，因此一些研究在进行下游任务微调之前采用指令调优来加强对特定领域的知识理解。一种简单的微调方法包括将节点和相邻文本作为上下文信息馈送到 LLM 中，以帮助预测 <a href="https://openreview.net/forum?id=x5FfUvsLIE">1</a>、<a href="https://arxiv.org/pdf/2406.10393">2</a>、<a href="https://arxiv.org/pdf/2402.07483">3</a>。鉴于检索到的文档可能很广泛，研究人员可以利用 LLM 将这些文本提炼成单个嵌入 <a href="https://proceedings.neurips.cc/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf">4</a>。尽管缺乏词汇外标记的预训练数据，但 LLM 能够在实践中识别这些嵌入中的信息。</p><p>使用 Path-level Knowledge 进行微调。语言任务通常涉及复杂的推理，需要对事实关系有清晰的理解。利用知识图谱路径，LLM 通过关系和实体的引导增强自身推理能力。这些路径可以是从问题实体到答案实体的最直接路线，也可以使用 图检索模型 或 启发式方法 进行挖掘。它们可以用作输入和输出，但是当两个节点之间存在多条路径时，过滤掉嘈杂的路径同时保留知识图谱中的关系至关重要。为了保持实体表示的完整性及其沿路径的关系，一些方法侧重于将这些路径作为训练目标，预测两个节点之间路径上的节点和关系<a href="https://arxiv.org/pdf/2303.03922">5</a>，甚至跨多个路径<a href="https://arxiv.org/pdf/2310.01061">6</a>。这使 LLM 能够进行Path级推理并产生可靠的输出。</p><p>使用 Subgraph 级知识进行微调。与路径数据的线性拓扑不同，子图数据表现出更复杂、更不规则的拓扑。一种简单的方法是使用图编码器将子图级信息压缩到读出嵌入中。或者，将图数据转换为序列。然而，这些方法往往忽略了子图中丰富的文本内容，无法使 LLM 认识到底层的图结构。为了解决这个问题，一些工作专注于调整 transformer 架构以更好地处理结构化数据，例如<a href="https://arxiv.org/pdf/2212.01588">7</a>、<a href="https://arxiv.org/pdf/2402.11709">8</a>，而另一些则将节点和边的描述直接合并到提示中，例如<a href="https://aclanthology.org/2024.findings-eacl.132.pdf">9</a>、<a href="https://arxiv.org/pdf/2402.08170">10</a>。然而，现有方法仍然存在挑战。前者可能会因架构更改而丢失在预训练期间获得的知识，而后者可能难以处理具有大量节点和边的密集图。</p><h4 id="相关工作总结"><a href="#相关工作总结" class="headerlink" title="相关工作总结"></a>相关工作总结</h4><p>参考文献：<a href="https://arxiv.org/pdf/2501.13958">https://arxiv.org/pdf/2501.13958</a></p><p><img src="/../article_img/20250220/img3.png" alt="参考文献"></p>]]></content>
    
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>Graph</tag>
      
      <tag>RAG</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Graph + RAG</title>
    <link href="/2025/02/18/20250218/"/>
    <url>/2025/02/18/20250218/</url>
    
    <content type="html"><![CDATA[<h1 id="Graph-RAG"><a href="#Graph-RAG" class="headerlink" title="Graph + RAG"></a>Graph + RAG</h1><p>图RAG相比于传统RAG的优势：</p><ol><li>多跳推理能力 2. 关系建模能力 3. 高效的知识更新与管理 4. 减少检索的噪声和生成的幻觉</li></ol><p>最近看了几篇图RAG的论文：</p><h3 id="G-Retriever-Retrieval-Augmented-Generation-for-Textual-Graph-Understanding-and-Question-Answering（https-arxiv-org-pdf-2402-07630）"><a href="#G-Retriever-Retrieval-Augmented-Generation-for-Textual-Graph-Understanding-and-Question-Answering（https-arxiv-org-pdf-2402-07630）" class="headerlink" title="G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering（https://arxiv.org/pdf/2402.07630）"></a>G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering（<a href="https://arxiv.org/pdf/2402.07630%EF%BC%89">https://arxiv.org/pdf/2402.07630）</a></h3><p>Motivation: 引入文本图进行检索增强</p><p>开源代码：<a href="https://github.com/XiaoxinHe/G-Retriever">https://github.com/XiaoxinHe/G-Retriever</a></p><p>首先根据已有的外部知识构建知识图谱，并对每个节点和关系，利用其固有的文本属性进行特征编码。针对用户的query，进行相似度检索，得到节点和边的topk子集。然后设计了一种强化学习策略基于检索得到的子集构建subgraph。在生成阶段，LLM的参数被冻结，除了用户的query以外，还有检索子图的文本属性所构成的hard prompt和基于可训练graph encoder得到的soft prompt <img src="/article_img/20250218/20250218_01.png" alt="G-Retriever"></p><h3 id="Knowledge-Graph-Retrieval-Augmented-Generation-For-LLM-Based-Recommendation-https-arxiv-org-pdf-2501-02226"><a href="#Knowledge-Graph-Retrieval-Augmented-Generation-For-LLM-Based-Recommendation-https-arxiv-org-pdf-2501-02226" class="headerlink" title="Knowledge Graph Retrieval-Augmented Generation For LLM-Based Recommendation(https://arxiv.org/pdf/2501.02226)"></a>Knowledge Graph Retrieval-Augmented Generation For LLM-Based Recommendation(<a href="https://arxiv.org/pdf/2501.02226">https://arxiv.org/pdf/2501.02226</a>)</h3><p>Motivation: 传统的RAG方法忽视了知识的结构关系，借助外部知识构建KG，对推荐进行检索增强；</p><p>检索阶段，首先训练一个GNN网络用来对item-entity知识图谱的每个节点和关系进行编码，并以每个节点作为中心节点生成的多跳特征表示收集起来，构建向量数据库。对于待预测的用户节点，根据其交互历史中的每个节点，利用其文本特征从KG VecDB中检索相关子图，并对检索得到的所有子图进行重排序用于构建soft prompt，从而增强LLM的推荐能力。<img src="/article_img/20250218/20250218_02.png" alt="K-RagRec"></p><h3 id="KG-Retriever-Efficient-Knowledge-Indexing-for-Retrieval-Augmented-Large-Language-Models（https-arxiv-org-pdf-2412-05547）"><a href="#KG-Retriever-Efficient-Knowledge-Indexing-for-Retrieval-Augmented-Large-Language-Models（https-arxiv-org-pdf-2412-05547）" class="headerlink" title="KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models（https://arxiv.org/pdf/2412.05547）"></a>KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models（<a href="https://arxiv.org/pdf/2412.05547%EF%BC%89">https://arxiv.org/pdf/2412.05547）</a></h3><p>Motivation: 对结构信息分层检索，从根本上缓解信息碎片化的问题</p><p>设计了Doc层(Document-level Graph)和KG层(Entity-level Graph)分别用于建立文档内和文档间的连接，Doc Graph的构建是对每个文档进行文本编码，并基于语义相似性获得每个节点的K近邻居；KG Graph的构建是对每个文档进行信息抽取，从而获得对应的知识图谱。检索策略上，作者考虑了两级检索：文档级检索和实体级检索，前者除了考虑用户查询和每个文档的语义相似性以外，还根据Doc Graph获取这些topN文档的one-hop邻居；后者则针对上一阶段检索的所有文档所对应的kg图检索语义相关的实体集，和query一起作为最终LLM的输入<br><img src="/article_img/20250218/20250218_03.png" alt="KG-Retriever"></p>]]></content>
    
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>RAG</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于模型padding左对齐和右对齐的问题</title>
    <link href="/2025/02/17/LLM%20padding/"/>
    <url>/2025/02/17/LLM%20padding/</url>
    
    <content type="html"><![CDATA[<p>最近微调模型进行原因预测任务训练的时候，在eval阶段进行推理生成时遇到了一个警告：“A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set <code>padding_side=&#39;left&#39;</code> when initializing the tokenizer.”，我将tokenizer初始化的定义设置为左填充依然出现该警告，问了下身边对大模型比较了解的同学，发现是token序列结尾加了eos符号导致出现的warning，下面是transformers库中该警告出现的条件：</p><p><img src="/article_img/LLM%20padding/warning.png" alt="warning"></p><p>为什么模型训练选择右填充，推理时选择左填充；为什么训练时需要在结尾添加<eos>标记符，而推理时则不需要，下面给出解释说明：</p><p>训练：Q+A[EOS]  </p><p>模型训练时，对于输入的token序列，我们知道其真实标签（Ques部分可直接用-100作为 <strong>mask</strong> 填充或无效标签，以确保这些位置不会影响损失计算），采用右填充是为了让每个batch内的样本长度对齐。在结尾添加eos标记符是为了告诉模型输入序列的结束位置，如果没有 EOS token，模型可能会将序列当作是没有结束的，进而可能会试图无限制地生成下一个 token，导致训练不稳定或生成行为不正确</p><p>推理：Q</p><p>自回归模型在推理时，从bos标记符开始从左到右依次预测下一个词来生成内容，如下面的图所示：</p><p><img src="/article_img/LLM%20padding/padding.png" alt="padding"></p><p>如果采用右填充，<pad>将被放置在In-Context的右端，从而改变了In-Context内容，这将导致生成时模型的上下文理解出现偏差，结果可能会影响到生成的质量或连贯性。此外，如果在In-Context的结尾处加入eos标记符，这将导致模型停止生成。</p><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/4581421783">模型训练选择right填充，推理选择left填充，为什么？ - 知乎</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Bug</tag>
      
      <tag>Code</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>大模型显存占用计算</title>
    <link href="/2025/02/17/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97/"/>
    <url>/2025/02/17/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%AE%A1%E7%AE%97/</url>
    
    <content type="html"><![CDATA[<h2 id="1-显存单位换算"><a href="#1-显存单位换算" class="headerlink" title="1. 显存单位换算"></a>1. 显存单位换算</h2><p>在讨论显存占用时，首先要明白“B”和“G”的含义。通常，“B”指的是十亿（1B &#x3D; 10^9），而“G”则表示千兆字节（1G &#x3D; 10^9字节）。例如，1B参数意味着有10亿个参数。显存的单位通常以字节计算，而1个字节等于8位。<br>🎈如果使用全精度训练（fp32），每个参数需要占用32位（即4个字节），因此1B的参数需要占用4GB的显存。<br>🎈如果使用半精度（fp16或bf16），则每个参数占用2字节，1B的参数只需占用2GB的显存。</p><h2 id="2-显存开销的其他组成部分"><a href="#2-显存开销的其他组成部分" class="headerlink" title="2. 显存开销的其他组成部分"></a>2. 显存开销的其他组成部分</h2><p>除了模型参数本身外，训练过程中还会消耗一定的显存，主要包括以下几部分：<br>🎈梯度：每个参数对应一个梯度，因此梯度的显存占用与参数量相同。<br>🎈优化器状态：优化器，如Adam，通常会为每个参数保存一阶动量和二阶动量，因此优化器的显存开销为参数量的2倍（对于Adam）。对于其他优化器（如SGD），则取决于优化器的具体实现，若是带动量的SGD，则为参数量的1倍。</p><h2 id="3-显存总占用计算"><a href="#3-显存总占用计算" class="headerlink" title="3. 显存总占用计算"></a>3. 显存总占用计算</h2><p>假设我们训练一个参数量为1B的模型，采用全精度（fp32）并使用Adam优化器，显存的占用计算如下：<br>🎈参数：1B × 4GB &#x3D; 4GB<br>🎈梯度：1B × 4GB &#x3D; 4GB<br>🎈优化器状态：1B × 8GB &#x3D; 8GB<br>因此，总显存占用为16GB。如果使用半精度（bf16），则显存占用减半，为8GB。混合精度训练则会根据各部分精度调整计算结果。</p>]]></content>
    
    
    
    <tags>
      
      <tag>LLM</tag>
      
      <tag>Code</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>人工智能竞赛汇总</title>
    <link href="/2025/02/01/competition/"/>
    <url>/2025/02/01/competition/</url>
    
    <content type="html"><![CDATA[<h2 id="1-人工智能竞赛平台-Biendata：Data-Competition-Community-Biendata"><a href="#1-人工智能竞赛平台-Biendata：Data-Competition-Community-Biendata" class="headerlink" title="1.人工智能竞赛平台 Biendata：Data Competition Community - Biendata"></a><strong>1.人工智能竞赛平台 Biendata：</strong><a href="https://link.zhihu.com/?target=https://www.biendata.xyz/">Data Competition Community - Biendata</a></h2><p><strong>介绍：</strong></p><blockquote><p>2018 年 5 月，人工智能和大数据的竞赛平台 Biendata 完成天使轮融资，由DeepTech深科技投资，旨在打造中国人工智能赛事顶级 IP，赛事相关媒体运营。Biendata 的比赛客户既包括<strong>今日头条、知乎、摩拜、搜狐等企业，也包括了 IEEE、ACM、中国计算机学会、中国人工智能学会</strong>等国内外顶尖学术组织。</p></blockquote><p>总体上来说就是一个各自AI比赛汇总的平台（除了一些大厂有自己的大规模AI赛事比如阿里云天池、华为云、百度、腾讯），类似的办赛平台IP还有</p><ul><li><strong>datafountain：</strong><a href="https://www.datafountain.cn/competitions">数据科学竞赛&#x2F;大数据 竞赛 - DataFountain</a></li><li><strong>Kaggle(国外)：</strong><a href="https://www.kaggle.com/competitions">Kaggle Competitions</a></li></ul><p><strong>时间：</strong>基本上是什么时间都有，需要持续关注官网，同一个企业基本每年举办的timeline不变</p><h2 id="2-阿里云天池：算法大赛-天池大数据竞赛-天池大赛-阿里云天池"><a href="#2-阿里云天池：算法大赛-天池大数据竞赛-天池大赛-阿里云天池" class="headerlink" title="2.阿里云天池：算法大赛-天池大数据竞赛-天池大赛-阿里云天池"></a><strong>2.阿里云天池：</strong><a href="https://tianchi.aliyun.com/competition/gameList/algorithmList">算法大赛-天池大数据竞赛-天池大赛-阿里云天池</a></h2><p><strong>介绍：</strong>老牌，2014年启办，面向全世界科研人员和高校师生，业务场景丰富（2B2C都有cover），奖金池也丰富。</p><p><strong>时间：</strong>基本上是5月份开始报名——夏天初赛\复赛——10月决赛答辩</p><h2 id="3-华为云-：华为云大赛平台"><a href="#3-华为云-：华为云大赛平台" class="headerlink" title="3.华为云 ：华为云大赛平台"></a><strong>3.华为云 ：</strong><a href="https://competition.huaweicloud.com/competitions">华为云大赛平台</a></h2><p><strong>介绍：</strong>众所周知华为对研发投入比例很大，也十分重视创新大赛的举办，会联合各种高校、产品线、学术机构\组织办赛，每年任何时间节点都可能会有比赛。相关领域的同学需要持续关注。</p><p><strong>时间：</strong>一年中任意时刻</p><h2 id="4-百度飞桨AI-Studio大赛：飞桨AI-Studio-人工智能学习与实训社区"><a href="#4-百度飞桨AI-Studio大赛：飞桨AI-Studio-人工智能学习与实训社区" class="headerlink" title="4. 百度飞桨AI Studio大赛：飞桨AI Studio - 人工智能学习与实训社区"></a><strong>4. 百度飞桨AI Studio大赛：</strong><a href="https://aistudio.baidu.com/aistudio/competition/1/1">飞桨AI Studio - 人工智能学习与实训社区</a></h2><p><strong>介绍：</strong>AI Studio是基于百度深度学习平台飞桨的人工智能学习与实训社区，整体跟华为云的形式差异不大，但赛程周期会紧凑一些，内容也和百度的业务内容强相关（如<strong>NLP</strong>\图像检测\导航路径）。个人感觉场景会更专精于NLP，比如事件抽取\机器翻译\QA\阅读理解\情感分析。</p><p><strong>时间：</strong>每年3-5月</p><h2 id="5-腾讯：-2021腾讯广告算法大赛"><a href="#5-腾讯：-2021腾讯广告算法大赛" class="headerlink" title="5.腾讯： 2021腾讯广告算法大赛"></a><strong>5.腾讯：</strong> <a href="https://algo.qq.com/index.html%3Flang%3Dcn">2021腾讯广告算法大赛</a></h2><p><strong>介绍：</strong>腾讯AI赛事做的不是特别好，除了广告算法大赛还比较成规模（基本每年有延续），其他的都很分散，没有统一的平台。</p><blockquote><p>AI Lab偶尔有些算法挑战赛，AI温室种番茄什么的: <a href="https://ai.tencent.com/ailab/zh/index">腾讯 AI Lab - 腾讯人工智能实验室官网</a></p></blockquote><p><strong>时间：</strong>三月开始报名——夏季初赛\复赛——八月决赛答辩</p><h2 id="6-AIOps-Challenge智能运维挑战赛：竞赛列表"><a href="#6-AIOps-Challenge智能运维挑战赛：竞赛列表" class="headerlink" title="6.AIOps Challenge智能运维挑战赛：竞赛列表"></a><strong>6.AIOps Challenge智能运维挑战赛</strong>：<a href="https://iops.ai/competition_list/">竞赛列表</a></h2><p><strong>介绍：</strong>规模较小，每年承办方会有变化，但是主题围绕着AIOps不变</p><p><strong>时间：</strong>基本上是1月年初开始报名——春季初赛\复赛——五月决赛答辩</p><h2 id="7-KDD-CUP：KDD-2021-Singapore"><a href="#7-KDD-CUP：KDD-2021-Singapore" class="headerlink" title="7.KDD CUP：KDD 2021 | Singapore"></a><strong>7.KDD CUP：</strong><a href="https://www.kdd.org/kdd2021/%23">KDD 2021 | Singapore</a></h2><p><strong>介绍:</strong> 国外赛事，商业性质较弱所以奖金池较小，主题是多源数据时序异常检测\OGB-LSC\城市大脑挑战，延续性比较好。</p><p><strong>时间：</strong>每年五月-八月</p>]]></content>
    
    
    
    <tags>
      
      <tag>Study</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Recsys大牛实验室官网链接</title>
    <link href="/2025/02/01/lab/"/>
    <url>/2025/02/01/lab/</url>
    
    <content type="html"><![CDATA[<p>Xiangnan He：<a href="https://hexiangnan.github.io/">https://hexiangnan.github.io/</a><br>Yuan Fang@SMU: <a href="https://www.yfang.site/">https://www.yfang.site/</a><br>Huang Chao: <a href="https://sites.google.com/view/chaoh">https://sites.google.com/view/chaoh</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Study</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>搭建代理服务器访问外网</title>
    <link href="/2025/02/01/buildvpn/"/>
    <url>/2025/02/01/buildvpn/</url>
    
    <content type="html"><![CDATA[<h1 id="buildVpn"><a href="#buildVpn" class="headerlink" title="buildVpn"></a>buildVpn</h1><h3 id="图文教程搭建一个vpn"><a href="#图文教程搭建一个vpn" class="headerlink" title="图文教程搭建一个vpn"></a>图文教程搭建一个vpn</h3><h3 id="准备工作：有支付宝账户，有一个可用邮箱，有10美元。（根据我下面的链接注册，会赠送300美元的体验金，可以试一下没成本，如果长期用可以再去充值）"><a href="#准备工作：有支付宝账户，有一个可用邮箱，有10美元。（根据我下面的链接注册，会赠送300美元的体验金，可以试一下没成本，如果长期用可以再去充值）" class="headerlink" title="准备工作：有支付宝账户，有一个可用邮箱，有10美元。（根据我下面的链接注册，会赠送300美元的体验金，可以试一下没成本，如果长期用可以再去充值）"></a>准备工作：有支付宝账户，有一个可用邮箱，有10美元。（根据我下面的链接注册，会赠送300美元的体验金，可以试一下没成本，如果长期用可以再去充值）</h3><h3 id="前言：首先我们选择Vultr供应商来购买海外VPS服务器，具有12个地区可以选择，当然也可以选择其他的供应商，但是Vultr的优点在于，所有服务器创建成功后开始计费，并且是按照小时来计费的，如果你删除掉服务器将不再计费。众所周知，目前国内的VPN打击特别严厉，很多VPN已经被封掉了，我们购买的海外服务器也有可能是被墙掉IP或者用一段时间被墙的。所以Vultr可以随时创建一个新的服务器（会分配一个新的ip），删除掉原有的。"><a href="#前言：首先我们选择Vultr供应商来购买海外VPS服务器，具有12个地区可以选择，当然也可以选择其他的供应商，但是Vultr的优点在于，所有服务器创建成功后开始计费，并且是按照小时来计费的，如果你删除掉服务器将不再计费。众所周知，目前国内的VPN打击特别严厉，很多VPN已经被封掉了，我们购买的海外服务器也有可能是被墙掉IP或者用一段时间被墙的。所以Vultr可以随时创建一个新的服务器（会分配一个新的ip），删除掉原有的。" class="headerlink" title="前言：首先我们选择Vultr供应商来购买海外VPS服务器，具有12个地区可以选择，当然也可以选择其他的供应商，但是Vultr的优点在于，所有服务器创建成功后开始计费，并且是按照小时来计费的，如果你删除掉服务器将不再计费。众所周知，目前国内的VPN打击特别严厉，很多VPN已经被封掉了，我们购买的海外服务器也有可能是被墙掉IP或者用一段时间被墙的。所以Vultr可以随时创建一个新的服务器（会分配一个新的ip），删除掉原有的。"></a>前言：首先我们选择Vultr供应商来购买海外VPS服务器，具有12个地区可以选择，当然也可以选择其他的供应商，但是Vultr的优点在于，所有服务器创建成功后开始计费，并且是按照小时来计费的，如果你删除掉服务器将不再计费。众所周知，目前国内的VPN打击特别严厉，很多VPN已经被封掉了，我们购买的海外服务器也有可能是被墙掉IP或者用一段时间被墙的。所以Vultr可以随时创建一个新的服务器（会分配一个新的ip），删除掉原有的。</h3><h3 id="创建账户及购买VPS服务器"><a href="#创建账户及购买VPS服务器" class="headerlink" title="创建账户及购买VPS服务器"></a>创建账户及购买VPS服务器</h3><p>第一步：登录vultr官网注册一个账户，只需要一个邮箱和密码即可。然后到你注册的邮箱中去验证你的账户。</p><h4 id="官网推广链接-https-www-vultr-com-ref-9695214-9J-这个链接是官网一个推荐链接，有300刀体验金"><a href="#官网推广链接-https-www-vultr-com-ref-9695214-9J-这个链接是官网一个推荐链接，有300刀体验金" class="headerlink" title="官网推广链接(https://www.vultr.com/?ref=9695214-9J) 这个链接是官网一个推荐链接，有300刀体验金"></a>官网推广链接(<a href="https://www.vultr.com/?ref=9695214-9J">https://www.vultr.com/?ref=9695214-9J</a>) 这个链接是官网一个推荐链接，有300刀体验金</h4><p>官网链接(<a href="https://www.vultr.com/?ref=7348872">https://www.vultr.com/?ref=7348872</a>)        这个链接就是普通的推荐链接</p><p><img src="/article_img/buildvpn/20180307101419422.jpg" alt="第一步"></p><p>第二步：登录你的账户，然后在如图所示地方进行充值。这里我们可以使用微信或支付宝扫码支付，充值成功后，可以再右上角看到你的账户余额。</p><p><img src="/article_img/buildvpn/20180307101506198.jpg" alt="第二步"></p><p>第三步：购买VPS服务器。在Servers标签中看到，我们目前还没有服务器，这时选择右上角的加号新添加一个服务器。</p><p><img src="/article_img/buildvpn/20180307101543991.jpg" alt="第三步"></p><p>我们首先选择服务器所在地区，这里我们选择NewYork纽约，一般来说选择日本、纽约、洛杉矶、硅谷都还可以（全看人品）。</p><p><img src="/article_img/buildvpn/20180307101558312.jpg" alt="第四步"></p><p>其次我们选择服务器的系统版本。这里注意选择CentOS6 ，默认是7由于防火墙等原因可能会影响接下来的操作。</p><p><img src="/article_img/buildvpn/20180307101612917.jpg" alt="第五步"></p><p>最后，我们选择每个月2.5刀，500G带宽的就可以了。</p><p><img src="/article_img/buildvpn/20180307101629749.jpg" alt="第六步"></p><p>其他的不需要选择，如果需要使用IPv6就在第四部选择。这里我们不选择，默认使用IPv4，最下面我们选择Depliy Now 新建服务器。</p><p><img src="/article_img/buildvpn/20180307101643841.jpg" alt="第七步"></p><p>到目前为止我们就已经成功的创建了一个海外服务器。但是这个服务器是否可用，有没有被墙掉呢？当服务器安装完成之后，我们来测试一下。</p><p><img src="/article_img/buildvpn/20180307101656506.jpg" alt="第八步"></p><p>我们可以看到已经在运行的服务器ip为  45.63.7.251 ，接下来就测试一下是否能够连接。<br>Win： win + R快捷键或者在开始菜单-附件-运行，调出运行窗口，输入cmd，然后输入ping  45.63.7.251 可以看到是否被墙。（多ping几次）<br>Mac + Linux：直接在命令行窗口输入ping  45.63.7.251 （按ctrl + c 退出）<br>或者通过网站ping检测，如果全是超时代表被墙了。<a href="http://ping.chinaz.com/">http://ping.chinaz.com/</a></p><p><img src="/article_img/buildvpn/20180307101706991.jpg" alt="第九步"></p><p>这里可以看到刚刚新建的服务器是被墙掉的。无法访问，这时就再新建一个服务器，然后在ping。如果同一个地区多次无法ping通，就换一个地区试试，这里推荐日本。（每次新建服务器，按小时首付0.01刀，删除后不计费，十次也才不到一块钱）</p><p>如图，我再次新建了一个服务器，这回可以ping通，说明没有被墙。就是延时高一点，延时与你的网络和当前的时间段，使用的人数有关。</p><p><img src="/article_img/buildvpn/20180307101717865.jpg" alt="第九步"></p><p><img src="/article_img/buildvpn/20180307101733164.jpg" alt="第十步"></p><p>这时我们把之前被墙掉的服务器删除就可以了。新建可用的服务器已经全部完成了。</p><p><img src="/article_img/buildvpn/20180307101748789.jpg" alt="第十一步"></p><p>点击详情可以看到服务器的用户名和密码</p><p><img src="/article_img/buildvpn/20180307101802763.jpg" alt="第十二步"></p><p><img src="/article_img/buildvpn/20180307101812373.jpg" alt="第十三步"></p><p>接下来我们就可以搭建VPN了。距离成功已经很近了。</p><p>首先如果我们是Windows系统需要下载一个软件（Mac 或 Linux不需要），Xshell或者SecureCRT。这里我用的是SecureCRT。<br>填写你的IP地址，用户名为root，点击链接，点击接受保存，输入你的密码，成功连接。</p><p><img src="/article_img/buildvpn/20180307101823784.jpg" alt="第十四步"><br><img src="/article_img/buildvpn/20180307101836775.jpg" alt="第十五步"></p><p>其次要设置编码格式，不然一会的中文会显示乱码。菜单栏 选项-会话选项-外观-字符编码-UTF8-确认。<br>关闭软件，重新连接（直接双击IP就可以了）。</p><p><img src="/article_img/buildvpn/20180307101848327.jpg" alt="第十六步"></p><p>然后复制下面的一键部署管理脚本，粘贴到窗口中（鼠标右键一下即可粘贴）</p><p>CentOS6&#x2F;Debian6&#x2F;Ubuntu14 ShadowsocksR一键部署管理脚本(可以把下面命令按行拆开分步执行)：</p><p>wget –no-check-certificate <a href="https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.sh">https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.sh</a></p><p>chmod +x shadowsocksR.sh</p><p>.&#x2F;shadowsocksR.sh 2&gt;&amp;1 | tee shadowsocksR.log</p><h3 id="主脚本安装SSR："><a href="#主脚本安装SSR：" class="headerlink" title="主脚本安装SSR："></a>主脚本安装SSR：</h3><p>第一步：设定密码，default 为默认密码</p><p><img src="/article_img/buildvpn/new2.png" alt="第十六-1步"></p><p>第二步：设定端口，default 为随机生成默认端口<br><img src="/article_img/buildvpn/new3.png" alt="第十六-2步"></p><p>第三步：设定加密方式，default 为默认加密方式<br><img src="/article_img/buildvpn/new4.png" alt="第十六-3步"></p><p>第四步：设协议，default 为默认协议<br><img src="/article_img/buildvpn/new1.png" alt="第十六-4步"></p><p>第五步：设定混淆方式，default 为默认混淆<br><img src="/article_img/buildvpn/new5.png" alt="第十六-5步"></p><p>第六步：安任意键，回车开始进行安装，安装完成后自动启动<br><img src="/article_img/buildvpn/new7.png" alt="第十六-6步"></p><p>当安装出现问题时，有可能是centOS中缺少相应c编译器，可以分别执行以下指令安装编译器后再安装SSR：</p><p>yum -y install gcc automake autoconf libtool make</p><p>yum -y install gcc-c++</p><p>最终：安装完成，展示你所设置的内容，可以按照链接信息进行连接(最近较严有可能被墙或者端口被封)<br><img src="/article_img/buildvpn/new6.png" alt="第十六-7步"></p><p>安装过后如果想要修改，运行如下相关命令</p><p>启动：&#x2F;etc&#x2F;init.d&#x2F;shadowsocks start</p><p>停止：&#x2F;etc&#x2F;init.d&#x2F;shadowsocks stop</p><p>重启：&#x2F;etc&#x2F;init.d&#x2F;shadowsocks restart</p><p>状态：&#x2F;etc&#x2F;init.d&#x2F;shadowsocks status</p><p>配置文件路径：&#x2F;etc&#x2F;shadowsocks.json  修改文件用vi 或者 vim命令，使用方法百度</p><p>日志文件路径：&#x2F;var&#x2F;log&#x2F;shadowsocks.log </p><p>安装路径：&#x2F;usr&#x2F;local&#x2F;shadowsocks&#x2F;shadowsoks</p><p>卸载.&#x2F;shadowsocksR.sh uninstall</p><h3 id="备用脚本安装SSR：（如果此时链接断了，重连后输入-ssr-sh-就可以进入下面安装操作，以后修改时也输入-ssr-sh）"><a href="#备用脚本安装SSR：（如果此时链接断了，重连后输入-ssr-sh-就可以进入下面安装操作，以后修改时也输入-ssr-sh）" class="headerlink" title="备用脚本安装SSR：（如果此时链接断了，重连后输入.&#x2F;ssr.sh 就可以进入下面安装操作，以后修改时也输入.&#x2F;ssr.sh）"></a>备用脚本安装SSR：（如果此时链接断了，重连后输入.&#x2F;ssr.sh 就可以进入下面安装操作，以后修改时也输入.&#x2F;ssr.sh）</h3><p>备用脚本（上面的脚步不可用再输入这个）：</p><p>wget -N –no-check-certificate <a href="https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssr.sh">https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssr.sh</a> &amp;&amp; chmod +x ssr.sh &amp;&amp; bash ssr.sh</p><p>如果在输入命令式提示wget:command not found，则表示没有wget工具，先输入下面指令进行安装，然后再部署管理脚本<br>yum -y install wget</p><p>第一步：选择1 </p><p><img src="/article_img/buildvpn/20180307101902154.jpg" alt="第十七步"></p><p>第二步：直接默认即可。（理论上说是可以随便的，1 - 65535）</p><p><img src="/article_img/buildvpn/20180307101913385.jpg" alt="第十八步"></p><p>第三步：设置密码</p><p><img src="/article_img/buildvpn/20180307101927773.jpg" alt="第十九步"></p><p>第四步：加密方式，选择aes-128-cfb就可以</p><p><img src="/article_img/buildvpn/20180307101937845.jpg" alt="第二十步"></p><p>第五步：协议插件，为了使SS也能够使用，这里选择origin</p><p><img src="/article_img/buildvpn/20180307101948387.jpg" alt="第二十一步"></p><p>第六步：选择混淆plain</p><p><img src="/article_img/buildvpn/20180307101957836.jpg" alt="第二十二步"></p><p>第七步：设置连接数量，默认回车即可。然后开始进行安装。</p><p><img src="/article_img/buildvpn/20180307102008416.jpg" alt="第二十三步"></p><p>如果遇到输入项，问y还是n时，输入y 回车确认。</p><p><img src="/article_img/buildvpn/20180307102018140.jpg" alt="第二十四步"></p><h3 id="到此安装就完成了。可以通过客户端进行链接翻墙上网了。"><a href="#到此安装就完成了。可以通过客户端进行链接翻墙上网了。" class="headerlink" title="到此安装就完成了。可以通过客户端进行链接翻墙上网了。"></a>到此安装就完成了。可以通过客户端进行链接翻墙上网了。</h3><p><img src="/article_img/buildvpn/2018030710205260.jpg" alt="第二十五步"></p><p>如果SSR成功安装，但是不能正常启动，在centOS中主要原因是缺少python环境，利用以下指令进行安装</p><p>yum -y install python36</p><p>cd &#x2F;usr&#x2F;bin</p><p>ln -s python3 python</p><h3 id="为了能够提高上网速度，YouTube从480-体验为1080。我们接下来进行安装加速软件（速锐、BBR两者选其一，不可共存）。"><a href="#为了能够提高上网速度，YouTube从480-体验为1080。我们接下来进行安装加速软件（速锐、BBR两者选其一，不可共存）。" class="headerlink" title="为了能够提高上网速度，YouTube从480 体验为1080。我们接下来进行安装加速软件（速锐、BBR两者选其一，不可共存）。"></a>为了能够提高上网速度，YouTube从480 体验为1080。我们接下来进行安装加速软件（速锐、BBR两者选其一，不可共存）。</h3><h3 id="BBR加速（如果需要速锐，跳过此段）"><a href="#BBR加速（如果需要速锐，跳过此段）" class="headerlink" title="BBR加速（如果需要速锐，跳过此段）"></a>BBR加速（如果需要速锐，跳过此段）</h3><p>BBR加速特别简单，复制下面脚本代码即可。<br>谷歌BBR加速脚本：</p><p>第一个指令：wget –no-check-certificate <a href="https://github.com/teddysun/across/raw/master/bbr.sh">https://github.com/teddysun/across/raw/master/bbr.sh</a></p><p>第二个指令：chmod +x bbr.sh</p><p>第三个指令：.&#x2F;bbr.sh</p><p>1、遇到停顿按回车即可。然后继续安装。（多等一会）</p><p><img src="/article_img/buildvpn/20180307102104748.jpg" alt="第二十六步"></p><p>2、安装完成后问你是否重启，这里输入y，回车。</p><p><img src="/article_img/buildvpn/20180307102114503.jpg" alt="第二十七步"></p><p>3、重新连接后，输入 lsmod | grep bbr 查看BBR是否启动，可以看到已经启动了。</p><p><img src="/article_img/buildvpn/20180307102126665.jpg" alt="第二十八步"></p><h3 id="备用脚本安装SS："><a href="#备用脚本安装SS：" class="headerlink" title="备用脚本安装SS："></a>备用脚本安装SS：</h3><p>wget –no-check-certificate -O shadowsocks-all.sh <a href="https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh">https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh</a></p><p>第一项选1 python安装，其他选择与主脚本描述一样</p><h3 id="速锐加速"><a href="#速锐加速" class="headerlink" title="速锐加速"></a>速锐加速</h3><p>1、首先输入<br>uname -a 查看内核为</p><p>2、然后输入<br>cat &#x2F;etc&#x2F;redhat-release  查看系统版本</p><p>3、下载CentOS 6.6版本的内核（速锐支持6.6版本的）<br>wget <a href="http://ftp.scientificlinux.org/linux/scientific/6.6/x86_64/updates/security/kernel-2.6.32-504.3.3.el6.x86_64.rpm">http://ftp.scientificlinux.org/linux/scientific/6.6/x86_64/updates/security/kernel-2.6.32-504.3.3.el6.x86_64.rpm</a></p><p>4、安装内核<br>rpm -ivh kernel-2.6.32-504.3.3.el6.x86_64.rpm –force</p><p>5、重启服务器<br>reboot</p><p>6、安装速锐<br>wget -N –no-check-certificate <a href="https://raw.githubusercontent.com/91yun/serverspeeder/master/serverspeeder-all.sh">https://raw.githubusercontent.com/91yun/serverspeeder/master/serverspeeder-all.sh</a> &amp;&amp; bash serverspeeder-all.sh</p><p>这时正常情况速锐就已经安装完成并且启动了。</p><p><img src="/article_img/buildvpn/20180307102140531.jpg" alt="第二十九步"></p><p>service serverSpeeder status     查看速锐的状态<br>service serverSpeeder start | stop | restart  停止暂停重启锐速</p><h3 id="到此为止，通过BBR或速锐加速的VPN服务器已经全部搭建完成了。"><a href="#到此为止，通过BBR或速锐加速的VPN服务器已经全部搭建完成了。" class="headerlink" title="到此为止，通过BBR或速锐加速的VPN服务器已经全部搭建完成了。"></a>到此为止，通过BBR或速锐加速的VPN服务器已经全部搭建完成了。</h3><h3 id="接下来使用SSR或者SS客户端连接即可"><a href="#接下来使用SSR或者SS客户端连接即可" class="headerlink" title="接下来使用SSR或者SS客户端连接即可"></a>接下来使用SSR或者SS客户端连接即可</h3><p>MAC：<a href="https://github.com/shadowsocksr-backup/ShadowsocksX-NG/releases">https://github.com/shadowsocksr-backup/ShadowsocksX-NG/releases</a><br>WIN：<a href="https://github.com/shadowsocksr-backup/shadowsocksr-csharp/releases">https://github.com/shadowsocksr-backup/shadowsocksr-csharp/releases</a><br>IPHONE：FirstWingy、potatso lite  （商店里有，实在找不到可以弄个美国APPLEID，什么都能下）</p><p>以iphone为例：首先右上角加号，添加服务器配置信息。</p><p><img src="/article_img/buildvpn/20180307102153178.jpg" alt="第三十步"></p><p>然后：填写一开始安装时的信息,保存。如果忘了记得 .&#x2F;ssr.sh  选择5 查看连接信息</p><p><img src="/article_img/buildvpn/20180307102204995.jpg" alt="第三十一步"></p><p>这时你可以愉快的翻墙上网了。</p><p><img src="/article_img/buildvpn/20180307102258394.jpg" alt="第三十二步"></p><h3 id="如果使用SSR无法连接网络，则可能是centOS未开放相关端口，接下来查询并开启端口"><a href="#如果使用SSR无法连接网络，则可能是centOS未开放相关端口，接下来查询并开启端口" class="headerlink" title="如果使用SSR无法连接网络，则可能是centOS未开放相关端口，接下来查询并开启端口"></a>如果使用SSR无法连接网络，则可能是centOS未开放相关端口，接下来查询并开启端口</h3><p>.&#x2F;ssr.sh 选择5 查看配置信息中的端口号</p><p>假如我们使用的是2333端口</p><p>用以下指令可以查看是否开启对应端口</p><p>firewall-cmd –list-ports</p><p><img src="/article_img/buildvpn/port.png" alt="第三十三步"></p><p>如果没有出现2333&#x2F;tcp的字样，那么该端口还没有开放。使用以下命令开放相应端口并重启：</p><p>firewall-cmd –zone&#x3D;public –add-port&#x3D;2333&#x2F;tcp –permanent</p><p>reboot</p><p>等待1分钟左右，端口已开放，SSR可以连接</p>]]></content>
    
    
    
    <tags>
      
      <tag>Web</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
